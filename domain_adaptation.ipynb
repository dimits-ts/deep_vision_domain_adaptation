{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Pseudo-labeling Performance Sans Supporting Algorithms and Models\n",
    "\n",
    "---\n",
    "\n",
    "> Dimitris Tsirmpas <br>\n",
    "> MSc in Data Science f3352315 <br>\n",
    "> Athens University of Economics and Business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Structure\n",
    "\n",
    "The project is structured as follows:\n",
    "\n",
    "Main files:\n",
    "- domain_adaptation.ipynb: is the main Jupyter Notebook containing the project code\n",
    "- report.pdf: Supplemental material containing Figures, Tables and analysis on the results of the project\n",
    "  \n",
    "Directories:\n",
    "- lib: a library of general functions for Data Science tasks\n",
    "- tasks: task-specific modules\n",
    "- data: the input data\n",
    "- output: the model training output\n",
    "- results: Graphs, Tables and Figures produced in the project\n",
    "- scripts: pre-processing scripts applied to the data\n",
    "\n",
    "Notes:\n",
    "\n",
    "* This notebook mainly discusses the implementation and design decisions of the project. For the theory, experimental procedures\n",
    "and results, consult [the main report](report.pdf).\n",
    "\n",
    "* This notebook does not contain the fundamental code for preprocessing, loading data, training models, implementing the pseudo-labeling procedure\n",
    "or our incremental learning algorithm. The code, as well as extensive comments and documentation, exist in the respective source files in the\n",
    "`tasks` and `lib` directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Office Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lib.data\n",
    "import lib.torch_train_eval\n",
    "import lib.adaptive_train_eval\n",
    "import lib.coral_train\n",
    "\n",
    "import tasks.preprocessing\n",
    "import tasks.utils\n",
    "import tasks.results\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_DIR = \"data/office\"\n",
    "OUTPUT_DIR = \"output/office\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 1\n",
    "PRINT_STATS_PERIOD = 500\n",
    "\n",
    "SOURCE_DATASET = \"amazon\"\n",
    "SOURCE_VAL_SPLIT = .15\n",
    "SOURCE_TEST_SPLIT = .1\n",
    "\n",
    "TARGET_VAL_SPLIT = .15\n",
    "TARGET_TEST_SPLIT = .15\n",
    "TARGET_DATASET = \"webcam\"\n",
    "\n",
    "RHO = 4\n",
    "SAMPLING_PERIOD = 20\n",
    "\n",
    "FINETUNED_SOURCE__MODEL_DIR = os.path.join(OUTPUT_DIR, \"classifier\")\n",
    "CORAL_SOURCE_MODEL_DIR = os.path.join(OUTPUT_DIR, \"coral\")\n",
    "FINETUNED_TARGET_MODEL_DIR = os.path.join(OUTPUT_DIR, \"target_classifier\")\n",
    "UNSUPERVISED_MODEL_DIR = os.path.join(OUTPUT_DIR, \"unsupervised\")\n",
    "SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20 = os.path.join(OUTPUT_DIR, \"semi-supervised-finetuned-20\")\n",
    "SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20 = os.path.join(OUTPUT_DIR, \"semi-supervised-adaptive-20\")\n",
    "SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10 = os.path.join(OUTPUT_DIR, \"semi-supervised-finetuned-10\")\n",
    "SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10 = os.path.join(OUTPUT_DIR, \"semi-supervised-adaptive-10\")\n",
    "\n",
    "FINETUNE_SOURCE_MODEL = False\n",
    "TRAIN_CORAL_MODEL = False\n",
    "FINETUNE_TARGET_MODEL = False\n",
    "TRAIN_UNSUPERVISED_MODEL = False\n",
    "FINETUNE_SEMI_SUPERVISED_MODEL_20 = False\n",
    "TRAIN_SEMI_SUPERVISED_MODEL_20 = False\n",
    "FINETUNE_SEMI_SUPERVISED_MODEL_10 = False\n",
    "TRAIN_SEMI_SUPERVISED_MODEL_10 = False\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing\n",
    "\n",
    "Most of the work here is done through the ImageDataset class, which lazy loads all images from the given root directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the data from the source dataset (Modern Office-31 Amazon domain)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "source_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "source_dataset.load_from_directory(os.path.join(DATA_DIR, SOURCE_DATASET))\n",
    "\n",
    "source_train_dataset, source_val_dataset, source_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        source_dataset, SOURCE_VAL_SPLIT, SOURCE_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "source_train_loader = tasks.preprocessing.single_batch_loader(\n",
    "    source_train_dataset, shuffle=True\n",
    ")\n",
    "source_val_loader = tasks.preprocessing.single_batch_loader(\n",
    "    source_val_dataset, shuffle=False\n",
    ")\n",
    "source_test_loader = tasks.preprocessing.single_batch_loader(\n",
    "    source_test_dataset, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the respective target dataset (Modern Office-31 Webcam domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    "    label_encoder=source_dataset.label_encoder,  # use same classes\n",
    ")\n",
    "target_dataset.load_from_directory(os.path.join(DATA_DIR, TARGET_DATASET))\n",
    "\n",
    "target_train_dataset, target_val_dataset, target_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        target_dataset, TARGET_VAL_SPLIT, TARGET_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "target_train_loader = tasks.preprocessing.single_batch_loader(\n",
    "    target_train_dataset, shuffle=True\n",
    ")\n",
    "target_val_loader = tasks.preprocessing.single_batch_loader(\n",
    "    target_val_dataset, shuffle=False\n",
    ")\n",
    "target_test_loader = tasks.preprocessing.single_batch_loader(\n",
    "    target_test_dataset, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import convert the target domain data into unlabelled and labelled datasets. \n",
    "\n",
    "We use a stratified split for all classes, converting 10%/20% of the target domain samples into labelled data and then adding them to the source domain dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset_20 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "unlabeled_dataset_20.load_from_image_dataset(target_train_dataset)\n",
    "\n",
    "to_be_unlabeled_dataset_20, labeled_dataset_20 = lib.data.stratified_split(\n",
    "    target_train_dataset, test_size=0.2\n",
    ")\n",
    "\n",
    "unlabeled_dataset_20 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=labeled_dataset_20.parser_func,\n",
    "    preprocessing_func=labeled_dataset_20.preprocessing_func,\n",
    ")\n",
    "unlabeled_dataset_20.load_from_image_dataset(to_be_unlabeled_dataset_20)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in source_train_dataset.samples:\n",
    "    labeled_dataset_20.add(sample_img, sample_label)\n",
    "\n",
    "len(labeled_dataset_20), len(source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_unlabeled_dataset_10, labeled_dataset_10 = lib.data.stratified_split(\n",
    "    target_train_dataset, test_size=0.1\n",
    ")\n",
    "\n",
    "unlabeled_dataset_10 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=labeled_dataset_10.parser_func,\n",
    "    preprocessing_func=labeled_dataset_20.preprocessing_func,\n",
    ")\n",
    "unlabeled_dataset_10.load_from_image_dataset(to_be_unlabeled_dataset_10)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in source_train_dataset.samples:\n",
    "    labeled_dataset_10.add(sample_img, sample_label)\n",
    "\n",
    "len(labeled_dataset_10), len(source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = source_train_dataset.label_encoder.classes_\n",
    "\n",
    "office_encodings = {\n",
    "    label: class_name\n",
    "    for label, class_name in enumerate(source_train_dataset.label_encoder.classes_)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source-only model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the ResNet-18 model, pre-trained on the ImageNet dataset. \n",
    "\n",
    "From our experience, keeping the pre-trained classification head of 1000 classes actually significantly speeds up training and avoids overfitting. Thus, we do not replace it with our own 31-class dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "#https://arxiv.org/pdf/2405.13698\n",
    "# disable lr for adam\n",
    "exp_lr_scheduler = None\n",
    "\n",
    "torchinfo.summary(tasks.utils.get_model(device=device), input_size=(BATCH_SIZE, 3, 1500, 1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finetune the pretrained model on the source domain dataset (Amazon domain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if FINETUNE_SOURCE_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_SOURCE__MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(FINETUNED_SOURCE__MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        source_train_loader,\n",
    "        source_val_loader,\n",
    "        output_dir=FINETUNED_SOURCE__MODEL_DIR,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(FINETUNED_SOURCE__MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_SOURCE__MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And print the learning curves as well as the classification results on both source and target domain test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that our baseline, the source-only model, can not effectively distinguish between any of the classes (except for the first few)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target only model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure described above is repeated for the model trained on the target domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device, replace_fc_layer=True, num_classes=len(office_encodings))\n",
    "\n",
    "if FINETUNE_TARGET_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_TARGET_MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=10e-2)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(FINETUNED_TARGET_MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        target_train_loader,\n",
    "        target_val_loader,\n",
    "        output_dir=FINETUNED_TARGET_MODEL_DIR,\n",
    "        num_epochs=100,\n",
    "        patience=10,\n",
    "        warmup_period=25,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=20000,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(FINETUNED_TARGET_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_TARGET_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, there is no way we can effectively train the target-only model which was supposed to be our baseline. \n",
    "Due to the low number of datapoints and the difficulty of the domain, it immediately overfits. No amount of increasing regularization\n",
    "(such as AdamW with weight_decay=$10^{-2}$) seems to influence the results. Additionally, we can not use data augmentation, since that\n",
    "would make the comparison between models unfair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORAL Source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device, replace_fc_layer=True, num_classes=len(office_encodings))\n",
    "\n",
    "if TRAIN_CORAL_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(CORAL_SOURCE_MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=10e-2)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.coral_train.coral_train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        source_train_dataloader=source_train_loader,\n",
    "        source_val_dataloader=source_val_loader,\n",
    "        target_train_dataloader=target_train_loader,\n",
    "        output_dir=CORAL_SOURCE_MODEL_DIR,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(CORAL_SOURCE_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Domain Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained and evaluated our baselines, we can begin experimenting with the incremental learning procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if TRAIN_UNSUPERVISED_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(FINETUNED_SOURCE__MODEL_DIR, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=source_train_dataset,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_20,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=UNSUPERVISED_MODEL_DIR,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "            verbose=False,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, UNSUPERVISED_MODEL_DIR)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, office_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised domain adaptation: 10% target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if FINETUNE_SEMI_SUPERVISED_MODEL_10:\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"model.pt\"))\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            labeled_dataset_10, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=source_val_loader,\n",
    "        output_dir=SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10,\n",
    "        num_epochs=25,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        previous_history=None,\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if TRAIN_SEMI_SUPERVISED_MODEL_10:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"model.pt\"))\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=labeled_dataset_10,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=1, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_10,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=None,\n",
    "            previous_target_history=None,\n",
    "            verbose=False\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, office_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised domain adaptation: 20% target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if FINETUNE_SEMI_SUPERVISED_MODEL_20:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20, \"model.pt\"))\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            labeled_dataset_20, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=source_val_loader,\n",
    "        output_dir=SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20,\n",
    "        num_epochs=25,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        previous_history=history\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device)\n",
    "\n",
    "if TRAIN_SEMI_SUPERVISED_MODEL_20:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20, \"model.pt\"))\n",
    "    optimizer_ft = optim.Adam(model.parameters())\n",
    "\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=labeled_dataset_20,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, sampler=sampler, shuffle=False\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_20,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "            verbose=False\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, office_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST/MNIST-M dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is near-identical to the one running the models on the Modern Office-31 dataset. \n",
    "\n",
    "* We slightly change hyperparameters because of the different nature of the dataset (batch size, $\\rho$, weight decay...)\n",
    "* We change the optimizer from Adam to AdamW (since the second implements weight decay in a mathematically correct manner)\n",
    "* We swap the classification head from the 1000 classes to 10 since:\n",
    "    * There is no correlation between the MNIST and ImageNet classes\n",
    "    * It makes the model smaller and thus harder to overfit, which is likely given the comparatively easier task of MNIST classification\n",
    "* We do not use pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "WEIGHT_DECAY = 10e-6\n",
    "RHO = 2.5\n",
    "SAMPLING_PERIOD = 7\n",
    "\n",
    "AD_DATA_DIR = \"data/digits\"\n",
    "AD_OUTPUT_DIR = \"output/digits\"\n",
    "\n",
    "AD_SOURCE_DATASET = \"mnist\"\n",
    "AD_TARGET_DATASET = \"mnist-m\"\n",
    "\n",
    "AD_FINETUNED_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"classifier\")\n",
    "AD_FINETUNED_TARGET_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"target_classifier\")\n",
    "AD_UNSUPERVISED_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"unsupervised\")\n",
    "AD_CORAL_SOURCE_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"coral\")\n",
    "AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_LARGE = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-finetuned-large\")\n",
    "AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_LARGE = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-adaptive-large\")\n",
    "AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-finetuned-small\")\n",
    "AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-adaptive-small\")\n",
    "\n",
    "AD_FINETUNE_MODEL = False\n",
    "AD_FINETUNE_TARGET_MODEL = False\n",
    "AD_FINETUNE_CORAL_MODEL = False\n",
    "AD_TRAIN_UNSUPERVISED_MODEL = False\n",
    "AD_FINETUNE_SEMI_SUPERVISED_MODEL_LARGE = True\n",
    "AD_TRAIN_SEMI_SUPERVISED_MODEL_LARGE = True\n",
    "AD_FINETUNE_SEMI_SUPERVISED_MODEL_SMALL = True\n",
    "AD_TRAIN_SEMI_SUPERVISED_MODEL_SMALL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf8cd405ea4031b527029204c28752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad_source_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "ad_source_dataset.load_from_directory(os.path.join(AD_DATA_DIR, AD_SOURCE_DATASET))\n",
    "\n",
    "ad_source_train_dataset, ad_source_val_dataset, ad_source_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        ad_source_dataset, SOURCE_VAL_SPLIT, SOURCE_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "ad_source_train_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_source_train_dataset, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "ad_source_val_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_source_val_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")\n",
    "ad_source_test_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_source_test_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf21efb5c7954de7a0f46fd664c2a900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad_target_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    "    label_encoder=ad_source_dataset.label_encoder,  # use same classes\n",
    ")\n",
    "ad_target_dataset.load_from_directory(os.path.join(AD_DATA_DIR, AD_TARGET_DATASET))\n",
    "\n",
    "ad_target_train_dataset, ad_target_val_dataset, ad_target_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        ad_target_dataset, TARGET_VAL_SPLIT, TARGET_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "ad_target_train_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_target_train_dataset, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "ad_target_val_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_target_val_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")\n",
    "ad_target_test_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    ad_target_test_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_unlabeled_dataset = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "ad_unlabeled_dataset.load_from_image_dataset(ad_target_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52601, 52500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_to_be_unlabeled_dataset_small, ad_labeled_dataset_small = lib.data.stratified_split(\n",
    "    ad_target_train_dataset, test_size=100/len(ad_target_train_dataset)\n",
    ")\n",
    "\n",
    "ad_unlabeled_dataset_small = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=ad_labeled_dataset_small.parser_func,\n",
    "    preprocessing_func=ad_source_dataset.preprocessing_func,\n",
    ")\n",
    "ad_unlabeled_dataset_small.load_from_image_dataset(ad_to_be_unlabeled_dataset_small)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in ad_source_train_dataset.samples:\n",
    "    ad_labeled_dataset_small.add(sample_img, sample_label)\n",
    "\n",
    "len(ad_labeled_dataset_small), len(ad_source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52735, 52500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_unlabeled_dataset_large = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "ad_unlabeled_dataset_large.load_from_image_dataset(ad_target_train_dataset)\n",
    "\n",
    "ad_to_be_unlabeled_dataset_large, ad_labeled_dataset_large = lib.data.stratified_split(\n",
    "    ad_target_train_dataset, test_size=0.005\n",
    ")\n",
    "\n",
    "ad_unlabeled_dataset_large = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=ad_labeled_dataset_large.parser_func,\n",
    "    preprocessing_func=ad_labeled_dataset_large.preprocessing_func,\n",
    ")\n",
    "ad_unlabeled_dataset_large.load_from_image_dataset(ad_to_be_unlabeled_dataset_large)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in ad_source_train_dataset.samples:\n",
    "    ad_labeled_dataset_large.add(sample_img, sample_label)\n",
    "\n",
    "len(ad_labeled_dataset_large), len(ad_source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ad_source_train_dataset.label_encoder.classes_\n",
    "\n",
    "mnist_encodings = {\n",
    "    label: class_name\n",
    "    for label, class_name in enumerate(ad_source_train_dataset.label_encoder.classes_)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dimits/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [16, 10]                  --\n",
       "├─Conv2d: 1-1                            [16, 64, 15, 15]          9,408\n",
       "├─BatchNorm2d: 1-2                       [16, 64, 15, 15]          128\n",
       "├─ReLU: 1-3                              [16, 64, 15, 15]          --\n",
       "├─MaxPool2d: 1-4                         [16, 64, 8, 8]            --\n",
       "├─Sequential: 1-5                        [16, 64, 8, 8]            --\n",
       "│    └─BasicBlock: 2-1                   [16, 64, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-1                  [16, 64, 8, 8]            36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [16, 64, 8, 8]            128\n",
       "│    │    └─ReLU: 3-3                    [16, 64, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-4                  [16, 64, 8, 8]            36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [16, 64, 8, 8]            128\n",
       "│    │    └─ReLU: 3-6                    [16, 64, 8, 8]            --\n",
       "│    └─BasicBlock: 2-2                   [16, 64, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-7                  [16, 64, 8, 8]            36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [16, 64, 8, 8]            128\n",
       "│    │    └─ReLU: 3-9                    [16, 64, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-10                 [16, 64, 8, 8]            36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [16, 64, 8, 8]            128\n",
       "│    │    └─ReLU: 3-12                   [16, 64, 8, 8]            --\n",
       "├─Sequential: 1-6                        [16, 128, 4, 4]           --\n",
       "│    └─BasicBlock: 2-3                   [16, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-13                 [16, 128, 4, 4]           73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [16, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-15                   [16, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-16                 [16, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [16, 128, 4, 4]           256\n",
       "│    │    └─Sequential: 3-18             [16, 128, 4, 4]           8,448\n",
       "│    │    └─ReLU: 3-19                   [16, 128, 4, 4]           --\n",
       "│    └─BasicBlock: 2-4                   [16, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-20                 [16, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [16, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-22                   [16, 128, 4, 4]           --\n",
       "│    │    └─Conv2d: 3-23                 [16, 128, 4, 4]           147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [16, 128, 4, 4]           256\n",
       "│    │    └─ReLU: 3-25                   [16, 128, 4, 4]           --\n",
       "├─Sequential: 1-7                        [16, 256, 2, 2]           --\n",
       "│    └─BasicBlock: 2-5                   [16, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-26                 [16, 256, 2, 2]           294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [16, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-28                   [16, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-29                 [16, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [16, 256, 2, 2]           512\n",
       "│    │    └─Sequential: 3-31             [16, 256, 2, 2]           33,280\n",
       "│    │    └─ReLU: 3-32                   [16, 256, 2, 2]           --\n",
       "│    └─BasicBlock: 2-6                   [16, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-33                 [16, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [16, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-35                   [16, 256, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-36                 [16, 256, 2, 2]           589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [16, 256, 2, 2]           512\n",
       "│    │    └─ReLU: 3-38                   [16, 256, 2, 2]           --\n",
       "├─Sequential: 1-8                        [16, 512, 1, 1]           --\n",
       "│    └─BasicBlock: 2-7                   [16, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-39                 [16, 512, 1, 1]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [16, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-41                   [16, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-42                 [16, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [16, 512, 1, 1]           1,024\n",
       "│    │    └─Sequential: 3-44             [16, 512, 1, 1]           132,096\n",
       "│    │    └─ReLU: 3-45                   [16, 512, 1, 1]           --\n",
       "│    └─BasicBlock: 2-8                   [16, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-46                 [16, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [16, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-48                   [16, 512, 1, 1]           --\n",
       "│    │    └─Conv2d: 3-49                 [16, 512, 1, 1]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [16, 512, 1, 1]           1,024\n",
       "│    │    └─ReLU: 3-51                   [16, 512, 1, 1]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [16, 512, 1, 1]           --\n",
       "├─Linear: 1-10                           [16, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 11,181,642\n",
       "Trainable params: 11,181,642\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 587.75\n",
       "==========================================================================================\n",
       "Input size (MB): 0.17\n",
       "Forward/backward pass size (MB): 12.47\n",
       "Params size (MB): 44.73\n",
       "Estimated Total Size (MB): 57.37\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "#https://arxiv.org/pdf/2405.13698\n",
    "# disable lr for adam\n",
    "exp_lr_scheduler = None\n",
    "\n",
    "\n",
    "torchinfo.summary(tasks.utils.get_model(device=device,\n",
    "                                        replace_fc_layer=True,\n",
    "                                        num_classes=len(mnist_encodings)),\n",
    "                                        input_size=(BATCH_SIZE, 3, 30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device,\n",
    "                            replace_fc_layer=True,\n",
    "                            num_classes=len(mnist_encodings),\n",
    "                            use_default_weights=False)\n",
    "\n",
    "if AD_FINETUNE_MODEL:\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_FINETUNED_MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        ad_source_train_loader,\n",
    "        ad_source_val_loader,\n",
    "        output_dir=AD_FINETUNED_MODEL_DIR,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        warmup_period=1,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_FINETUNED_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device, replace_fc_layer=True, num_classes=len(mnist_encodings))\n",
    "\n",
    "if AD_FINETUNE_CORAL_MODEL:\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        ad_target_train_loader,\n",
    "        ad_target_val_loader,\n",
    "        output_dir=AD_CORAL_SOURCE_MODEL_DIR,\n",
    "        num_epochs=15,\n",
    "        patience=3,\n",
    "        warmup_period=1,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORAL Source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(device=device, replace_fc_layer=True, num_classes=len(mnist_encodings))\n",
    "\n",
    "if AD_FINETUNE_CORAL_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model, history = lib.coral_train.coral_train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        source_train_dataloader=ad_source_train_loader,\n",
    "        source_val_dataloader=ad_source_val_loader,\n",
    "        target_train_dataloader=ad_target_train_loader,\n",
    "        output_dir=AD_CORAL_SOURCE_MODEL_DIR,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        gradient_accumulation=1,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_CORAL_SOURCE_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")\n",
    "\n",
    "if AD_TRAIN_UNSUPERVISED_MODEL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=ad_source_train_dataset,\n",
    "            source_val_dataset=ad_source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            # we can not use padding with unlabeled data\n",
    "            unlabeled_dataloader_initializer=lambda dataset: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, shuffle=True, n_workers=8\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=ad_unlabeled_dataset,\n",
    "            target_val_dataset=ad_target_val_dataset,\n",
    "            output_dir=AD_UNSUPERVISED_MODEL_DIR,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "            verbose=False,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, AD_UNSUPERVISED_MODEL_DIR)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, mnist_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi Supervised Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")\n",
    "\n",
    "if AD_FINETUNE_SEMI_SUPERVISED_MODEL_SMALL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            ad_labeled_dataset_small, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=ad_source_val_loader,\n",
    "        output_dir=AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL,\n",
    "        num_epochs=1,\n",
    "        patience=2,\n",
    "        warmup_period=2,\n",
    "        previous_history=history,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dimits/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/159\n",
      "----------\n",
      "Selected 4164/46857 images on threshold 0.9219089799641847\n",
      "[('data/digits/mnist-m/7/00055384.png', 7), ('data/digits/mnist-m/7/00048135.png', 7), ('data/digits/mnist-m/7/00006908.png', 7), ('data/digits/mnist-m/2/00039203.png', 2), ('data/digits/mnist-m/6/00001582.png', 6), ('data/digits/mnist-m/2/00004339.png', 2), ('data/digits/mnist-m/2/00002510.png', 2), ('data/digits/mnist-m/0/00032946.png', 0), ('data/digits/mnist-m/3/00048426.png', 3), ('data/digits/mnist-m/2/00026341.png', 2), ('data/digits/mnist-m/7/00052791.png', 7), ('data/digits/mnist-m/7/00046265.png', 7), ('data/digits/mnist-m/7/00051916.png', 7), ('data/digits/mnist-m/8/00004582.png', 8), ('data/digits/mnist-m/7/00003361.png', 7), ('data/digits/mnist-m/0/00041696.png', 0), ('data/digits/mnist-m/8/00040364.png', 8), ('data/digits/mnist-m/8/00043532.png', 8), ('data/digits/mnist-m/7/00051409.png', 7), ('data/digits/mnist-m/7/00034178.png', 7), ('data/digits/mnist-m/2/00037989.png', 2), ('data/digits/mnist-m/7/00012206.png', 7), ('data/digits/mnist-m/2/00002457.png', 2), ('data/digits/mnist-m/3/00007336.png', 3), ('data/digits/mnist-m/6/00018772.png', 6), ('data/digits/mnist-m/7/00043337.png', 7), ('data/digits/mnist-m/2/00002133.png', 2), ('data/digits/mnist-m/6/00006128.png', 6), ('data/digits/mnist-m/7/00015340.png', 7), ('data/digits/mnist-m/7/00039760.png', 7), ('data/digits/mnist-m/7/00044367.png', 7), ('data/digits/mnist-m/2/00022641.png', 2), ('data/digits/mnist-m/7/00021915.png', 7), ('data/digits/mnist-m/6/00030444.png', 6), ('data/digits/mnist-m/2/00043743.png', 2), ('data/digits/mnist-m/0/00050434.png', 0), ('data/digits/mnist-m/7/00041851.png', 7), ('data/digits/mnist-m/2/00039470.png', 2), ('data/digits/mnist-m/7/00006853.png', 7), ('data/digits/mnist-m/7/00016514.png', 7), ('data/digits/mnist-m/7/00048250.png', 7), ('data/digits/mnist-m/7/00052484.png', 7), ('data/digits/mnist-m/6/00038431.png', 6), ('data/digits/mnist-m/3/00045655.png', 3), ('data/digits/mnist-m/5/00035171.png', 5), ('data/digits/mnist-m/7/00005728.png', 7), ('data/digits/mnist-m/7/00012067.png', 7), ('data/digits/mnist-m/2/00021683.png', 2), ('data/digits/mnist-m/0/00017048.png', 0), ('data/digits/mnist-m/7/00027976.png', 7), ('data/digits/mnist-m/2/00002699.png', 2), ('data/digits/mnist-m/7/00054681.png', 7), ('data/digits/mnist-m/6/00013759.png', 6), ('data/digits/mnist-m/6/00041869.png', 6), ('data/digits/mnist-m/6/00005040.png', 6), ('data/digits/mnist-m/2/00005217.png', 2), ('data/digits/mnist-m/7/00033280.png', 7), ('data/digits/mnist-m/7/00001522.png', 7), ('data/digits/mnist-m/7/00034233.png', 7), ('data/digits/mnist-m/2/00034620.png', 2), ('data/digits/mnist-m/7/00021904.png', 7), ('data/digits/mnist-m/2/00052637.png', 2), ('data/digits/mnist-m/7/00018020.png', 7), ('data/digits/mnist-m/2/00052118.png', 2), ('data/digits/mnist-m/7/00046618.png', 7), ('data/digits/mnist-m/3/00024748.png', 3), ('data/digits/mnist-m/7/00016437.png', 7), ('data/digits/mnist-m/2/00004144.png', 2), ('data/digits/mnist-m/7/00012348.png', 7), ('data/digits/mnist-m/0/00051980.png', 0), ('data/digits/mnist-m/3/00006226.png', 3), ('data/digits/mnist-m/7/00046031.png', 7), ('data/digits/mnist-m/6/00047064.png', 6), ('data/digits/mnist-m/0/00027735.png', 0), ('data/digits/mnist-m/7/00039989.png', 7), ('data/digits/mnist-m/7/00026076.png', 7), ('data/digits/mnist-m/7/00013767.png', 7), ('data/digits/mnist-m/0/00044448.png', 0), ('data/digits/mnist-m/7/00000911.png', 7), ('data/digits/mnist-m/0/00055651.png', 0), ('data/digits/mnist-m/1/00002997.png', 7), ('data/digits/mnist-m/5/00010192.png', 5), ('data/digits/mnist-m/5/00034082.png', 5), ('data/digits/mnist-m/2/00027331.png', 2), ('data/digits/mnist-m/7/00024975.png', 7), ('data/digits/mnist-m/2/00026461.png', 2), ('data/digits/mnist-m/7/00046671.png', 7), ('data/digits/mnist-m/2/00042792.png', 2), ('data/digits/mnist-m/2/00045819.png', 2), ('data/digits/mnist-m/7/00015909.png', 7), ('data/digits/mnist-m/6/00031268.png', 6), ('data/digits/mnist-m/1/00020319.png', 7), ('data/digits/mnist-m/7/00024503.png', 7), ('data/digits/mnist-m/2/00041997.png', 2), ('data/digits/mnist-m/8/00014495.png', 8), ('data/digits/mnist-m/0/00007607.png', 0), ('data/digits/mnist-m/7/00057572.png', 7), ('data/digits/mnist-m/3/00029104.png', 3), ('data/digits/mnist-m/2/00007554.png', 2), ('data/digits/mnist-m/8/00057238.png', 8), ('data/digits/mnist-m/7/00022351.png', 7), ('data/digits/mnist-m/7/00018969.png', 7), ('data/digits/mnist-m/3/00029913.png', 3), ('data/digits/mnist-m/6/00000140.png', 6), ('data/digits/mnist-m/2/00039840.png', 2), ('data/digits/mnist-m/5/00046675.png', 5), ('data/digits/mnist-m/7/00036762.png', 7), ('data/digits/mnist-m/7/00032620.png', 7), ('data/digits/mnist-m/2/00003305.png', 2), ('data/digits/mnist-m/2/00055137.png', 2), ('data/digits/mnist-m/0/00047000.png', 0), ('data/digits/mnist-m/6/00006509.png', 6), ('data/digits/mnist-m/0/00035343.png', 0), ('data/digits/mnist-m/2/00016810.png', 2), ('data/digits/mnist-m/6/00018432.png', 6), ('data/digits/mnist-m/6/00049293.png', 6), ('data/digits/mnist-m/7/00009198.png', 7), ('data/digits/mnist-m/7/00014439.png', 7), ('data/digits/mnist-m/6/00015431.png', 6), ('data/digits/mnist-m/2/00051001.png', 2), ('data/digits/mnist-m/0/00019117.png', 0), ('data/digits/mnist-m/0/00055617.png', 0), ('data/digits/mnist-m/7/00005768.png', 7), ('data/digits/mnist-m/7/00006752.png', 7), ('data/digits/mnist-m/7/00017114.png', 7), ('data/digits/mnist-m/7/00013786.png', 7), ('data/digits/mnist-m/2/00045412.png', 2), ('data/digits/mnist-m/2/00047612.png', 2), ('data/digits/mnist-m/7/00009267.png', 7), ('data/digits/mnist-m/2/00011977.png', 2), ('data/digits/mnist-m/7/00022300.png', 7), ('data/digits/mnist-m/6/00015529.png', 6), ('data/digits/mnist-m/0/00058521.png', 0), ('data/digits/mnist-m/7/00000522.png', 7), ('data/digits/mnist-m/5/00055775.png', 5), ('data/digits/mnist-m/7/00011421.png', 7), ('data/digits/mnist-m/7/00039069.png', 7), ('data/digits/mnist-m/2/00030811.png', 2), ('data/digits/mnist-m/0/00054690.png', 0), ('data/digits/mnist-m/2/00002464.png', 2), ('data/digits/mnist-m/7/00001699.png', 7), ('data/digits/mnist-m/7/00022016.png', 7), ('data/digits/mnist-m/2/00049191.png', 2), ('data/digits/mnist-m/2/00039939.png', 2), ('data/digits/mnist-m/2/00042539.png', 2), ('data/digits/mnist-m/2/00058103.png', 2), ('data/digits/mnist-m/6/00000940.png', 6), ('data/digits/mnist-m/0/00017770.png', 0), ('data/digits/mnist-m/7/00055409.png', 7), ('data/digits/mnist-m/5/00045947.png', 5), ('data/digits/mnist-m/7/00002967.png', 7), ('data/digits/mnist-m/7/00030313.png', 7), ('data/digits/mnist-m/2/00002495.png', 2), ('data/digits/mnist-m/5/00057251.png', 3), ('data/digits/mnist-m/7/00003463.png', 7), ('data/digits/mnist-m/8/00047122.png', 8), ('data/digits/mnist-m/0/00032336.png', 0), ('data/digits/mnist-m/7/00010989.png', 7), ('data/digits/mnist-m/2/00003924.png', 2), ('data/digits/mnist-m/2/00058945.png', 2), ('data/digits/mnist-m/7/00046765.png', 7), ('data/digits/mnist-m/7/00013789.png', 7), ('data/digits/mnist-m/2/00013406.png', 2), ('data/digits/mnist-m/2/00022990.png', 2), ('data/digits/mnist-m/7/00020312.png', 7), ('data/digits/mnist-m/2/00003921.png', 2), ('data/digits/mnist-m/2/00053585.png', 2), ('data/digits/mnist-m/3/00001941.png', 3), ('data/digits/mnist-m/0/00048176.png', 0), ('data/digits/mnist-m/6/00002002.png', 6), ('data/digits/mnist-m/7/00025693.png', 7), ('data/digits/mnist-m/7/00056679.png', 7), ('data/digits/mnist-m/5/00055554.png', 5), ('data/digits/mnist-m/2/00005480.png', 2), ('data/digits/mnist-m/7/00006953.png', 7), ('data/digits/mnist-m/0/00000473.png', 0), ('data/digits/mnist-m/7/00053183.png', 7), ('data/digits/mnist-m/7/00005640.png', 7), ('data/digits/mnist-m/8/00015879.png', 8), ('data/digits/mnist-m/2/00025672.png', 2), ('data/digits/mnist-m/8/00005257.png', 8), ('data/digits/mnist-m/0/00022657.png', 0), ('data/digits/mnist-m/7/00004545.png', 7), ('data/digits/mnist-m/0/00014722.png', 7), ('data/digits/mnist-m/7/00026916.png', 7), ('data/digits/mnist-m/6/00036893.png', 6), ('data/digits/mnist-m/0/00050026.png', 0), ('data/digits/mnist-m/7/00036411.png', 7), ('data/digits/mnist-m/7/00031725.png', 7), ('data/digits/mnist-m/2/00008611.png', 2), ('data/digits/mnist-m/0/00006835.png', 0), ('data/digits/mnist-m/7/00053839.png', 7), ('data/digits/mnist-m/8/00020559.png', 8), ('data/digits/mnist-m/2/00000076.png', 2), ('data/digits/mnist-m/7/00038890.png', 7), ('data/digits/mnist-m/3/00015077.png', 3), ('data/digits/mnist-m/7/00000728.png', 7), ('data/digits/mnist-m/3/00037397.png', 3), ('data/digits/mnist-m/7/00022220.png', 7), ('data/digits/mnist-m/2/00007555.png', 2), ('data/digits/mnist-m/7/00022950.png', 7), ('data/digits/mnist-m/2/00005772.png', 2), ('data/digits/mnist-m/8/00048192.png', 8), ('data/digits/mnist-m/8/00007218.png', 8), ('data/digits/mnist-m/3/00033000.png', 3), ('data/digits/mnist-m/0/00026371.png', 0), ('data/digits/mnist-m/7/00045188.png', 7), ('data/digits/mnist-m/2/00046266.png', 2), ('data/digits/mnist-m/3/00013242.png', 8), ('data/digits/mnist-m/2/00039772.png', 2), ('data/digits/mnist-m/2/00005438.png', 2), ('data/digits/mnist-m/9/00010102.png', 9), ('data/digits/mnist-m/7/00014448.png', 7), ('data/digits/mnist-m/7/00041009.png', 7), ('data/digits/mnist-m/9/00003292.png', 9), ('data/digits/mnist-m/6/00053606.png', 6), ('data/digits/mnist-m/6/00039455.png', 6), ('data/digits/mnist-m/2/00001064.png', 2), ('data/digits/mnist-m/7/00003308.png', 7), ('data/digits/mnist-m/3/00003949.png', 3), ('data/digits/mnist-m/3/00004595.png', 3), ('data/digits/mnist-m/7/00023381.png', 7), ('data/digits/mnist-m/7/00026721.png', 7), ('data/digits/mnist-m/7/00008480.png', 7), ('data/digits/mnist-m/7/00018950.png', 7), ('data/digits/mnist-m/2/00047270.png', 2), ('data/digits/mnist-m/2/00025238.png', 2), ('data/digits/mnist-m/7/00004151.png', 7), ('data/digits/mnist-m/0/00004241.png', 0), ('data/digits/mnist-m/7/00010392.png', 7), ('data/digits/mnist-m/7/00042427.png', 7), ('data/digits/mnist-m/7/00007504.png', 7), ('data/digits/mnist-m/3/00005850.png', 3), ('data/digits/mnist-m/5/00058117.png', 5), ('data/digits/mnist-m/2/00041966.png', 2), ('data/digits/mnist-m/7/00007701.png', 7), ('data/digits/mnist-m/2/00038417.png', 2), ('data/digits/mnist-m/2/00003830.png', 2), ('data/digits/mnist-m/7/00051011.png', 7), ('data/digits/mnist-m/6/00033434.png', 6), ('data/digits/mnist-m/6/00002337.png', 6), ('data/digits/mnist-m/6/00016976.png', 6), ('data/digits/mnist-m/2/00025459.png', 2), ('data/digits/mnist-m/7/00056604.png', 7), ('data/digits/mnist-m/8/00016274.png', 8), ('data/digits/mnist-m/0/00012748.png', 0), ('data/digits/mnist-m/7/00045657.png', 7), ('data/digits/mnist-m/7/00003609.png', 7), ('data/digits/mnist-m/2/00053239.png', 2), ('data/digits/mnist-m/3/00049188.png', 3), ('data/digits/mnist-m/3/00030175.png', 3), ('data/digits/mnist-m/7/00051166.png', 7), ('data/digits/mnist-m/6/00001831.png', 6), ('data/digits/mnist-m/8/00007433.png', 8), ('data/digits/mnist-m/0/00009035.png', 0), ('data/digits/mnist-m/5/00038325.png', 5), ('data/digits/mnist-m/7/00003640.png', 7), ('data/digits/mnist-m/0/00007703.png', 0), ('data/digits/mnist-m/0/00045066.png', 0), ('data/digits/mnist-m/6/00008996.png', 6), ('data/digits/mnist-m/8/00004468.png', 8), ('data/digits/mnist-m/7/00052436.png', 7), ('data/digits/mnist-m/2/00004345.png', 2), ('data/digits/mnist-m/7/00037657.png', 7), ('data/digits/mnist-m/2/00052869.png', 2), ('data/digits/mnist-m/0/00038808.png', 0), ('data/digits/mnist-m/6/00058133.png', 6), ('data/digits/mnist-m/3/00004983.png', 3), ('data/digits/mnist-m/3/00034364.png', 2), ('data/digits/mnist-m/5/00054053.png', 3), ('data/digits/mnist-m/2/00045929.png', 2), ('data/digits/mnist-m/8/00041132.png', 8), ('data/digits/mnist-m/0/00045504.png', 0), ('data/digits/mnist-m/7/00001171.png', 7), ('data/digits/mnist-m/2/00054574.png', 2), ('data/digits/mnist-m/2/00056540.png', 2), ('data/digits/mnist-m/2/00001210.png', 2), ('data/digits/mnist-m/7/00055799.png', 7), ('data/digits/mnist-m/2/00018499.png', 2), ('data/digits/mnist-m/7/00055613.png', 7), ('data/digits/mnist-m/2/00040279.png', 2), ('data/digits/mnist-m/0/00033732.png', 0), ('data/digits/mnist-m/3/00005193.png', 3), ('data/digits/mnist-m/7/00001117.png', 7), ('data/digits/mnist-m/2/00058032.png', 2), ('data/digits/mnist-m/7/00017833.png', 7), ('data/digits/mnist-m/7/00006006.png', 7), ('data/digits/mnist-m/4/00026855.png', 7), ('data/digits/mnist-m/6/00013712.png', 6), ('data/digits/mnist-m/7/00001547.png', 7), ('data/digits/mnist-m/2/00057416.png', 2), ('data/digits/mnist-m/7/00007439.png', 7), ('data/digits/mnist-m/7/00041026.png', 7), ('data/digits/mnist-m/5/00010987.png', 3), ('data/digits/mnist-m/2/00023705.png', 2), ('data/digits/mnist-m/7/00011553.png', 7), ('data/digits/mnist-m/7/00003804.png', 7), ('data/digits/mnist-m/5/00012016.png', 5), ('data/digits/mnist-m/6/00044690.png', 6), ('data/digits/mnist-m/0/00036712.png', 0), ('data/digits/mnist-m/0/00000750.png', 0), ('data/digits/mnist-m/0/00019857.png', 0), ('data/digits/mnist-m/3/00052385.png', 3), ('data/digits/mnist-m/5/00019162.png', 5), ('data/digits/mnist-m/3/00025896.png', 3), ('data/digits/mnist-m/0/00000485.png', 0), ('data/digits/mnist-m/7/00036748.png', 7), ('data/digits/mnist-m/3/00014624.png', 3), ('data/digits/mnist-m/2/00002664.png', 2), ('data/digits/mnist-m/7/00017136.png', 7), ('data/digits/mnist-m/0/00014820.png', 0), ('data/digits/mnist-m/7/00040681.png', 7), ('data/digits/mnist-m/7/00042269.png', 7), ('data/digits/mnist-m/7/00003575.png', 7), ('data/digits/mnist-m/7/00006105.png', 7), ('data/digits/mnist-m/0/00055666.png', 0), ('data/digits/mnist-m/7/00014519.png', 7), ('data/digits/mnist-m/2/00042887.png', 2), ('data/digits/mnist-m/7/00006947.png', 7), ('data/digits/mnist-m/7/00048893.png', 7), ('data/digits/mnist-m/2/00035104.png', 2), ('data/digits/mnist-m/7/00029806.png', 7), ('data/digits/mnist-m/3/00041629.png', 3), ('data/digits/mnist-m/6/00038299.png', 6), ('data/digits/mnist-m/7/00058912.png', 7), ('data/digits/mnist-m/7/00032584.png', 7), ('data/digits/mnist-m/2/00034462.png', 2), ('data/digits/mnist-m/2/00010417.png', 2), ('data/digits/mnist-m/5/00007577.png', 3), ('data/digits/mnist-m/0/00024345.png', 0), ('data/digits/mnist-m/2/00025148.png', 2), ('data/digits/mnist-m/7/00027872.png', 7), ('data/digits/mnist-m/2/00013313.png', 2), ('data/digits/mnist-m/8/00007777.png', 8), ('data/digits/mnist-m/7/00026982.png', 7), ('data/digits/mnist-m/7/00018469.png', 7), ('data/digits/mnist-m/7/00013158.png', 7), ('data/digits/mnist-m/7/00042418.png', 7), ('data/digits/mnist-m/7/00045215.png', 7), ('data/digits/mnist-m/5/00037551.png', 5), ('data/digits/mnist-m/5/00013021.png', 6), ('data/digits/mnist-m/2/00043122.png', 2), ('data/digits/mnist-m/5/00042509.png', 5), ('data/digits/mnist-m/7/00050129.png', 7), ('data/digits/mnist-m/0/00023108.png', 0), ('data/digits/mnist-m/2/00032590.png', 2), ('data/digits/mnist-m/7/00027881.png', 7), ('data/digits/mnist-m/6/00033934.png', 6), ('data/digits/mnist-m/0/00000458.png', 0), ('data/digits/mnist-m/2/00019031.png', 2), ('data/digits/mnist-m/7/00037556.png', 7), ('data/digits/mnist-m/7/00021482.png', 7), ('data/digits/mnist-m/7/00023551.png', 7), ('data/digits/mnist-m/6/00017408.png', 6), ('data/digits/mnist-m/2/00002205.png', 2), ('data/digits/mnist-m/6/00037829.png', 6), ('data/digits/mnist-m/7/00028880.png', 7), ('data/digits/mnist-m/7/00012526.png', 7), ('data/digits/mnist-m/6/00006024.png', 6), ('data/digits/mnist-m/7/00015705.png', 7), ('data/digits/mnist-m/2/00044021.png', 2), ('data/digits/mnist-m/8/00055026.png', 8), ('data/digits/mnist-m/6/00008850.png', 6), ('data/digits/mnist-m/2/00024546.png', 2), ('data/digits/mnist-m/7/00010427.png', 7), ('data/digits/mnist-m/7/00058571.png', 7), ('data/digits/mnist-m/7/00050795.png', 7), ('data/digits/mnist-m/7/00002825.png', 7), ('data/digits/mnist-m/2/00003064.png', 2), ('data/digits/mnist-m/6/00009446.png', 6), ('data/digits/mnist-m/7/00026568.png', 7), ('data/digits/mnist-m/2/00031354.png', 2), ('data/digits/mnist-m/5/00017886.png', 5), ('data/digits/mnist-m/2/00022335.png', 2), ('data/digits/mnist-m/7/00038743.png', 7), ('data/digits/mnist-m/6/00005279.png', 6), ('data/digits/mnist-m/7/00040436.png', 7), ('data/digits/mnist-m/2/00055972.png', 2), ('data/digits/mnist-m/3/00027022.png', 3), ('data/digits/mnist-m/7/00052669.png', 7), ('data/digits/mnist-m/3/00044380.png', 3), ('data/digits/mnist-m/0/00031272.png', 0), ('data/digits/mnist-m/9/00019256.png', 7), ('data/digits/mnist-m/7/00032347.png', 7), ('data/digits/mnist-m/7/00006316.png', 7), ('data/digits/mnist-m/2/00024752.png', 2), ('data/digits/mnist-m/0/00022254.png', 0), ('data/digits/mnist-m/7/00001734.png', 7), ('data/digits/mnist-m/7/00044595.png', 7), ('data/digits/mnist-m/2/00003880.png', 2), ('data/digits/mnist-m/8/00006297.png', 8), ('data/digits/mnist-m/6/00042154.png', 6), ('data/digits/mnist-m/7/00015906.png', 7), ('data/digits/mnist-m/9/00005501.png', 7), ('data/digits/mnist-m/2/00008870.png', 2), ('data/digits/mnist-m/6/00018140.png', 6), ('data/digits/mnist-m/3/00042534.png', 3), ('data/digits/mnist-m/3/00057131.png', 3), ('data/digits/mnist-m/7/00048768.png', 7), ('data/digits/mnist-m/6/00002533.png', 6), ('data/digits/mnist-m/2/00025530.png', 2), ('data/digits/mnist-m/6/00028170.png', 6), ('data/digits/mnist-m/2/00000609.png', 2), ('data/digits/mnist-m/0/00034553.png', 0), ('data/digits/mnist-m/0/00042389.png', 0), ('data/digits/mnist-m/3/00017908.png', 3), ('data/digits/mnist-m/7/00056756.png', 7), ('data/digits/mnist-m/2/00046317.png', 2), ('data/digits/mnist-m/7/00003505.png', 7), ('data/digits/mnist-m/2/00042278.png', 2), ('data/digits/mnist-m/2/00052413.png', 2), ('data/digits/mnist-m/2/00028879.png', 2), ('data/digits/mnist-m/7/00043052.png', 7), ('data/digits/mnist-m/0/00042250.png', 0), ('data/digits/mnist-m/7/00044145.png', 7), ('data/digits/mnist-m/8/00039778.png', 8), ('data/digits/mnist-m/7/00047221.png', 7), ('data/digits/mnist-m/6/00005441.png', 6), ('data/digits/mnist-m/6/00042370.png', 6), ('data/digits/mnist-m/5/00045567.png', 5), ('data/digits/mnist-m/2/00050543.png', 2), ('data/digits/mnist-m/2/00026638.png', 2), ('data/digits/mnist-m/6/00022215.png', 6), ('data/digits/mnist-m/7/00000086.png', 7), ('data/digits/mnist-m/7/00055090.png', 7), ('data/digits/mnist-m/8/00000538.png', 8), ('data/digits/mnist-m/7/00034690.png', 7), ('data/digits/mnist-m/7/00050849.png', 7), ('data/digits/mnist-m/2/00016269.png', 2), ('data/digits/mnist-m/6/00030950.png', 6), ('data/digits/mnist-m/7/00013421.png', 7), ('data/digits/mnist-m/0/00047820.png', 0), ('data/digits/mnist-m/7/00020301.png', 7), ('data/digits/mnist-m/7/00039060.png', 7), ('data/digits/mnist-m/7/00006623.png', 7), ('data/digits/mnist-m/3/00006322.png', 3), ('data/digits/mnist-m/7/00032820.png', 7), ('data/digits/mnist-m/2/00044226.png', 2), ('data/digits/mnist-m/7/00005512.png', 7), ('data/digits/mnist-m/7/00020189.png', 7), ('data/digits/mnist-m/2/00006225.png', 2), ('data/digits/mnist-m/7/00002115.png', 7), ('data/digits/mnist-m/8/00013004.png', 8), ('data/digits/mnist-m/2/00004962.png', 2), ('data/digits/mnist-m/8/00025205.png', 8), ('data/digits/mnist-m/3/00003947.png', 3), ('data/digits/mnist-m/7/00023267.png', 7), ('data/digits/mnist-m/3/00034268.png', 3), ('data/digits/mnist-m/7/00018691.png', 7), ('data/digits/mnist-m/7/00011372.png', 7), ('data/digits/mnist-m/7/00021021.png', 7), ('data/digits/mnist-m/6/00014147.png', 6), ('data/digits/mnist-m/3/00003057.png', 3), ('data/digits/mnist-m/8/00045913.png', 8), ('data/digits/mnist-m/2/00041579.png', 2), ('data/digits/mnist-m/2/00026006.png', 2), ('data/digits/mnist-m/7/00008926.png', 7), ('data/digits/mnist-m/0/00019856.png', 0), ('data/digits/mnist-m/3/00007672.png', 3), ('data/digits/mnist-m/7/00038972.png', 7), ('data/digits/mnist-m/7/00017031.png', 7), ('data/digits/mnist-m/7/00000683.png', 7), ('data/digits/mnist-m/2/00058928.png', 2), ('data/digits/mnist-m/6/00037334.png', 6), ('data/digits/mnist-m/2/00039592.png', 2), ('data/digits/mnist-m/2/00039518.png', 2), ('data/digits/mnist-m/6/00004416.png', 6), ('data/digits/mnist-m/0/00008619.png', 0), ('data/digits/mnist-m/0/00014034.png', 0), ('data/digits/mnist-m/7/00017113.png', 7), ('data/digits/mnist-m/7/00017373.png', 7), ('data/digits/mnist-m/2/00045420.png', 2), ('data/digits/mnist-m/2/00050581.png', 2), ('data/digits/mnist-m/2/00003077.png', 2), ('data/digits/mnist-m/3/00045171.png', 3), ('data/digits/mnist-m/2/00043994.png', 2), ('data/digits/mnist-m/5/00000857.png', 5), ('data/digits/mnist-m/7/00019270.png', 7), ('data/digits/mnist-m/7/00005808.png', 7), ('data/digits/mnist-m/2/00038935.png', 2), ('data/digits/mnist-m/2/00045096.png', 2), ('data/digits/mnist-m/6/00026252.png', 6), ('data/digits/mnist-m/7/00022018.png', 7), ('data/digits/mnist-m/0/00053407.png', 0), ('data/digits/mnist-m/7/00002391.png', 7), ('data/digits/mnist-m/2/00005264.png', 2), ('data/digits/mnist-m/7/00056121.png', 7), ('data/digits/mnist-m/2/00016729.png', 2), ('data/digits/mnist-m/2/00002726.png', 2), ('data/digits/mnist-m/2/00021511.png', 2), ('data/digits/mnist-m/4/00014411.png', 7), ('data/digits/mnist-m/7/00022754.png', 7), ('data/digits/mnist-m/1/00039169.png', 7), ('data/digits/mnist-m/8/00006372.png', 8), ('data/digits/mnist-m/7/00010965.png', 7), ('data/digits/mnist-m/5/00042431.png', 5), ('data/digits/mnist-m/3/00024969.png', 3), ('data/digits/mnist-m/7/00049069.png', 7), ('data/digits/mnist-m/0/00056512.png', 0), ('data/digits/mnist-m/8/00055697.png', 8), ('data/digits/mnist-m/6/00038659.png', 6), ('data/digits/mnist-m/7/00052092.png', 7), ('data/digits/mnist-m/2/00029611.png', 2), ('data/digits/mnist-m/7/00054426.png', 7), ('data/digits/mnist-m/7/00036365.png', 7), ('data/digits/mnist-m/0/00004957.png', 0), ('data/digits/mnist-m/6/00037675.png', 6), ('data/digits/mnist-m/2/00005965.png', 2), ('data/digits/mnist-m/3/00001315.png', 3), ('data/digits/mnist-m/2/00052408.png', 2), ('data/digits/mnist-m/5/00032052.png', 5), ('data/digits/mnist-m/0/00013044.png', 0), ('data/digits/mnist-m/7/00003589.png', 7), ('data/digits/mnist-m/0/00002257.png', 0), ('data/digits/mnist-m/6/00055379.png', 6), ('data/digits/mnist-m/2/00042014.png', 2), ('data/digits/mnist-m/8/00022201.png', 8), ('data/digits/mnist-m/0/00026980.png', 0), ('data/digits/mnist-m/7/00032028.png', 7), ('data/digits/mnist-m/5/00005021.png', 5), ('data/digits/mnist-m/2/00013452.png', 7), ('data/digits/mnist-m/7/00027360.png', 7), ('data/digits/mnist-m/7/00038711.png', 7), ('data/digits/mnist-m/2/00043815.png', 2), ('data/digits/mnist-m/0/00023557.png', 0), ('data/digits/mnist-m/7/00004747.png', 7), ('data/digits/mnist-m/2/00012238.png', 2), ('data/digits/mnist-m/7/00050894.png', 7), ('data/digits/mnist-m/3/00018612.png', 3), ('data/digits/mnist-m/7/00029002.png', 7), ('data/digits/mnist-m/7/00016630.png', 7), ('data/digits/mnist-m/3/00010453.png', 3), ('data/digits/mnist-m/6/00028001.png', 6), ('data/digits/mnist-m/7/00002650.png', 7), ('data/digits/mnist-m/7/00018784.png', 7), ('data/digits/mnist-m/3/00017676.png', 3), ('data/digits/mnist-m/2/00002429.png', 2), ('data/digits/mnist-m/7/00021603.png', 7), ('data/digits/mnist-m/3/00005555.png', 3), ('data/digits/mnist-m/7/00007352.png', 7), ('data/digits/mnist-m/2/00001255.png', 2), ('data/digits/mnist-m/7/00003228.png', 7), ('data/digits/mnist-m/7/00035176.png', 7), ('data/digits/mnist-m/7/00002240.png', 7), ('data/digits/mnist-m/8/00053885.png', 8), ('data/digits/mnist-m/7/00058899.png', 7), ('data/digits/mnist-m/7/00001660.png', 7), ('data/digits/mnist-m/0/00021242.png', 0), ('data/digits/mnist-m/6/00047265.png', 6), ('data/digits/mnist-m/7/00036334.png', 7), ('data/digits/mnist-m/0/00033192.png', 0), ('data/digits/mnist-m/8/00028587.png', 7), ('data/digits/mnist-m/7/00052124.png', 7), ('data/digits/mnist-m/6/00035888.png', 6), ('data/digits/mnist-m/7/00048952.png', 7), ('data/digits/mnist-m/2/00022930.png', 2), ('data/digits/mnist-m/3/00044478.png', 3), ('data/digits/mnist-m/2/00001727.png', 2), ('data/digits/mnist-m/7/00005575.png', 7), ('data/digits/mnist-m/7/00058092.png', 7), ('data/digits/mnist-m/2/00002518.png', 2), ('data/digits/mnist-m/2/00041181.png', 2), ('data/digits/mnist-m/2/00028275.png', 2), ('data/digits/mnist-m/2/00008648.png', 2), ('data/digits/mnist-m/7/00037215.png', 7), ('data/digits/mnist-m/3/00017062.png', 3), ('data/digits/mnist-m/6/00003979.png', 6), ('data/digits/mnist-m/8/00039242.png', 8), ('data/digits/mnist-m/7/00038954.png', 7), ('data/digits/mnist-m/0/00005886.png', 0), ('data/digits/mnist-m/2/00008129.png', 2), ('data/digits/mnist-m/2/00010959.png', 2), ('data/digits/mnist-m/7/00050075.png', 7), ('data/digits/mnist-m/7/00051636.png', 7), ('data/digits/mnist-m/7/00005504.png', 7), ('data/digits/mnist-m/7/00040018.png', 7), ('data/digits/mnist-m/8/00039011.png', 8), ('data/digits/mnist-m/0/00021299.png', 0), ('data/digits/mnist-m/2/00047083.png', 2), ('data/digits/mnist-m/2/00040212.png', 2), ('data/digits/mnist-m/2/00051506.png', 2), ('data/digits/mnist-m/8/00007265.png', 8), ('data/digits/mnist-m/0/00003371.png', 0), ('data/digits/mnist-m/2/00016772.png', 2), ('data/digits/mnist-m/7/00014926.png', 7), ('data/digits/mnist-m/7/00046607.png', 7), ('data/digits/mnist-m/6/00031054.png', 6), ('data/digits/mnist-m/7/00039276.png', 7), ('data/digits/mnist-m/7/00058848.png', 7), ('data/digits/mnist-m/6/00006782.png', 6), ('data/digits/mnist-m/7/00007032.png', 7), ('data/digits/mnist-m/2/00001679.png', 2), ('data/digits/mnist-m/0/00038559.png', 3), ('data/digits/mnist-m/6/00021838.png', 6), ('data/digits/mnist-m/7/00004295.png', 7), ('data/digits/mnist-m/7/00027723.png', 7), ('data/digits/mnist-m/8/00040571.png', 8), ('data/digits/mnist-m/7/00027059.png', 7), ('data/digits/mnist-m/0/00021975.png', 0), ('data/digits/mnist-m/0/00001807.png', 0), ('data/digits/mnist-m/7/00001833.png', 7), ('data/digits/mnist-m/6/00044189.png', 6), ('data/digits/mnist-m/8/00003866.png', 8), ('data/digits/mnist-m/7/00057286.png', 7), ('data/digits/mnist-m/7/00051162.png', 7), ('data/digits/mnist-m/3/00005621.png', 3), ('data/digits/mnist-m/7/00015545.png', 7), ('data/digits/mnist-m/8/00035072.png', 8), ('data/digits/mnist-m/2/00030663.png', 2), ('data/digits/mnist-m/7/00046636.png', 7), ('data/digits/mnist-m/0/00038744.png', 0), ('data/digits/mnist-m/8/00055578.png', 8), ('data/digits/mnist-m/7/00025597.png', 7), ('data/digits/mnist-m/6/00003923.png', 6), ('data/digits/mnist-m/6/00037142.png', 6), ('data/digits/mnist-m/2/00055183.png', 2), ('data/digits/mnist-m/7/00004875.png', 7), ('data/digits/mnist-m/2/00052784.png', 2), ('data/digits/mnist-m/6/00028934.png', 6), ('data/digits/mnist-m/7/00056064.png', 7), ('data/digits/mnist-m/7/00000676.png', 7), ('data/digits/mnist-m/2/00028336.png', 2), ('data/digits/mnist-m/8/00054216.png', 8), ('data/digits/mnist-m/7/00039314.png', 7), ('data/digits/mnist-m/7/00047262.png', 7), ('data/digits/mnist-m/2/00046463.png', 2), ('data/digits/mnist-m/8/00008933.png', 8), ('data/digits/mnist-m/5/00015794.png', 5), ('data/digits/mnist-m/7/00050942.png', 7), ('data/digits/mnist-m/7/00001208.png', 7), ('data/digits/mnist-m/3/00045822.png', 3), ('data/digits/mnist-m/9/00057880.png', 7), ('data/digits/mnist-m/0/00016540.png', 0), ('data/digits/mnist-m/2/00020832.png', 2), ('data/digits/mnist-m/2/00034558.png', 2), ('data/digits/mnist-m/2/00010122.png', 2), ('data/digits/mnist-m/7/00047504.png', 7), ('data/digits/mnist-m/7/00056482.png', 7), ('data/digits/mnist-m/7/00002578.png', 7), ('data/digits/mnist-m/8/00006629.png', 8), ('data/digits/mnist-m/6/00004526.png', 6), ('data/digits/mnist-m/2/00006844.png', 2), ('data/digits/mnist-m/6/00046750.png', 6), ('data/digits/mnist-m/6/00004908.png', 6), ('data/digits/mnist-m/6/00035614.png', 6), ('data/digits/mnist-m/7/00000262.png', 7), ('data/digits/mnist-m/3/00030131.png', 3), ('data/digits/mnist-m/7/00028012.png', 7), ('data/digits/mnist-m/7/00004266.png', 7), ('data/digits/mnist-m/7/00001789.png', 7), ('data/digits/mnist-m/7/00029661.png', 7), ('data/digits/mnist-m/7/00047416.png', 7), ('data/digits/mnist-m/8/00012904.png', 8), ('data/digits/mnist-m/2/00035454.png', 2), ('data/digits/mnist-m/7/00000824.png', 7), ('data/digits/mnist-m/7/00018346.png', 7), ('data/digits/mnist-m/7/00057196.png', 7), ('data/digits/mnist-m/9/00030825.png', 7), ('data/digits/mnist-m/6/00057419.png', 6), ('data/digits/mnist-m/2/00004582.png', 2), ('data/digits/mnist-m/5/00037180.png', 5), ('data/digits/mnist-m/6/00054113.png', 6), ('data/digits/mnist-m/7/00002711.png', 7), ('data/digits/mnist-m/2/00039467.png', 2), ('data/digits/mnist-m/8/00025859.png', 8), ('data/digits/mnist-m/7/00005441.png', 7), ('data/digits/mnist-m/7/00041892.png', 7), ('data/digits/mnist-m/8/00028033.png', 8), ('data/digits/mnist-m/7/00023220.png', 7), ('data/digits/mnist-m/0/00002764.png', 0), ('data/digits/mnist-m/7/00011309.png', 7), ('data/digits/mnist-m/7/00019809.png', 7), ('data/digits/mnist-m/6/00023688.png', 6), ('data/digits/mnist-m/0/00028486.png', 0), ('data/digits/mnist-m/0/00003242.png', 0), ('data/digits/mnist-m/2/00001341.png', 2), ('data/digits/mnist-m/7/00030558.png', 7), ('data/digits/mnist-m/7/00006653.png', 7), ('data/digits/mnist-m/7/00002090.png', 7), ('data/digits/mnist-m/9/00007094.png', 9), ('data/digits/mnist-m/6/00048714.png', 6), ('data/digits/mnist-m/8/00010881.png', 8), ('data/digits/mnist-m/3/00049147.png', 3), ('data/digits/mnist-m/7/00017007.png', 7), ('data/digits/mnist-m/8/00002834.png', 8), ('data/digits/mnist-m/6/00023949.png', 6), ('data/digits/mnist-m/2/00037501.png', 2), ('data/digits/mnist-m/2/00005314.png', 2), ('data/digits/mnist-m/2/00054674.png', 2), ('data/digits/mnist-m/0/00000794.png', 0), ('data/digits/mnist-m/8/00029178.png', 8), ('data/digits/mnist-m/0/00049953.png', 0), ('data/digits/mnist-m/7/00012757.png', 7), ('data/digits/mnist-m/5/00055755.png', 5), ('data/digits/mnist-m/7/00006119.png', 7), ('data/digits/mnist-m/6/00045267.png', 6), ('data/digits/mnist-m/7/00044443.png', 7), ('data/digits/mnist-m/6/00032783.png', 6), ('data/digits/mnist-m/6/00018702.png', 6), ('data/digits/mnist-m/2/00004646.png', 2), ('data/digits/mnist-m/0/00000972.png', 0), ('data/digits/mnist-m/2/00000996.png', 2), ('data/digits/mnist-m/0/00053982.png', 0), ('data/digits/mnist-m/7/00029324.png', 7), ('data/digits/mnist-m/7/00041661.png', 7), ('data/digits/mnist-m/8/00019182.png', 8), ('data/digits/mnist-m/7/00024907.png', 7), ('data/digits/mnist-m/5/00003527.png', 3), ('data/digits/mnist-m/7/00034835.png', 7), ('data/digits/mnist-m/6/00053047.png', 6), ('data/digits/mnist-m/0/00005502.png', 0), ('data/digits/mnist-m/2/00003655.png', 2), ('data/digits/mnist-m/2/00053391.png', 2), ('data/digits/mnist-m/2/00050812.png', 2), ('data/digits/mnist-m/2/00011193.png', 2), ('data/digits/mnist-m/2/00031873.png', 2), ('data/digits/mnist-m/7/00006830.png', 7), ('data/digits/mnist-m/7/00012296.png', 7), ('data/digits/mnist-m/8/00016611.png', 8), ('data/digits/mnist-m/6/00018134.png', 6), ('data/digits/mnist-m/7/00002980.png', 7), ('data/digits/mnist-m/7/00004530.png', 7), ('data/digits/mnist-m/2/00027781.png', 2), ('data/digits/mnist-m/0/00022040.png', 0), ('data/digits/mnist-m/7/00023334.png', 7), ('data/digits/mnist-m/7/00028869.png', 7), ('data/digits/mnist-m/7/00029714.png', 7), ('data/digits/mnist-m/0/00013798.png', 0), ('data/digits/mnist-m/8/00029798.png', 8), ('data/digits/mnist-m/7/00007445.png', 7), ('data/digits/mnist-m/7/00002372.png', 7), ('data/digits/mnist-m/2/00026161.png', 2), ('data/digits/mnist-m/6/00022221.png', 6), ('data/digits/mnist-m/2/00010699.png', 2), ('data/digits/mnist-m/8/00028779.png', 8), ('data/digits/mnist-m/8/00033778.png', 8), ('data/digits/mnist-m/8/00013559.png', 8), ('data/digits/mnist-m/7/00001809.png', 7), ('data/digits/mnist-m/2/00030594.png', 2), ('data/digits/mnist-m/7/00022129.png', 7), ('data/digits/mnist-m/5/00026236.png', 5), ('data/digits/mnist-m/0/00053575.png', 0), ('data/digits/mnist-m/3/00021606.png', 7), ('data/digits/mnist-m/7/00056131.png', 7), ('data/digits/mnist-m/7/00043528.png', 7), ('data/digits/mnist-m/5/00049445.png', 5), ('data/digits/mnist-m/7/00005180.png', 7), ('data/digits/mnist-m/7/00028180.png', 7), ('data/digits/mnist-m/7/00051489.png', 7), ('data/digits/mnist-m/2/00037347.png', 2), ('data/digits/mnist-m/6/00003993.png', 6), ('data/digits/mnist-m/6/00013758.png', 6), ('data/digits/mnist-m/2/00003054.png', 2), ('data/digits/mnist-m/2/00028095.png', 2), ('data/digits/mnist-m/2/00040119.png', 2), ('data/digits/mnist-m/2/00003166.png', 2), ('data/digits/mnist-m/7/00017532.png', 7), ('data/digits/mnist-m/2/00009105.png', 2), ('data/digits/mnist-m/2/00058398.png', 2), ('data/digits/mnist-m/0/00006538.png', 0), ('data/digits/mnist-m/7/00002348.png', 7), ('data/digits/mnist-m/2/00005885.png', 2), ('data/digits/mnist-m/2/00022792.png', 2), ('data/digits/mnist-m/2/00010090.png', 2), ('data/digits/mnist-m/3/00015101.png', 3), ('data/digits/mnist-m/2/00020071.png', 2), ('data/digits/mnist-m/7/00020403.png', 7), ('data/digits/mnist-m/2/00018841.png', 2), ('data/digits/mnist-m/2/00058476.png', 2), ('data/digits/mnist-m/7/00025581.png', 7), ('data/digits/mnist-m/7/00030988.png', 7), ('data/digits/mnist-m/7/00034732.png', 7), ('data/digits/mnist-m/2/00004648.png', 2), ('data/digits/mnist-m/8/00058905.png', 8), ('data/digits/mnist-m/7/00055608.png', 7), ('data/digits/mnist-m/2/00057933.png', 2), ('data/digits/mnist-m/2/00000635.png', 2), ('data/digits/mnist-m/7/00009276.png', 7), ('data/digits/mnist-m/7/00052480.png', 7), ('data/digits/mnist-m/6/00050418.png', 6), ('data/digits/mnist-m/7/00055448.png', 7), ('data/digits/mnist-m/7/00020576.png', 7), ('data/digits/mnist-m/2/00001187.png', 2), ('data/digits/mnist-m/2/00001602.png', 2), ('data/digits/mnist-m/3/00047533.png', 3), ('data/digits/mnist-m/2/00038326.png', 2), ('data/digits/mnist-m/6/00007792.png', 6), ('data/digits/mnist-m/2/00027535.png', 2), ('data/digits/mnist-m/2/00013523.png', 2), ('data/digits/mnist-m/5/00001806.png', 5), ('data/digits/mnist-m/7/00029963.png', 7), ('data/digits/mnist-m/2/00019602.png', 2), ('data/digits/mnist-m/3/00025007.png', 3), ('data/digits/mnist-m/6/00009818.png', 6), ('data/digits/mnist-m/7/00017443.png', 7), ('data/digits/mnist-m/2/00007983.png', 2), ('data/digits/mnist-m/7/00053579.png', 7), ('data/digits/mnist-m/6/00014708.png', 6), ('data/digits/mnist-m/2/00034606.png', 2), ('data/digits/mnist-m/6/00047864.png', 6), ('data/digits/mnist-m/8/00003711.png', 8), ('data/digits/mnist-m/2/00010072.png', 2), ('data/digits/mnist-m/6/00012699.png', 6), ('data/digits/mnist-m/2/00053926.png', 2), ('data/digits/mnist-m/7/00005058.png', 7), ('data/digits/mnist-m/0/00002373.png', 0), ('data/digits/mnist-m/7/00039649.png', 7), ('data/digits/mnist-m/7/00018410.png', 7), ('data/digits/mnist-m/7/00053490.png', 7), ('data/digits/mnist-m/2/00003577.png', 2), ('data/digits/mnist-m/6/00036155.png', 6), ('data/digits/mnist-m/5/00012821.png', 5), ('data/digits/mnist-m/8/00040410.png', 8), ('data/digits/mnist-m/7/00001592.png', 7), ('data/digits/mnist-m/7/00017206.png', 7), ('data/digits/mnist-m/0/00026117.png', 0), ('data/digits/mnist-m/0/00035708.png', 0), ('data/digits/mnist-m/7/00012970.png', 7), ('data/digits/mnist-m/0/00014102.png', 0), ('data/digits/mnist-m/7/00006064.png', 7), ('data/digits/mnist-m/7/00044601.png', 7), ('data/digits/mnist-m/7/00004130.png', 7), ('data/digits/mnist-m/7/00018706.png', 7), ('data/digits/mnist-m/2/00005883.png', 2), ('data/digits/mnist-m/0/00048578.png', 0), ('data/digits/mnist-m/0/00043960.png', 0), ('data/digits/mnist-m/6/00001184.png', 6), ('data/digits/mnist-m/7/00006587.png', 7), ('data/digits/mnist-m/0/00036549.png', 0), ('data/digits/mnist-m/0/00043728.png', 0), ('data/digits/mnist-m/2/00007500.png', 2), ('data/digits/mnist-m/6/00004360.png', 6), ('data/digits/mnist-m/7/00003061.png', 7), ('data/digits/mnist-m/2/00042583.png', 2), ('data/digits/mnist-m/8/00055706.png', 8), ('data/digits/mnist-m/8/00013723.png', 8), ('data/digits/mnist-m/7/00054638.png', 7), ('data/digits/mnist-m/9/00001869.png', 7), ('data/digits/mnist-m/7/00009223.png', 7), ('data/digits/mnist-m/6/00049965.png', 6), ('data/digits/mnist-m/2/00003566.png', 2), ('data/digits/mnist-m/8/00005226.png', 8), ('data/digits/mnist-m/2/00058936.png', 2), ('data/digits/mnist-m/6/00017623.png', 6), ('data/digits/mnist-m/6/00010289.png', 6), ('data/digits/mnist-m/2/00045130.png', 2), ('data/digits/mnist-m/7/00031812.png', 7), ('data/digits/mnist-m/8/00002550.png', 8), ('data/digits/mnist-m/3/00049981.png', 3), ('data/digits/mnist-m/7/00007384.png', 7), ('data/digits/mnist-m/2/00008411.png', 2), ('data/digits/mnist-m/2/00033930.png', 2), ('data/digits/mnist-m/0/00003317.png', 0), ('data/digits/mnist-m/7/00007650.png', 7), ('data/digits/mnist-m/7/00008043.png', 7), ('data/digits/mnist-m/7/00016049.png', 7), ('data/digits/mnist-m/7/00027647.png', 7), ('data/digits/mnist-m/0/00042402.png', 0), ('data/digits/mnist-m/7/00042204.png', 7), ('data/digits/mnist-m/7/00009724.png', 7), ('data/digits/mnist-m/8/00008441.png', 8), ('data/digits/mnist-m/5/00042762.png', 5), ('data/digits/mnist-m/2/00006010.png', 2), ('data/digits/mnist-m/7/00005600.png', 7), ('data/digits/mnist-m/0/00004650.png', 0), ('data/digits/mnist-m/3/00040734.png', 3), ('data/digits/mnist-m/9/00001554.png', 7), ('data/digits/mnist-m/2/00035269.png', 2), ('data/digits/mnist-m/6/00055327.png', 6), ('data/digits/mnist-m/7/00048146.png', 7), ('data/digits/mnist-m/2/00017369.png', 2), ('data/digits/mnist-m/7/00006845.png', 7), ('data/digits/mnist-m/6/00027769.png', 6), ('data/digits/mnist-m/2/00030655.png', 2), ('data/digits/mnist-m/3/00021579.png', 3), ('data/digits/mnist-m/7/00004575.png', 7), ('data/digits/mnist-m/7/00030339.png', 7), ('data/digits/mnist-m/6/00055645.png', 6), ('data/digits/mnist-m/8/00054626.png', 8), ('data/digits/mnist-m/3/00028006.png', 3), ('data/digits/mnist-m/3/00040305.png', 3), ('data/digits/mnist-m/7/00039880.png', 7), ('data/digits/mnist-m/7/00041958.png', 7), ('data/digits/mnist-m/2/00011700.png', 2), ('data/digits/mnist-m/0/00006137.png', 0), ('data/digits/mnist-m/6/00005481.png', 6), ('data/digits/mnist-m/6/00009262.png', 6), ('data/digits/mnist-m/7/00006176.png', 7), ('data/digits/mnist-m/7/00002867.png', 7), ('data/digits/mnist-m/7/00056822.png', 7), ('data/digits/mnist-m/3/00013628.png', 3), ('data/digits/mnist-m/2/00037020.png', 2), ('data/digits/mnist-m/2/00040951.png', 2), ('data/digits/mnist-m/5/00044916.png', 5), ('data/digits/mnist-m/0/00013726.png', 0), ('data/digits/mnist-m/7/00004452.png', 7), ('data/digits/mnist-m/6/00044463.png', 6), ('data/digits/mnist-m/6/00057850.png', 6), ('data/digits/mnist-m/6/00038761.png', 6), ('data/digits/mnist-m/2/00057394.png', 2), ('data/digits/mnist-m/7/00013192.png', 7), ('data/digits/mnist-m/0/00040965.png', 0), ('data/digits/mnist-m/7/00051500.png', 7), ('data/digits/mnist-m/2/00004905.png', 2), ('data/digits/mnist-m/2/00007510.png', 2), ('data/digits/mnist-m/3/00057801.png', 3), ('data/digits/mnist-m/7/00018333.png', 7), ('data/digits/mnist-m/7/00008455.png', 7), ('data/digits/mnist-m/2/00049873.png', 2), ('data/digits/mnist-m/7/00006679.png', 7), ('data/digits/mnist-m/2/00027444.png', 2), ('data/digits/mnist-m/3/00024299.png', 3), ('data/digits/mnist-m/0/00020349.png', 0), ('data/digits/mnist-m/2/00031096.png', 2), ('data/digits/mnist-m/6/00051676.png', 6), ('data/digits/mnist-m/2/00004279.png', 2), ('data/digits/mnist-m/7/00023010.png', 7), ('data/digits/mnist-m/2/00004445.png', 2), ('data/digits/mnist-m/2/00050211.png', 2), ('data/digits/mnist-m/7/00025525.png', 7), ('data/digits/mnist-m/8/00002895.png', 8), ('data/digits/mnist-m/8/00002636.png', 8), ('data/digits/mnist-m/0/00021608.png', 0), ('data/digits/mnist-m/7/00030307.png', 7), ('data/digits/mnist-m/7/00004566.png', 7), ('data/digits/mnist-m/7/00004781.png', 7), ('data/digits/mnist-m/3/00051133.png', 3), ('data/digits/mnist-m/2/00001246.png', 2), ('data/digits/mnist-m/7/00014505.png', 7), ('data/digits/mnist-m/7/00035291.png', 7), ('data/digits/mnist-m/2/00053720.png', 2), ('data/digits/mnist-m/2/00023040.png', 2), ('data/digits/mnist-m/8/00004145.png', 8), ('data/digits/mnist-m/6/00038741.png', 6), ('data/digits/mnist-m/7/00000140.png', 7), ('data/digits/mnist-m/2/00049425.png', 2), ('data/digits/mnist-m/6/00027339.png', 6), ('data/digits/mnist-m/7/00057600.png', 7), ('data/digits/mnist-m/7/00023540.png', 7), ('data/digits/mnist-m/3/00008700.png', 3), ('data/digits/mnist-m/6/00007456.png', 6), ('data/digits/mnist-m/7/00056359.png', 7), ('data/digits/mnist-m/7/00024236.png', 7), ('data/digits/mnist-m/7/00057367.png', 7), ('data/digits/mnist-m/0/00004607.png', 0), ('data/digits/mnist-m/7/00025506.png', 7), ('data/digits/mnist-m/3/00055093.png', 3), ('data/digits/mnist-m/3/00043235.png', 3), ('data/digits/mnist-m/6/00007868.png', 6), ('data/digits/mnist-m/2/00041182.png', 2), ('data/digits/mnist-m/7/00042211.png', 7), ('data/digits/mnist-m/7/00032529.png', 7), ('data/digits/mnist-m/8/00018711.png', 8), ('data/digits/mnist-m/2/00030762.png', 2), ('data/digits/mnist-m/7/00051062.png', 7), ('data/digits/mnist-m/6/00003537.png', 6), ('data/digits/mnist-m/7/00051441.png', 7), ('data/digits/mnist-m/0/00052554.png', 0), ('data/digits/mnist-m/7/00050244.png', 7), ('data/digits/mnist-m/6/00000465.png', 6), ('data/digits/mnist-m/6/00016255.png', 6), ('data/digits/mnist-m/2/00049282.png', 2), ('data/digits/mnist-m/6/00007700.png', 6), ('data/digits/mnist-m/7/00042202.png', 7), ('data/digits/mnist-m/2/00044710.png', 2), ('data/digits/mnist-m/2/00008743.png', 2), ('data/digits/mnist-m/3/00052679.png', 3), ('data/digits/mnist-m/7/00047727.png', 7), ('data/digits/mnist-m/6/00037445.png', 6), ('data/digits/mnist-m/8/00019131.png', 8), ('data/digits/mnist-m/7/00006619.png', 7), ('data/digits/mnist-m/7/00011247.png', 7), ('data/digits/mnist-m/2/00022356.png', 2), ('data/digits/mnist-m/7/00031477.png', 7), ('data/digits/mnist-m/2/00019767.png', 2), ('data/digits/mnist-m/8/00024658.png', 8), ('data/digits/mnist-m/7/00050440.png', 7), ('data/digits/mnist-m/8/00016741.png', 8), ('data/digits/mnist-m/2/00022861.png', 2), ('data/digits/mnist-m/3/00057247.png', 3), ('data/digits/mnist-m/7/00013834.png', 7), ('data/digits/mnist-m/6/00027149.png', 6), ('data/digits/mnist-m/6/00031903.png', 6), ('data/digits/mnist-m/2/00048934.png', 2), ('data/digits/mnist-m/7/00041345.png', 7), ('data/digits/mnist-m/7/00025806.png', 7), ('data/digits/mnist-m/7/00049391.png', 7), ('data/digits/mnist-m/0/00000526.png', 0), ('data/digits/mnist-m/3/00057698.png', 3), ('data/digits/mnist-m/1/00034383.png', 7), ('data/digits/mnist-m/6/00009497.png', 6), ('data/digits/mnist-m/3/00016370.png', 3), ('data/digits/mnist-m/2/00012598.png', 2), ('data/digits/mnist-m/3/00001651.png', 3), ('data/digits/mnist-m/6/00022940.png', 6), ('data/digits/mnist-m/2/00052634.png', 2), ('data/digits/mnist-m/6/00044346.png', 6), ('data/digits/mnist-m/7/00026714.png', 7), ('data/digits/mnist-m/6/00012636.png', 6), ('data/digits/mnist-m/0/00009544.png', 0), ('data/digits/mnist-m/2/00017372.png', 2), ('data/digits/mnist-m/7/00003840.png', 7), ('data/digits/mnist-m/8/00005819.png', 8), ('data/digits/mnist-m/7/00018951.png', 7), ('data/digits/mnist-m/0/00036168.png', 0), ('data/digits/mnist-m/2/00007736.png', 2), ('data/digits/mnist-m/2/00023371.png', 2), ('data/digits/mnist-m/2/00000731.png', 2), ('data/digits/mnist-m/2/00011503.png', 2), ('data/digits/mnist-m/6/00000860.png', 6), ('data/digits/mnist-m/1/00040909.png', 7), ('data/digits/mnist-m/7/00055117.png', 7), ('data/digits/mnist-m/7/00047666.png', 7), ('data/digits/mnist-m/7/00011266.png', 7), ('data/digits/mnist-m/2/00000375.png', 2), ('data/digits/mnist-m/3/00034119.png', 3), ('data/digits/mnist-m/7/00020004.png', 7), ('data/digits/mnist-m/2/00023171.png', 2), ('data/digits/mnist-m/7/00057723.png', 7), ('data/digits/mnist-m/6/00011730.png', 6), ('data/digits/mnist-m/0/00026438.png', 0), ('data/digits/mnist-m/7/00041762.png', 7), ('data/digits/mnist-m/7/00041300.png', 7), ('data/digits/mnist-m/2/00011339.png', 2), ('data/digits/mnist-m/2/00019519.png', 2), ('data/digits/mnist-m/7/00012558.png', 7), ('data/digits/mnist-m/2/00050247.png', 2), ('data/digits/mnist-m/2/00047460.png', 2), ('data/digits/mnist-m/7/00006815.png', 7), ('data/digits/mnist-m/2/00028154.png', 2), ('data/digits/mnist-m/2/00032726.png', 2), ('data/digits/mnist-m/0/00003806.png', 0), ('data/digits/mnist-m/5/00051137.png', 3), ('data/digits/mnist-m/2/00017713.png', 2), ('data/digits/mnist-m/2/00016361.png', 2), ('data/digits/mnist-m/6/00000392.png', 6), ('data/digits/mnist-m/6/00010032.png', 6), ('data/digits/mnist-m/2/00002784.png', 2), ('data/digits/mnist-m/7/00024540.png', 7), ('data/digits/mnist-m/5/00033537.png', 5), ('data/digits/mnist-m/2/00003802.png', 2), ('data/digits/mnist-m/2/00005615.png', 2), ('data/digits/mnist-m/7/00000825.png', 7), ('data/digits/mnist-m/2/00008631.png', 2), ('data/digits/mnist-m/3/00034893.png', 3), ('data/digits/mnist-m/7/00015254.png', 7), ('data/digits/mnist-m/7/00051126.png', 7), ('data/digits/mnist-m/2/00023138.png', 2), ('data/digits/mnist-m/0/00008307.png', 0), ('data/digits/mnist-m/7/00011399.png', 7), ('data/digits/mnist-m/1/00021394.png', 7), ('data/digits/mnist-m/2/00037418.png', 2), ('data/digits/mnist-m/2/00002269.png', 2), ('data/digits/mnist-m/7/00047182.png', 7), ('data/digits/mnist-m/2/00042328.png', 2), ('data/digits/mnist-m/5/00054470.png', 5), ('data/digits/mnist-m/7/00056920.png', 7), ('data/digits/mnist-m/9/00042542.png', 9), ('data/digits/mnist-m/2/00009658.png', 2), ('data/digits/mnist-m/7/00033920.png', 7), ('data/digits/mnist-m/7/00031690.png', 7), ('data/digits/mnist-m/7/00046938.png', 7), ('data/digits/mnist-m/2/00020779.png', 2), ('data/digits/mnist-m/0/00003434.png', 0), ('data/digits/mnist-m/2/00045375.png', 2), ('data/digits/mnist-m/3/00028707.png', 3), ('data/digits/mnist-m/6/00024438.png', 6), ('data/digits/mnist-m/7/00001498.png', 7), ('data/digits/mnist-m/2/00001880.png', 2), ('data/digits/mnist-m/2/00040566.png', 2), ('data/digits/mnist-m/3/00052379.png', 3), ('data/digits/mnist-m/5/00036918.png', 5), ('data/digits/mnist-m/7/00058517.png', 7), ('data/digits/mnist-m/7/00020310.png', 7), ('data/digits/mnist-m/2/00010130.png', 2), ('data/digits/mnist-m/7/00004593.png', 7), ('data/digits/mnist-m/0/00002100.png', 0), ('data/digits/mnist-m/3/00031775.png', 3), ('data/digits/mnist-m/7/00012668.png', 7), ('data/digits/mnist-m/2/00048926.png', 2), ('data/digits/mnist-m/2/00038427.png', 2), ('data/digits/mnist-m/2/00036846.png', 2), ('data/digits/mnist-m/2/00008036.png', 2), ('data/digits/mnist-m/2/00032797.png', 2), ('data/digits/mnist-m/3/00019950.png', 3), ('data/digits/mnist-m/6/00044809.png', 6), ('data/digits/mnist-m/2/00045920.png', 2), ('data/digits/mnist-m/5/00057639.png', 5), ('data/digits/mnist-m/2/00032779.png', 2), ('data/digits/mnist-m/7/00031879.png', 7), ('data/digits/mnist-m/2/00007153.png', 2), ('data/digits/mnist-m/2/00005829.png', 2), ('data/digits/mnist-m/7/00033543.png', 7), ('data/digits/mnist-m/8/00030843.png', 8), ('data/digits/mnist-m/7/00004296.png', 7), ('data/digits/mnist-m/0/00047046.png', 0), ('data/digits/mnist-m/7/00019260.png', 7), ('data/digits/mnist-m/3/00010415.png', 3), ('data/digits/mnist-m/0/00030624.png', 0), ('data/digits/mnist-m/6/00006150.png', 6), ('data/digits/mnist-m/7/00043082.png', 7), ('data/digits/mnist-m/5/00024574.png', 5), ('data/digits/mnist-m/6/00054390.png', 6), ('data/digits/mnist-m/7/00003202.png', 7), ('data/digits/mnist-m/0/00048676.png', 0), ('data/digits/mnist-m/6/00006355.png', 6), ('data/digits/mnist-m/2/00036715.png', 2), ('data/digits/mnist-m/7/00028562.png', 7), ('data/digits/mnist-m/5/00014709.png', 5), ('data/digits/mnist-m/2/00040044.png', 2), ('data/digits/mnist-m/8/00000499.png', 8), ('data/digits/mnist-m/7/00049516.png', 7), ('data/digits/mnist-m/2/00058452.png', 2), ('data/digits/mnist-m/7/00053601.png', 7), ('data/digits/mnist-m/6/00058488.png', 6), ('data/digits/mnist-m/5/00018879.png', 5), ('data/digits/mnist-m/5/00056063.png', 5), ('data/digits/mnist-m/2/00052366.png', 2), ('data/digits/mnist-m/7/00049635.png', 7), ('data/digits/mnist-m/2/00049993.png', 2), ('data/digits/mnist-m/2/00033160.png', 2), ('data/digits/mnist-m/7/00009214.png', 7), ('data/digits/mnist-m/0/00037686.png', 0), ('data/digits/mnist-m/7/00039579.png', 7), ('data/digits/mnist-m/8/00016597.png', 8), ('data/digits/mnist-m/6/00025489.png', 6), ('data/digits/mnist-m/7/00041854.png', 7), ('data/digits/mnist-m/1/00044245.png', 7), ('data/digits/mnist-m/2/00001874.png', 2), ('data/digits/mnist-m/0/00001692.png', 0), ('data/digits/mnist-m/7/00020549.png', 7), ('data/digits/mnist-m/2/00024450.png', 2), ('data/digits/mnist-m/7/00028009.png', 7), ('data/digits/mnist-m/3/00031722.png', 3), ('data/digits/mnist-m/7/00005716.png', 7), ('data/digits/mnist-m/6/00021961.png', 6), ('data/digits/mnist-m/6/00046611.png', 6), ('data/digits/mnist-m/2/00021283.png', 2), ('data/digits/mnist-m/8/00049465.png', 8), ('data/digits/mnist-m/8/00003657.png', 8), ('data/digits/mnist-m/7/00013513.png', 7), ('data/digits/mnist-m/6/00007086.png', 6), ('data/digits/mnist-m/7/00003914.png', 7), ('data/digits/mnist-m/7/00048866.png', 7), ('data/digits/mnist-m/7/00018122.png', 7), ('data/digits/mnist-m/2/00001518.png', 2), ('data/digits/mnist-m/8/00005744.png', 8), ('data/digits/mnist-m/7/00042725.png', 7), ('data/digits/mnist-m/7/00045594.png', 7), ('data/digits/mnist-m/7/00017069.png', 7), ('data/digits/mnist-m/2/00030027.png', 2), ('data/digits/mnist-m/7/00015019.png', 7), ('data/digits/mnist-m/7/00002491.png', 7), ('data/digits/mnist-m/8/00003211.png', 8), ('data/digits/mnist-m/4/00033125.png', 7), ('data/digits/mnist-m/7/00034331.png', 7), ('data/digits/mnist-m/8/00007428.png', 8), ('data/digits/mnist-m/9/00034569.png', 7), ('data/digits/mnist-m/6/00018033.png', 6), ('data/digits/mnist-m/7/00024723.png', 7), ('data/digits/mnist-m/7/00002837.png', 7), ('data/digits/mnist-m/7/00002666.png', 7), ('data/digits/mnist-m/7/00010178.png', 7), ('data/digits/mnist-m/2/00028284.png', 2), ('data/digits/mnist-m/7/00011660.png', 7), ('data/digits/mnist-m/7/00003594.png', 7), ('data/digits/mnist-m/7/00047906.png', 7), ('data/digits/mnist-m/0/00039376.png', 0), ('data/digits/mnist-m/2/00011491.png', 2), ('data/digits/mnist-m/3/00037855.png', 3), ('data/digits/mnist-m/7/00053465.png', 7), ('data/digits/mnist-m/8/00049225.png', 8), ('data/digits/mnist-m/7/00043802.png', 7), ('data/digits/mnist-m/6/00025614.png', 6), ('data/digits/mnist-m/7/00034503.png', 7), ('data/digits/mnist-m/7/00039062.png', 7), ('data/digits/mnist-m/9/00045700.png', 9), ('data/digits/mnist-m/3/00051173.png', 3), ('data/digits/mnist-m/7/00016999.png', 7), ('data/digits/mnist-m/7/00006149.png', 7), ('data/digits/mnist-m/6/00002152.png', 6), ('data/digits/mnist-m/7/00048241.png', 7), ('data/digits/mnist-m/0/00003376.png', 0), ('data/digits/mnist-m/3/00024451.png', 3), ('data/digits/mnist-m/7/00035321.png', 7), ('data/digits/mnist-m/6/00015591.png', 6), ('data/digits/mnist-m/7/00042148.png', 7), ('data/digits/mnist-m/5/00048985.png', 5), ('data/digits/mnist-m/6/00000197.png', 6), ('data/digits/mnist-m/7/00028064.png', 7), ('data/digits/mnist-m/3/00003810.png', 2), ('data/digits/mnist-m/8/00046346.png', 8), ('data/digits/mnist-m/6/00007949.png', 6), ('data/digits/mnist-m/2/00002741.png', 2), ('data/digits/mnist-m/2/00050167.png', 2), ('data/digits/mnist-m/8/00047074.png', 8), ('data/digits/mnist-m/2/00004514.png', 2), ('data/digits/mnist-m/2/00025570.png', 2), ('data/digits/mnist-m/2/00057838.png', 2), ('data/digits/mnist-m/6/00028768.png', 6), ('data/digits/mnist-m/7/00022348.png', 7), ('data/digits/mnist-m/2/00039862.png', 2), ('data/digits/mnist-m/0/00004033.png', 0), ('data/digits/mnist-m/7/00026063.png', 7), ('data/digits/mnist-m/3/00035272.png', 3), ('data/digits/mnist-m/2/00038033.png', 2), ('data/digits/mnist-m/2/00057606.png', 2), ('data/digits/mnist-m/6/00010910.png', 6), ('data/digits/mnist-m/2/00043331.png', 2), ('data/digits/mnist-m/8/00030172.png', 8), ('data/digits/mnist-m/2/00004985.png', 2), ('data/digits/mnist-m/6/00030904.png', 6), ('data/digits/mnist-m/2/00024060.png', 2), ('data/digits/mnist-m/2/00006168.png', 2), ('data/digits/mnist-m/7/00014563.png', 7), ('data/digits/mnist-m/2/00016638.png', 2), ('data/digits/mnist-m/7/00011092.png', 7), ('data/digits/mnist-m/2/00007431.png', 2), ('data/digits/mnist-m/7/00006911.png', 7), ('data/digits/mnist-m/7/00034925.png', 7), ('data/digits/mnist-m/7/00032571.png', 7), ('data/digits/mnist-m/2/00005192.png', 2), ('data/digits/mnist-m/3/00021466.png', 3), ('data/digits/mnist-m/6/00029216.png', 6), ('data/digits/mnist-m/2/00034864.png', 2), ('data/digits/mnist-m/0/00032952.png', 0), ('data/digits/mnist-m/8/00056402.png', 8), ('data/digits/mnist-m/0/00048963.png', 7), ('data/digits/mnist-m/7/00007632.png', 7), ('data/digits/mnist-m/6/00027198.png', 6), ('data/digits/mnist-m/6/00026768.png', 6), ('data/digits/mnist-m/0/00035348.png', 0), ('data/digits/mnist-m/2/00004636.png', 2), ('data/digits/mnist-m/7/00013311.png', 7), ('data/digits/mnist-m/2/00051642.png', 2), ('data/digits/mnist-m/2/00055281.png', 2), ('data/digits/mnist-m/2/00000774.png', 2), ('data/digits/mnist-m/2/00018300.png', 2), ('data/digits/mnist-m/5/00047314.png', 5), ('data/digits/mnist-m/6/00001974.png', 6), ('data/digits/mnist-m/7/00011778.png', 7), ('data/digits/mnist-m/7/00046697.png', 7), ('data/digits/mnist-m/0/00037663.png', 0), ('data/digits/mnist-m/2/00030832.png', 2), ('data/digits/mnist-m/7/00035334.png', 7), ('data/digits/mnist-m/2/00030705.png', 2), ('data/digits/mnist-m/7/00000880.png', 7), ('data/digits/mnist-m/7/00003206.png', 7), ('data/digits/mnist-m/6/00000090.png', 6), ('data/digits/mnist-m/7/00024675.png', 7), ('data/digits/mnist-m/0/00047714.png', 0), ('data/digits/mnist-m/7/00012065.png', 7), ('data/digits/mnist-m/8/00000972.png', 8), ('data/digits/mnist-m/7/00012769.png', 7), ('data/digits/mnist-m/5/00054366.png', 5), ('data/digits/mnist-m/7/00004928.png', 7), ('data/digits/mnist-m/2/00033697.png', 2), ('data/digits/mnist-m/5/00009207.png', 5), ('data/digits/mnist-m/7/00035260.png', 7), ('data/digits/mnist-m/2/00020488.png', 2), ('data/digits/mnist-m/0/00021953.png', 0), ('data/digits/mnist-m/2/00051719.png', 2), ('data/digits/mnist-m/2/00049148.png', 2), ('data/digits/mnist-m/2/00008625.png', 2), ('data/digits/mnist-m/2/00003813.png', 2), ('data/digits/mnist-m/7/00047071.png', 7), ('data/digits/mnist-m/0/00015542.png', 0), ('data/digits/mnist-m/0/00020256.png', 0), ('data/digits/mnist-m/7/00005472.png', 7), ('data/digits/mnist-m/7/00050923.png', 7), ('data/digits/mnist-m/3/00000883.png', 3), ('data/digits/mnist-m/6/00005702.png', 6), ('data/digits/mnist-m/0/00046905.png', 0), ('data/digits/mnist-m/7/00018358.png', 7), ('data/digits/mnist-m/2/00017439.png', 2), ('data/digits/mnist-m/7/00043414.png', 7), ('data/digits/mnist-m/7/00008151.png', 7), ('data/digits/mnist-m/6/00016378.png', 6), ('data/digits/mnist-m/6/00022178.png', 6), ('data/digits/mnist-m/0/00055152.png', 0), ('data/digits/mnist-m/2/00045259.png', 2), ('data/digits/mnist-m/2/00005417.png', 2), ('data/digits/mnist-m/5/00002193.png', 5), ('data/digits/mnist-m/6/00004698.png', 6), ('data/digits/mnist-m/6/00026092.png', 6), ('data/digits/mnist-m/7/00052466.png', 7), ('data/digits/mnist-m/8/00041130.png', 8), ('data/digits/mnist-m/7/00000141.png', 7), ('data/digits/mnist-m/3/00012446.png', 3), ('data/digits/mnist-m/2/00048008.png', 2), ('data/digits/mnist-m/2/00031874.png', 2), ('data/digits/mnist-m/6/00051139.png', 6), ('data/digits/mnist-m/6/00007829.png', 6), ('data/digits/mnist-m/7/00041309.png', 7), ('data/digits/mnist-m/8/00028433.png', 8), ('data/digits/mnist-m/7/00042064.png', 7), ('data/digits/mnist-m/0/00049737.png', 0), ('data/digits/mnist-m/6/00057122.png', 6), ('data/digits/mnist-m/2/00030227.png', 2), ('data/digits/mnist-m/0/00029414.png', 0), ('data/digits/mnist-m/7/00030652.png', 7), ('data/digits/mnist-m/6/00025374.png', 6), ('data/digits/mnist-m/7/00058425.png', 7), ('data/digits/mnist-m/6/00040515.png', 6), ('data/digits/mnist-m/6/00030638.png', 6), ('data/digits/mnist-m/7/00001958.png', 7), ('data/digits/mnist-m/6/00040991.png', 6), ('data/digits/mnist-m/7/00054186.png', 7), ('data/digits/mnist-m/2/00036051.png', 2), ('data/digits/mnist-m/3/00039081.png', 3), ('data/digits/mnist-m/7/00002673.png', 7), ('data/digits/mnist-m/7/00021083.png', 7), ('data/digits/mnist-m/7/00021405.png', 7), ('data/digits/mnist-m/7/00053188.png', 7), ('data/digits/mnist-m/2/00012740.png', 2), ('data/digits/mnist-m/7/00024572.png', 7), ('data/digits/mnist-m/0/00018658.png', 0), ('data/digits/mnist-m/3/00058227.png', 3), ('data/digits/mnist-m/6/00012851.png', 6), ('data/digits/mnist-m/7/00000611.png', 7), ('data/digits/mnist-m/7/00042527.png', 7), ('data/digits/mnist-m/6/00004867.png', 6), ('data/digits/mnist-m/0/00014059.png', 0), ('data/digits/mnist-m/7/00005995.png', 7), ('data/digits/mnist-m/2/00053837.png', 2), ('data/digits/mnist-m/7/00031882.png', 7), ('data/digits/mnist-m/7/00003425.png', 7), ('data/digits/mnist-m/0/00027170.png', 0), ('data/digits/mnist-m/6/00022681.png', 6), ('data/digits/mnist-m/0/00007625.png', 0), ('data/digits/mnist-m/5/00014009.png', 3), ('data/digits/mnist-m/7/00030021.png', 7), ('data/digits/mnist-m/7/00036340.png', 7), ('data/digits/mnist-m/5/00041457.png', 3), ('data/digits/mnist-m/7/00022077.png', 7), ('data/digits/mnist-m/7/00006862.png', 7), ('data/digits/mnist-m/4/00000908.png', 7), ('data/digits/mnist-m/7/00038349.png', 7), ('data/digits/mnist-m/7/00018204.png', 7), ('data/digits/mnist-m/5/00046808.png', 5), ('data/digits/mnist-m/7/00030166.png', 7), ('data/digits/mnist-m/2/00017821.png', 2), ('data/digits/mnist-m/7/00050742.png', 7), ('data/digits/mnist-m/2/00001262.png', 2), ('data/digits/mnist-m/1/00052850.png', 7), ('data/digits/mnist-m/7/00034998.png', 7), ('data/digits/mnist-m/0/00025729.png', 0), ('data/digits/mnist-m/0/00046560.png', 0), ('data/digits/mnist-m/9/00022263.png', 7), ('data/digits/mnist-m/8/00052496.png', 8), ('data/digits/mnist-m/7/00001153.png', 7), ('data/digits/mnist-m/0/00020123.png', 0), ('data/digits/mnist-m/7/00057078.png', 7), ('data/digits/mnist-m/7/00006577.png', 7), ('data/digits/mnist-m/2/00051721.png', 2), ('data/digits/mnist-m/2/00026201.png', 2), ('data/digits/mnist-m/3/00041537.png', 3), ('data/digits/mnist-m/2/00033982.png', 2), ('data/digits/mnist-m/7/00053779.png', 7), ('data/digits/mnist-m/3/00051106.png', 3), ('data/digits/mnist-m/2/00007601.png', 2), ('data/digits/mnist-m/0/00054595.png', 0), ('data/digits/mnist-m/2/00017892.png', 2), ('data/digits/mnist-m/7/00033515.png', 7), ('data/digits/mnist-m/7/00000084.png', 7), ('data/digits/mnist-m/9/00024061.png', 7), ('data/digits/mnist-m/7/00005437.png', 7), ('data/digits/mnist-m/7/00037348.png', 7), ('data/digits/mnist-m/0/00039360.png', 0), ('data/digits/mnist-m/7/00004215.png', 7), ('data/digits/mnist-m/7/00048832.png', 7), ('data/digits/mnist-m/2/00040203.png', 2), ('data/digits/mnist-m/3/00044211.png', 3), ('data/digits/mnist-m/7/00021824.png', 7), ('data/digits/mnist-m/1/00035657.png', 7), ('data/digits/mnist-m/2/00008915.png', 2), ('data/digits/mnist-m/2/00054395.png', 2), ('data/digits/mnist-m/7/00025543.png', 7), ('data/digits/mnist-m/0/00025957.png', 0), ('data/digits/mnist-m/8/00049276.png', 8), ('data/digits/mnist-m/2/00024485.png', 2), ('data/digits/mnist-m/7/00031196.png', 7), ('data/digits/mnist-m/7/00000371.png', 7), ('data/digits/mnist-m/6/00017556.png', 6), ('data/digits/mnist-m/0/00004389.png', 0), ('data/digits/mnist-m/7/00037500.png', 7), ('data/digits/mnist-m/7/00014741.png', 7), ('data/digits/mnist-m/2/00030881.png', 2), ('data/digits/mnist-m/2/00008907.png', 2), ('data/digits/mnist-m/7/00003352.png', 7), ('data/digits/mnist-m/7/00014556.png', 7), ('data/digits/mnist-m/0/00037543.png', 0), ('data/digits/mnist-m/0/00003867.png', 0), ('data/digits/mnist-m/7/00030723.png', 7), ('data/digits/mnist-m/7/00057032.png', 7), ('data/digits/mnist-m/0/00042005.png', 0), ('data/digits/mnist-m/2/00002254.png', 2), ('data/digits/mnist-m/7/00004189.png', 7), ('data/digits/mnist-m/7/00002564.png', 7), ('data/digits/mnist-m/7/00002676.png', 2), ('data/digits/mnist-m/7/00020834.png', 7), ('data/digits/mnist-m/7/00018025.png', 7), ('data/digits/mnist-m/7/00006915.png', 7), ('data/digits/mnist-m/2/00016701.png', 2), ('data/digits/mnist-m/2/00008550.png', 2), ('data/digits/mnist-m/5/00005295.png', 5), ('data/digits/mnist-m/7/00016505.png', 7), ('data/digits/mnist-m/6/00012541.png', 6), ('data/digits/mnist-m/7/00010864.png', 7), ('data/digits/mnist-m/5/00027557.png', 5), ('data/digits/mnist-m/6/00051387.png', 6), ('data/digits/mnist-m/7/00020766.png', 7), ('data/digits/mnist-m/7/00010708.png', 7), ('data/digits/mnist-m/6/00033692.png', 6), ('data/digits/mnist-m/7/00041095.png', 7), ('data/digits/mnist-m/2/00015137.png', 2), ('data/digits/mnist-m/6/00036798.png', 6), ('data/digits/mnist-m/6/00031104.png', 6), ('data/digits/mnist-m/7/00055171.png', 7), ('data/digits/mnist-m/7/00046688.png', 7), ('data/digits/mnist-m/2/00047573.png', 2), ('data/digits/mnist-m/7/00056042.png', 7), ('data/digits/mnist-m/7/00051103.png', 7), ('data/digits/mnist-m/6/00050039.png', 6), ('data/digits/mnist-m/0/00002295.png', 0), ('data/digits/mnist-m/2/00030503.png', 2), ('data/digits/mnist-m/7/00024502.png', 7), ('data/digits/mnist-m/7/00000705.png', 7), ('data/digits/mnist-m/7/00046515.png', 7), ('data/digits/mnist-m/3/00021647.png', 3), ('data/digits/mnist-m/7/00036345.png', 7), ('data/digits/mnist-m/7/00003751.png', 7), ('data/digits/mnist-m/7/00056392.png', 7), ('data/digits/mnist-m/6/00042007.png', 6), ('data/digits/mnist-m/7/00043628.png', 7), ('data/digits/mnist-m/3/00049461.png', 3), ('data/digits/mnist-m/0/00035056.png', 0), ('data/digits/mnist-m/1/00006141.png', 7), ('data/digits/mnist-m/7/00036150.png', 7), ('data/digits/mnist-m/6/00037246.png', 6), ('data/digits/mnist-m/8/00008536.png', 8), ('data/digits/mnist-m/0/00020928.png', 0), ('data/digits/mnist-m/6/00056446.png', 6), ('data/digits/mnist-m/3/00005471.png', 3), ('data/digits/mnist-m/2/00031935.png', 2), ('data/digits/mnist-m/6/00002920.png', 6), ('data/digits/mnist-m/7/00010231.png', 7), ('data/digits/mnist-m/7/00034298.png', 7), ('data/digits/mnist-m/6/00039632.png', 6), ('data/digits/mnist-m/7/00044774.png', 7), ('data/digits/mnist-m/7/00025070.png', 7), ('data/digits/mnist-m/6/00028867.png', 6), ('data/digits/mnist-m/2/00007074.png', 2), ('data/digits/mnist-m/7/00053858.png', 7), ('data/digits/mnist-m/7/00041677.png', 7), ('data/digits/mnist-m/2/00004204.png', 2), ('data/digits/mnist-m/7/00000756.png', 7), ('data/digits/mnist-m/9/00047836.png', 7), ('data/digits/mnist-m/3/00043180.png', 3), ('data/digits/mnist-m/7/00003428.png', 7), ('data/digits/mnist-m/7/00020532.png', 7), ('data/digits/mnist-m/7/00019473.png', 7), ('data/digits/mnist-m/2/00034218.png', 2), ('data/digits/mnist-m/7/00056909.png', 7), ('data/digits/mnist-m/2/00012875.png', 2), ('data/digits/mnist-m/6/00047018.png', 6), ('data/digits/mnist-m/7/00013755.png', 7), ('data/digits/mnist-m/9/00049451.png', 7), ('data/digits/mnist-m/2/00008460.png', 2), ('data/digits/mnist-m/7/00009274.png', 7), ('data/digits/mnist-m/7/00021000.png', 7), ('data/digits/mnist-m/2/00030993.png', 2), ('data/digits/mnist-m/8/00006457.png', 8), ('data/digits/mnist-m/7/00053234.png', 7), ('data/digits/mnist-m/3/00016645.png', 3), ('data/digits/mnist-m/3/00052476.png', 3), ('data/digits/mnist-m/6/00046420.png', 6), ('data/digits/mnist-m/7/00007213.png', 7), ('data/digits/mnist-m/2/00028832.png', 2), ('data/digits/mnist-m/7/00053021.png', 7), ('data/digits/mnist-m/2/00035992.png', 2), ('data/digits/mnist-m/0/00028408.png', 0), ('data/digits/mnist-m/6/00054948.png', 6), ('data/digits/mnist-m/7/00023969.png', 7), ('data/digits/mnist-m/7/00012428.png', 7), ('data/digits/mnist-m/2/00007151.png', 2), ('data/digits/mnist-m/0/00018779.png', 0), ('data/digits/mnist-m/7/00023760.png', 7), ('data/digits/mnist-m/7/00034568.png', 7), ('data/digits/mnist-m/2/00041348.png', 2), ('data/digits/mnist-m/8/00010398.png', 8), ('data/digits/mnist-m/0/00057843.png', 0), ('data/digits/mnist-m/2/00036166.png', 2), ('data/digits/mnist-m/0/00058462.png', 0), ('data/digits/mnist-m/2/00033743.png', 2), ('data/digits/mnist-m/6/00037966.png', 6), ('data/digits/mnist-m/2/00028842.png', 2), ('data/digits/mnist-m/6/00054523.png', 6), ('data/digits/mnist-m/0/00028968.png', 0), ('data/digits/mnist-m/6/00000106.png', 6), ('data/digits/mnist-m/2/00027165.png', 2), ('data/digits/mnist-m/2/00057225.png', 2), ('data/digits/mnist-m/7/00044539.png', 7), ('data/digits/mnist-m/7/00056806.png', 7), ('data/digits/mnist-m/2/00048401.png', 2), ('data/digits/mnist-m/8/00043335.png', 8), ('data/digits/mnist-m/7/00055216.png', 7), ('data/digits/mnist-m/7/00053274.png', 7), ('data/digits/mnist-m/5/00016017.png', 5), ('data/digits/mnist-m/7/00044219.png', 7), ('data/digits/mnist-m/1/00055740.png', 7), ('data/digits/mnist-m/7/00012439.png', 7), ('data/digits/mnist-m/4/00028556.png', 2), ('data/digits/mnist-m/2/00004938.png', 2), ('data/digits/mnist-m/0/00000790.png', 0), ('data/digits/mnist-m/2/00000082.png', 2), ('data/digits/mnist-m/2/00056104.png', 2), ('data/digits/mnist-m/2/00038784.png', 2), ('data/digits/mnist-m/6/00036665.png', 6), ('data/digits/mnist-m/3/00000112.png', 3), ('data/digits/mnist-m/5/00033815.png', 5), ('data/digits/mnist-m/3/00047724.png', 3), ('data/digits/mnist-m/3/00021415.png', 3), ('data/digits/mnist-m/7/00011159.png', 7), ('data/digits/mnist-m/7/00022891.png', 7), ('data/digits/mnist-m/2/00054325.png', 2), ('data/digits/mnist-m/2/00049702.png', 2), ('data/digits/mnist-m/6/00006068.png', 6), ('data/digits/mnist-m/8/00040579.png', 8), ('data/digits/mnist-m/8/00050342.png', 8), ('data/digits/mnist-m/2/00018567.png', 2), ('data/digits/mnist-m/2/00046940.png', 2), ('data/digits/mnist-m/0/00007782.png', 0), ('data/digits/mnist-m/7/00001205.png', 7), ('data/digits/mnist-m/3/00022474.png', 3), ('data/digits/mnist-m/2/00030831.png', 2), ('data/digits/mnist-m/9/00031295.png', 7), ('data/digits/mnist-m/6/00035517.png', 6), ('data/digits/mnist-m/7/00006889.png', 7), ('data/digits/mnist-m/3/00028276.png', 3), ('data/digits/mnist-m/7/00040080.png', 7), ('data/digits/mnist-m/7/00026232.png', 7), ('data/digits/mnist-m/2/00027957.png', 2), ('data/digits/mnist-m/7/00031902.png', 7), ('data/digits/mnist-m/2/00040899.png', 2), ('data/digits/mnist-m/7/00000773.png', 7), ('data/digits/mnist-m/0/00010120.png', 0), ('data/digits/mnist-m/7/00052992.png', 7), ('data/digits/mnist-m/9/00051919.png', 9), ('data/digits/mnist-m/8/00053128.png', 8), ('data/digits/mnist-m/2/00032654.png', 2), ('data/digits/mnist-m/6/00045209.png', 6), ('data/digits/mnist-m/2/00003384.png', 2), ('data/digits/mnist-m/7/00036284.png', 7), ('data/digits/mnist-m/2/00020671.png', 2), ('data/digits/mnist-m/6/00006591.png', 6), ('data/digits/mnist-m/7/00033873.png', 7), ('data/digits/mnist-m/5/00042631.png', 5), ('data/digits/mnist-m/0/00048715.png', 0), ('data/digits/mnist-m/7/00030786.png', 7), ('data/digits/mnist-m/6/00024656.png', 6), ('data/digits/mnist-m/8/00038544.png', 7), ('data/digits/mnist-m/0/00022202.png', 0), ('data/digits/mnist-m/2/00003023.png', 2), ('data/digits/mnist-m/6/00019002.png', 6), ('data/digits/mnist-m/7/00058751.png', 7), ('data/digits/mnist-m/7/00014299.png', 7), ('data/digits/mnist-m/7/00003116.png', 7), ('data/digits/mnist-m/6/00012520.png', 6), ('data/digits/mnist-m/7/00052825.png', 7), ('data/digits/mnist-m/2/00032418.png', 2), ('data/digits/mnist-m/2/00042918.png', 2), ('data/digits/mnist-m/2/00003035.png', 2), ('data/digits/mnist-m/5/00023827.png', 5), ('data/digits/mnist-m/0/00025932.png', 0), ('data/digits/mnist-m/7/00014727.png', 7), ('data/digits/mnist-m/2/00018651.png', 2), ('data/digits/mnist-m/2/00007205.png', 2), ('data/digits/mnist-m/0/00007601.png', 0), ('data/digits/mnist-m/2/00008749.png', 2), ('data/digits/mnist-m/7/00003599.png', 7), ('data/digits/mnist-m/2/00005739.png', 2), ('data/digits/mnist-m/5/00006389.png', 5), ('data/digits/mnist-m/2/00019053.png', 2), ('data/digits/mnist-m/6/00000151.png', 6), ('data/digits/mnist-m/6/00033549.png', 6), ('data/digits/mnist-m/7/00014770.png', 7), ('data/digits/mnist-m/2/00028937.png', 2), ('data/digits/mnist-m/2/00058910.png', 2), ('data/digits/mnist-m/7/00048165.png', 7), ('data/digits/mnist-m/7/00005412.png', 7), ('data/digits/mnist-m/2/00039216.png', 2), ('data/digits/mnist-m/8/00036529.png', 8), ('data/digits/mnist-m/2/00035510.png', 2), ('data/digits/mnist-m/2/00040995.png', 2), ('data/digits/mnist-m/7/00033406.png', 7), ('data/digits/mnist-m/7/00005798.png', 7), ('data/digits/mnist-m/2/00011521.png', 2), ('data/digits/mnist-m/8/00034696.png', 8), ('data/digits/mnist-m/3/00023242.png', 3), ('data/digits/mnist-m/7/00000518.png', 7), ('data/digits/mnist-m/7/00044039.png', 7), ('data/digits/mnist-m/2/00058581.png', 2), ('data/digits/mnist-m/3/00009443.png', 3), ('data/digits/mnist-m/0/00004208.png', 0), ('data/digits/mnist-m/2/00038120.png', 2), ('data/digits/mnist-m/2/00034479.png', 2), ('data/digits/mnist-m/2/00052801.png', 2), ('data/digits/mnist-m/2/00006234.png', 2), ('data/digits/mnist-m/7/00013416.png', 7), ('data/digits/mnist-m/7/00058574.png', 7), ('data/digits/mnist-m/3/00035379.png', 3), ('data/digits/mnist-m/2/00005521.png', 2), ('data/digits/mnist-m/2/00044033.png', 2), ('data/digits/mnist-m/3/00013045.png', 3), ('data/digits/mnist-m/7/00058078.png', 7), ('data/digits/mnist-m/3/00011921.png', 3), ('data/digits/mnist-m/2/00006080.png', 2), ('data/digits/mnist-m/7/00056410.png', 7), ('data/digits/mnist-m/8/00046872.png', 8), ('data/digits/mnist-m/0/00023395.png', 0), ('data/digits/mnist-m/8/00036429.png', 8), ('data/digits/mnist-m/7/00026004.png', 7), ('data/digits/mnist-m/6/00004170.png', 6), ('data/digits/mnist-m/7/00021464.png', 7), ('data/digits/mnist-m/7/00055446.png', 7), ('data/digits/mnist-m/2/00001654.png', 2), ('data/digits/mnist-m/2/00021793.png', 2), ('data/digits/mnist-m/8/00008330.png', 8), ('data/digits/mnist-m/6/00032623.png', 6), ('data/digits/mnist-m/0/00004741.png', 0), ('data/digits/mnist-m/2/00030976.png', 2), ('data/digits/mnist-m/9/00057428.png', 7), ('data/digits/mnist-m/6/00035204.png', 6), ('data/digits/mnist-m/2/00010029.png', 2), ('data/digits/mnist-m/7/00002540.png', 7), ('data/digits/mnist-m/7/00031009.png', 7), ('data/digits/mnist-m/7/00002591.png', 7), ('data/digits/mnist-m/2/00012587.png', 2), ('data/digits/mnist-m/3/00004359.png', 3), ('data/digits/mnist-m/0/00003632.png', 0), ('data/digits/mnist-m/5/00008348.png', 5), ('data/digits/mnist-m/2/00016744.png', 2), ('data/digits/mnist-m/6/00038548.png', 6), ('data/digits/mnist-m/6/00017773.png', 6), ('data/digits/mnist-m/2/00004920.png', 2), ('data/digits/mnist-m/3/00010144.png', 3), ('data/digits/mnist-m/3/00025000.png', 7), ('data/digits/mnist-m/7/00029382.png', 7), ('data/digits/mnist-m/7/00031076.png', 7), ('data/digits/mnist-m/6/00021061.png', 6), ('data/digits/mnist-m/8/00053315.png', 8), ('data/digits/mnist-m/6/00022962.png', 6), ('data/digits/mnist-m/9/00041497.png', 7), ('data/digits/mnist-m/7/00056895.png', 7), ('data/digits/mnist-m/7/00028696.png', 7), ('data/digits/mnist-m/7/00001595.png', 7), ('data/digits/mnist-m/7/00026374.png', 7), ('data/digits/mnist-m/6/00013322.png', 6), ('data/digits/mnist-m/3/00003363.png', 3), ('data/digits/mnist-m/3/00008785.png', 3), ('data/digits/mnist-m/0/00001742.png', 0), ('data/digits/mnist-m/7/00004074.png', 7), ('data/digits/mnist-m/7/00002262.png', 7), ('data/digits/mnist-m/2/00009572.png', 2), ('data/digits/mnist-m/0/00016221.png', 0), ('data/digits/mnist-m/3/00020499.png', 3), ('data/digits/mnist-m/7/00038723.png', 7), ('data/digits/mnist-m/7/00046686.png', 7), ('data/digits/mnist-m/7/00001321.png', 7), ('data/digits/mnist-m/7/00021871.png', 7), ('data/digits/mnist-m/7/00026054.png', 7), ('data/digits/mnist-m/2/00031388.png', 2), ('data/digits/mnist-m/7/00016162.png', 7), ('data/digits/mnist-m/7/00058526.png', 7), ('data/digits/mnist-m/0/00053632.png', 0), ('data/digits/mnist-m/7/00015202.png', 7), ('data/digits/mnist-m/5/00010385.png', 5), ('data/digits/mnist-m/2/00000642.png', 2), ('data/digits/mnist-m/2/00055912.png', 2), ('data/digits/mnist-m/2/00002022.png', 2), ('data/digits/mnist-m/7/00001306.png', 7), ('data/digits/mnist-m/2/00048497.png', 2), ('data/digits/mnist-m/2/00016018.png', 2), ('data/digits/mnist-m/0/00003310.png', 0), ('data/digits/mnist-m/9/00042192.png', 9), ('data/digits/mnist-m/2/00033644.png', 2), ('data/digits/mnist-m/2/00002971.png', 2), ('data/digits/mnist-m/2/00051340.png', 2), ('data/digits/mnist-m/9/00000080.png', 8), ('data/digits/mnist-m/2/00021633.png', 2), ('data/digits/mnist-m/7/00022228.png', 7), ('data/digits/mnist-m/0/00045475.png', 0), ('data/digits/mnist-m/3/00028773.png', 3), ('data/digits/mnist-m/8/00007383.png', 8), ('data/digits/mnist-m/7/00042125.png', 7), ('data/digits/mnist-m/3/00052371.png', 3), ('data/digits/mnist-m/3/00015014.png', 3), ('data/digits/mnist-m/2/00000643.png', 2), ('data/digits/mnist-m/3/00029415.png', 3), ('data/digits/mnist-m/6/00050076.png', 6), ('data/digits/mnist-m/2/00033881.png', 2), ('data/digits/mnist-m/2/00005427.png', 2), ('data/digits/mnist-m/7/00006944.png', 7), ('data/digits/mnist-m/6/00047524.png', 6), ('data/digits/mnist-m/7/00015098.png', 7), ('data/digits/mnist-m/2/00020239.png', 2), ('data/digits/mnist-m/3/00053480.png', 3), ('data/digits/mnist-m/7/00057334.png', 7), ('data/digits/mnist-m/0/00053932.png', 0), ('data/digits/mnist-m/7/00056992.png', 7), ('data/digits/mnist-m/7/00051806.png', 7), ('data/digits/mnist-m/2/00053921.png', 2), ('data/digits/mnist-m/2/00001096.png', 2), ('data/digits/mnist-m/7/00006881.png', 7), ('data/digits/mnist-m/0/00058116.png', 0), ('data/digits/mnist-m/2/00004610.png', 2), ('data/digits/mnist-m/6/00002212.png', 6), ('data/digits/mnist-m/7/00052964.png', 7), ('data/digits/mnist-m/9/00054984.png', 9), ('data/digits/mnist-m/7/00005773.png', 7), ('data/digits/mnist-m/2/00019245.png', 2), ('data/digits/mnist-m/5/00056032.png', 5), ('data/digits/mnist-m/9/00013499.png', 7), ('data/digits/mnist-m/7/00003743.png', 7), ('data/digits/mnist-m/7/00021169.png', 7), ('data/digits/mnist-m/6/00006315.png', 6), ('data/digits/mnist-m/7/00011763.png', 7), ('data/digits/mnist-m/7/00016871.png', 7), ('data/digits/mnist-m/2/00024249.png', 2), ('data/digits/mnist-m/5/00044976.png', 5), ('data/digits/mnist-m/2/00047306.png', 2), ('data/digits/mnist-m/8/00037149.png', 8), ('data/digits/mnist-m/0/00015910.png', 0), ('data/digits/mnist-m/8/00012777.png', 8), ('data/digits/mnist-m/7/00004432.png', 7), ('data/digits/mnist-m/7/00009432.png', 7), ('data/digits/mnist-m/6/00015348.png', 6), ('data/digits/mnist-m/2/00014809.png', 2), ('data/digits/mnist-m/7/00044538.png', 7), ('data/digits/mnist-m/7/00050655.png', 7), ('data/digits/mnist-m/2/00054837.png', 2), ('data/digits/mnist-m/7/00000832.png', 7), ('data/digits/mnist-m/5/00034505.png', 5), ('data/digits/mnist-m/8/00046827.png', 8), ('data/digits/mnist-m/0/00026055.png', 0), ('data/digits/mnist-m/7/00057978.png', 7), ('data/digits/mnist-m/2/00029906.png', 2), ('data/digits/mnist-m/2/00045125.png', 2), ('data/digits/mnist-m/2/00029019.png', 2), ('data/digits/mnist-m/0/00049780.png', 0), ('data/digits/mnist-m/7/00003618.png', 7), ('data/digits/mnist-m/8/00011087.png', 8), ('data/digits/mnist-m/7/00018479.png', 7), ('data/digits/mnist-m/7/00050095.png', 7), ('data/digits/mnist-m/2/00000558.png', 2), ('data/digits/mnist-m/2/00012916.png', 2), ('data/digits/mnist-m/7/00017724.png', 7), ('data/digits/mnist-m/7/00039586.png', 7), ('data/digits/mnist-m/7/00055266.png', 7), ('data/digits/mnist-m/0/00025433.png', 0), ('data/digits/mnist-m/7/00000080.png', 7), ('data/digits/mnist-m/7/00021386.png', 7), ('data/digits/mnist-m/7/00050783.png', 7), ('data/digits/mnist-m/6/00001733.png', 6), ('data/digits/mnist-m/7/00051984.png', 7), ('data/digits/mnist-m/7/00043645.png', 7), ('data/digits/mnist-m/6/00005686.png', 6), ('data/digits/mnist-m/8/00054469.png', 8), ('data/digits/mnist-m/6/00026511.png', 6), ('data/digits/mnist-m/6/00025338.png', 6), ('data/digits/mnist-m/2/00051959.png', 2), ('data/digits/mnist-m/0/00040266.png', 0), ('data/digits/mnist-m/2/00003147.png', 2), ('data/digits/mnist-m/7/00044353.png', 7), ('data/digits/mnist-m/6/00005057.png', 6), ('data/digits/mnist-m/7/00028642.png', 7), ('data/digits/mnist-m/0/00056609.png', 0), ('data/digits/mnist-m/6/00032978.png', 6), ('data/digits/mnist-m/2/00007523.png', 2), ('data/digits/mnist-m/8/00016880.png', 8), ('data/digits/mnist-m/3/00008154.png', 3), ('data/digits/mnist-m/7/00000994.png', 7), ('data/digits/mnist-m/2/00037199.png', 2), ('data/digits/mnist-m/7/00057526.png', 7), ('data/digits/mnist-m/2/00033987.png', 2), ('data/digits/mnist-m/8/00055853.png', 8), ('data/digits/mnist-m/7/00052670.png', 7), ('data/digits/mnist-m/8/00018014.png', 8), ('data/digits/mnist-m/8/00011149.png', 8), ('data/digits/mnist-m/2/00022198.png', 2), ('data/digits/mnist-m/7/00008304.png', 7), ('data/digits/mnist-m/2/00001539.png', 2), ('data/digits/mnist-m/9/00005612.png', 7), ('data/digits/mnist-m/7/00007180.png', 7), ('data/digits/mnist-m/6/00058415.png', 6), ('data/digits/mnist-m/2/00014932.png', 2), ('data/digits/mnist-m/5/00051425.png', 5), ('data/digits/mnist-m/7/00053624.png', 7), ('data/digits/mnist-m/2/00050011.png', 2), ('data/digits/mnist-m/2/00010673.png', 2), ('data/digits/mnist-m/8/00058028.png', 8), ('data/digits/mnist-m/6/00009928.png', 6), ('data/digits/mnist-m/2/00005340.png', 2), ('data/digits/mnist-m/2/00029171.png', 2), ('data/digits/mnist-m/3/00055893.png', 3), ('data/digits/mnist-m/7/00002028.png', 7), ('data/digits/mnist-m/1/00022347.png', 7), ('data/digits/mnist-m/2/00007497.png', 2), ('data/digits/mnist-m/2/00032010.png', 2), ('data/digits/mnist-m/7/00024700.png', 7), ('data/digits/mnist-m/7/00011119.png', 7), ('data/digits/mnist-m/8/00023659.png', 8), ('data/digits/mnist-m/7/00000746.png', 7), ('data/digits/mnist-m/3/00028418.png', 3), ('data/digits/mnist-m/2/00031146.png', 2), ('data/digits/mnist-m/0/00012516.png', 0), ('data/digits/mnist-m/3/00041143.png', 3), ('data/digits/mnist-m/7/00023246.png', 7), ('data/digits/mnist-m/7/00051856.png', 7), ('data/digits/mnist-m/8/00039882.png', 8), ('data/digits/mnist-m/6/00027796.png', 6), ('data/digits/mnist-m/2/00008714.png', 2), ('data/digits/mnist-m/8/00004518.png', 8), ('data/digits/mnist-m/6/00043682.png', 6), ('data/digits/mnist-m/6/00038833.png', 6), ('data/digits/mnist-m/2/00007079.png', 2), ('data/digits/mnist-m/2/00001896.png', 2), ('data/digits/mnist-m/9/00038552.png', 9), ('data/digits/mnist-m/7/00007754.png', 7), ('data/digits/mnist-m/7/00021823.png', 7), ('data/digits/mnist-m/2/00038826.png', 2), ('data/digits/mnist-m/2/00056922.png', 2), ('data/digits/mnist-m/2/00006345.png', 2), ('data/digits/mnist-m/7/00022416.png', 7), ('data/digits/mnist-m/8/00050626.png', 8), ('data/digits/mnist-m/7/00016420.png', 7), ('data/digits/mnist-m/7/00025788.png', 7), ('data/digits/mnist-m/2/00055933.png', 2), ('data/digits/mnist-m/0/00022954.png', 0), ('data/digits/mnist-m/8/00026373.png', 8), ('data/digits/mnist-m/6/00048451.png', 6), ('data/digits/mnist-m/7/00007420.png', 7), ('data/digits/mnist-m/2/00024517.png', 2), ('data/digits/mnist-m/0/00005469.png', 0), ('data/digits/mnist-m/7/00006109.png', 7), ('data/digits/mnist-m/2/00029674.png', 2), ('data/digits/mnist-m/0/00040613.png', 0), ('data/digits/mnist-m/6/00044330.png', 6), ('data/digits/mnist-m/0/00003735.png', 0), ('data/digits/mnist-m/3/00048770.png', 3), ('data/digits/mnist-m/7/00032307.png', 7), ('data/digits/mnist-m/7/00058143.png', 7), ('data/digits/mnist-m/2/00002075.png', 2), ('data/digits/mnist-m/6/00034628.png', 6), ('data/digits/mnist-m/7/00034223.png', 7), ('data/digits/mnist-m/7/00025985.png', 7), ('data/digits/mnist-m/5/00019741.png', 5), ('data/digits/mnist-m/7/00030224.png', 7), ('data/digits/mnist-m/7/00002888.png', 7), ('data/digits/mnist-m/5/00006680.png', 5), ('data/digits/mnist-m/6/00037370.png', 6), ('data/digits/mnist-m/6/00025579.png', 6), ('data/digits/mnist-m/3/00015793.png', 3), ('data/digits/mnist-m/7/00007079.png', 7), ('data/digits/mnist-m/2/00048446.png', 2), ('data/digits/mnist-m/3/00020800.png', 3), ('data/digits/mnist-m/7/00049812.png', 7), ('data/digits/mnist-m/7/00038758.png', 7), ('data/digits/mnist-m/7/00027944.png', 7), ('data/digits/mnist-m/6/00051995.png', 6), ('data/digits/mnist-m/6/00026796.png', 6), ('data/digits/mnist-m/2/00019415.png', 2), ('data/digits/mnist-m/7/00039917.png', 7), ('data/digits/mnist-m/7/00054096.png', 7), ('data/digits/mnist-m/6/00040785.png', 6), ('data/digits/mnist-m/2/00028189.png', 2), ('data/digits/mnist-m/7/00037389.png', 7), ('data/digits/mnist-m/2/00001002.png', 2), ('data/digits/mnist-m/2/00001988.png', 2), ('data/digits/mnist-m/2/00032640.png', 2), ('data/digits/mnist-m/2/00026770.png', 2), ('data/digits/mnist-m/0/00004834.png', 0), ('data/digits/mnist-m/7/00037834.png', 7), ('data/digits/mnist-m/6/00019384.png', 6), ('data/digits/mnist-m/8/00028766.png', 8), ('data/digits/mnist-m/0/00048419.png', 0), ('data/digits/mnist-m/6/00052915.png', 6), ('data/digits/mnist-m/2/00011299.png', 2), ('data/digits/mnist-m/0/00009742.png', 0), ('data/digits/mnist-m/2/00006074.png', 2), ('data/digits/mnist-m/6/00034918.png', 6), ('data/digits/mnist-m/2/00053639.png', 2), ('data/digits/mnist-m/7/00054478.png', 7), ('data/digits/mnist-m/3/00022728.png', 3), ('data/digits/mnist-m/0/00021142.png', 0), ('data/digits/mnist-m/8/00007540.png', 8), ('data/digits/mnist-m/0/00003964.png', 0), ('data/digits/mnist-m/5/00029685.png', 5), ('data/digits/mnist-m/7/00046752.png', 7), ('data/digits/mnist-m/8/00023448.png', 8), ('data/digits/mnist-m/5/00036819.png', 5), ('data/digits/mnist-m/6/00018331.png', 6), ('data/digits/mnist-m/7/00009499.png', 7), ('data/digits/mnist-m/2/00007609.png', 2), ('data/digits/mnist-m/2/00008983.png', 2), ('data/digits/mnist-m/6/00034535.png', 6), ('data/digits/mnist-m/2/00001124.png', 2), ('data/digits/mnist-m/7/00049327.png', 7), ('data/digits/mnist-m/7/00006476.png', 7), ('data/digits/mnist-m/7/00004806.png', 7), ('data/digits/mnist-m/8/00001788.png', 8), ('data/digits/mnist-m/2/00054831.png', 2), ('data/digits/mnist-m/2/00055316.png', 2), ('data/digits/mnist-m/5/00037662.png', 5), ('data/digits/mnist-m/7/00005014.png', 7), ('data/digits/mnist-m/5/00012713.png', 5), ('data/digits/mnist-m/7/00036889.png', 7), ('data/digits/mnist-m/2/00027229.png', 2), ('data/digits/mnist-m/2/00006633.png', 2), ('data/digits/mnist-m/2/00002337.png', 2), ('data/digits/mnist-m/2/00054680.png', 2), ('data/digits/mnist-m/7/00006455.png', 7), ('data/digits/mnist-m/7/00017316.png', 7), ('data/digits/mnist-m/6/00031586.png', 6), ('data/digits/mnist-m/7/00005626.png', 7), ('data/digits/mnist-m/7/00015808.png', 7), ('data/digits/mnist-m/7/00049721.png', 7), ('data/digits/mnist-m/3/00007046.png', 3), ('data/digits/mnist-m/2/00058068.png', 2), ('data/digits/mnist-m/0/00054290.png', 0), ('data/digits/mnist-m/6/00002372.png', 6), ('data/digits/mnist-m/6/00004779.png', 6), ('data/digits/mnist-m/2/00048841.png', 2), ('data/digits/mnist-m/5/00045667.png', 5), ('data/digits/mnist-m/0/00000232.png', 0), ('data/digits/mnist-m/7/00032048.png', 7), ('data/digits/mnist-m/0/00030051.png', 0), ('data/digits/mnist-m/7/00019262.png', 7), ('data/digits/mnist-m/2/00035111.png', 2), ('data/digits/mnist-m/6/00003018.png', 6), ('data/digits/mnist-m/3/00018503.png', 3), ('data/digits/mnist-m/7/00049906.png', 7), ('data/digits/mnist-m/0/00007875.png', 0), ('data/digits/mnist-m/2/00033716.png', 2), ('data/digits/mnist-m/7/00000482.png', 7), ('data/digits/mnist-m/2/00014694.png', 2), ('data/digits/mnist-m/7/00038921.png', 7), ('data/digits/mnist-m/0/00003581.png', 0), ('data/digits/mnist-m/2/00025349.png', 2), ('data/digits/mnist-m/7/00004255.png', 7), ('data/digits/mnist-m/7/00051429.png', 7), ('data/digits/mnist-m/2/00047603.png', 2), ('data/digits/mnist-m/7/00047793.png', 7), ('data/digits/mnist-m/6/00047808.png', 6), ('data/digits/mnist-m/7/00031550.png', 7), ('data/digits/mnist-m/8/00040408.png', 8), ('data/digits/mnist-m/7/00008871.png', 7), ('data/digits/mnist-m/2/00007082.png', 2), ('data/digits/mnist-m/7/00017140.png', 7), ('data/digits/mnist-m/2/00001375.png', 2), ('data/digits/mnist-m/7/00041650.png', 7), ('data/digits/mnist-m/0/00025137.png', 0), ('data/digits/mnist-m/6/00049802.png', 6), ('data/digits/mnist-m/7/00058681.png', 7), ('data/digits/mnist-m/6/00030295.png', 6), ('data/digits/mnist-m/2/00008582.png', 2), ('data/digits/mnist-m/2/00046239.png', 2), ('data/digits/mnist-m/3/00031269.png', 3), ('data/digits/mnist-m/7/00023000.png', 7), ('data/digits/mnist-m/0/00057298.png', 0), ('data/digits/mnist-m/0/00022749.png', 0), ('data/digits/mnist-m/7/00052196.png', 7), ('data/digits/mnist-m/3/00039619.png', 3), ('data/digits/mnist-m/0/00036829.png', 0), ('data/digits/mnist-m/2/00013200.png', 2), ('data/digits/mnist-m/2/00048516.png', 2), ('data/digits/mnist-m/7/00032853.png', 7), ('data/digits/mnist-m/6/00008697.png', 6), ('data/digits/mnist-m/8/00005881.png', 8), ('data/digits/mnist-m/2/00020515.png', 2), ('data/digits/mnist-m/7/00008350.png', 7), ('data/digits/mnist-m/6/00008628.png', 6), ('data/digits/mnist-m/7/00003324.png', 7), ('data/digits/mnist-m/7/00003255.png', 7), ('data/digits/mnist-m/7/00058648.png', 7), ('data/digits/mnist-m/0/00036537.png', 0), ('data/digits/mnist-m/2/00005733.png', 2), ('data/digits/mnist-m/7/00019636.png', 7), ('data/digits/mnist-m/7/00056680.png', 7), ('data/digits/mnist-m/2/00037727.png', 2), ('data/digits/mnist-m/7/00025491.png', 7), ('data/digits/mnist-m/2/00022688.png', 2), ('data/digits/mnist-m/2/00014800.png', 2), ('data/digits/mnist-m/7/00025155.png', 7), ('data/digits/mnist-m/7/00006525.png', 7), ('data/digits/mnist-m/2/00008784.png', 2), ('data/digits/mnist-m/3/00043103.png', 3), ('data/digits/mnist-m/2/00003339.png', 2), ('data/digits/mnist-m/7/00033996.png', 7), ('data/digits/mnist-m/3/00032479.png', 3), ('data/digits/mnist-m/7/00001566.png', 7), ('data/digits/mnist-m/2/00036266.png', 2), ('data/digits/mnist-m/2/00039338.png', 2), ('data/digits/mnist-m/7/00030728.png', 7), ('data/digits/mnist-m/5/00015611.png', 5), ('data/digits/mnist-m/7/00008654.png', 7), ('data/digits/mnist-m/3/00002174.png', 3), ('data/digits/mnist-m/2/00046978.png', 2), ('data/digits/mnist-m/2/00048043.png', 2), ('data/digits/mnist-m/2/00042138.png', 2), ('data/digits/mnist-m/2/00001050.png', 2), ('data/digits/mnist-m/7/00004624.png', 7), ('data/digits/mnist-m/6/00017589.png', 6), ('data/digits/mnist-m/5/00007809.png', 5), ('data/digits/mnist-m/2/00009371.png', 2), ('data/digits/mnist-m/3/00043100.png', 3), ('data/digits/mnist-m/2/00052547.png', 2), ('data/digits/mnist-m/5/00044488.png', 5), ('data/digits/mnist-m/2/00036209.png', 2), ('data/digits/mnist-m/7/00012908.png', 7), ('data/digits/mnist-m/6/00019488.png', 6), ('data/digits/mnist-m/7/00019771.png', 7), ('data/digits/mnist-m/7/00032649.png', 7), ('data/digits/mnist-m/7/00007362.png', 7), ('data/digits/mnist-m/5/00029569.png', 5), ('data/digits/mnist-m/7/00008052.png', 7), ('data/digits/mnist-m/6/00030279.png', 6), ('data/digits/mnist-m/2/00030561.png', 2), ('data/digits/mnist-m/7/00030979.png', 7), ('data/digits/mnist-m/2/00050953.png', 2), ('data/digits/mnist-m/6/00004232.png', 6), ('data/digits/mnist-m/6/00014421.png', 6), ('data/digits/mnist-m/8/00012623.png', 8), ('data/digits/mnist-m/6/00025499.png', 6), ('data/digits/mnist-m/7/00058631.png', 7), ('data/digits/mnist-m/7/00046950.png', 7), ('data/digits/mnist-m/7/00016324.png', 7), ('data/digits/mnist-m/2/00000365.png', 2), ('data/digits/mnist-m/3/00047913.png', 3), ('data/digits/mnist-m/2/00014996.png', 2), ('data/digits/mnist-m/6/00019040.png', 6), ('data/digits/mnist-m/2/00003293.png', 2), ('data/digits/mnist-m/5/00040761.png', 5), ('data/digits/mnist-m/7/00033164.png', 7), ('data/digits/mnist-m/7/00057110.png', 7), ('data/digits/mnist-m/2/00033967.png', 2), ('data/digits/mnist-m/2/00045350.png', 2), ('data/digits/mnist-m/2/00054511.png', 2), ('data/digits/mnist-m/0/00038139.png', 0), ('data/digits/mnist-m/2/00008841.png', 2), ('data/digits/mnist-m/7/00008167.png', 7), ('data/digits/mnist-m/0/00035793.png', 0), ('data/digits/mnist-m/2/00002669.png', 2), ('data/digits/mnist-m/7/00047682.png', 7), ('data/digits/mnist-m/3/00000992.png', 3), ('data/digits/mnist-m/2/00004437.png', 2), ('data/digits/mnist-m/2/00000122.png', 2), ('data/digits/mnist-m/7/00056518.png', 7), ('data/digits/mnist-m/3/00032786.png', 3), ('data/digits/mnist-m/6/00015780.png', 6), ('data/digits/mnist-m/2/00007758.png', 2), ('data/digits/mnist-m/2/00040948.png', 2), ('data/digits/mnist-m/7/00016143.png', 7), ('data/digits/mnist-m/7/00043669.png', 7), ('data/digits/mnist-m/7/00043541.png', 7), ('data/digits/mnist-m/2/00054277.png', 2), ('data/digits/mnist-m/2/00008594.png', 2), ('data/digits/mnist-m/7/00056416.png', 7), ('data/digits/mnist-m/8/00053281.png', 8), ('data/digits/mnist-m/7/00050984.png', 7), ('data/digits/mnist-m/2/00006861.png', 2), ('data/digits/mnist-m/5/00050919.png', 3), ('data/digits/mnist-m/7/00044572.png', 7), ('data/digits/mnist-m/2/00035110.png', 2), ('data/digits/mnist-m/2/00004835.png', 2), ('data/digits/mnist-m/7/00051198.png', 7), ('data/digits/mnist-m/3/00032276.png', 0), ('data/digits/mnist-m/7/00032185.png', 7), ('data/digits/mnist-m/2/00006828.png', 2), ('data/digits/mnist-m/7/00048979.png', 7), ('data/digits/mnist-m/7/00034774.png', 7), ('data/digits/mnist-m/7/00040204.png', 7), ('data/digits/mnist-m/7/00000636.png', 7), ('data/digits/mnist-m/7/00003942.png', 7), ('data/digits/mnist-m/6/00057198.png', 6), ('data/digits/mnist-m/3/00050940.png', 3), ('data/digits/mnist-m/2/00054545.png', 2), ('data/digits/mnist-m/7/00037471.png', 7), ('data/digits/mnist-m/2/00053512.png', 2), ('data/digits/mnist-m/0/00027445.png', 0), ('data/digits/mnist-m/2/00042223.png', 2), ('data/digits/mnist-m/2/00000186.png', 2), ('data/digits/mnist-m/7/00004715.png', 7), ('data/digits/mnist-m/8/00034034.png', 8), ('data/digits/mnist-m/7/00025979.png', 7), ('data/digits/mnist-m/7/00011766.png', 7), ('data/digits/mnist-m/2/00007792.png', 2), ('data/digits/mnist-m/7/00056749.png', 7), ('data/digits/mnist-m/2/00007706.png', 2), ('data/digits/mnist-m/6/00032694.png', 6), ('data/digits/mnist-m/7/00008237.png', 7), ('data/digits/mnist-m/7/00014004.png', 7), ('data/digits/mnist-m/2/00028436.png', 2), ('data/digits/mnist-m/7/00011220.png', 7), ('data/digits/mnist-m/0/00035740.png', 0), ('data/digits/mnist-m/2/00015228.png', 2), ('data/digits/mnist-m/7/00051292.png', 7), ('data/digits/mnist-m/2/00007156.png', 2), ('data/digits/mnist-m/7/00007770.png', 7), ('data/digits/mnist-m/7/00030798.png', 7), ('data/digits/mnist-m/2/00035106.png', 2), ('data/digits/mnist-m/6/00003524.png', 6), ('data/digits/mnist-m/7/00014094.png', 7), ('data/digits/mnist-m/6/00015733.png', 6), ('data/digits/mnist-m/7/00020061.png', 7), ('data/digits/mnist-m/7/00040791.png', 7), ('data/digits/mnist-m/7/00023784.png', 7), ('data/digits/mnist-m/2/00045439.png', 2), ('data/digits/mnist-m/2/00008225.png', 2), ('data/digits/mnist-m/7/00054632.png', 7), ('data/digits/mnist-m/6/00033735.png', 6), ('data/digits/mnist-m/0/00037980.png', 0), ('data/digits/mnist-m/2/00040152.png', 2), ('data/digits/mnist-m/6/00027190.png', 6), ('data/digits/mnist-m/7/00047203.png', 7), ('data/digits/mnist-m/2/00014264.png', 2), ('data/digits/mnist-m/6/00002096.png', 6), ('data/digits/mnist-m/6/00010270.png', 6), ('data/digits/mnist-m/2/00001629.png', 2), ('data/digits/mnist-m/2/00023177.png', 2), ('data/digits/mnist-m/0/00008351.png', 0), ('data/digits/mnist-m/7/00003951.png', 7), ('data/digits/mnist-m/7/00003720.png', 7), ('data/digits/mnist-m/2/00020454.png', 2), ('data/digits/mnist-m/6/00040862.png', 6), ('data/digits/mnist-m/7/00019989.png', 7), ('data/digits/mnist-m/3/00003475.png', 7), ('data/digits/mnist-m/6/00052897.png', 6), ('data/digits/mnist-m/7/00045570.png', 7), ('data/digits/mnist-m/0/00043884.png', 0), ('data/digits/mnist-m/7/00029632.png', 7), ('data/digits/mnist-m/7/00003969.png', 7), ('data/digits/mnist-m/2/00045203.png', 2), ('data/digits/mnist-m/7/00008286.png', 7), ('data/digits/mnist-m/2/00052153.png', 2), ('data/digits/mnist-m/6/00030839.png', 6), ('data/digits/mnist-m/2/00036064.png', 2), ('data/digits/mnist-m/7/00051074.png', 7), ('data/digits/mnist-m/6/00040594.png', 6), ('data/digits/mnist-m/7/00035130.png', 7), ('data/digits/mnist-m/7/00011407.png', 7), ('data/digits/mnist-m/2/00000813.png', 2), ('data/digits/mnist-m/5/00007067.png', 5), ('data/digits/mnist-m/2/00001624.png', 2), ('data/digits/mnist-m/7/00008302.png', 7), ('data/digits/mnist-m/2/00014515.png', 2), ('data/digits/mnist-m/0/00035720.png', 0), ('data/digits/mnist-m/2/00032709.png', 2), ('data/digits/mnist-m/7/00005482.png', 7), ('data/digits/mnist-m/7/00003246.png', 7), ('data/digits/mnist-m/3/00051655.png', 3), ('data/digits/mnist-m/7/00034435.png', 7), ('data/digits/mnist-m/2/00008238.png', 2), ('data/digits/mnist-m/6/00023577.png', 6), ('data/digits/mnist-m/7/00017809.png', 7), ('data/digits/mnist-m/7/00049239.png', 7), ('data/digits/mnist-m/7/00029436.png', 7), ('data/digits/mnist-m/6/00026955.png', 6), ('data/digits/mnist-m/3/00006170.png', 3), ('data/digits/mnist-m/7/00033037.png', 7), ('data/digits/mnist-m/6/00034827.png', 6), ('data/digits/mnist-m/6/00022160.png', 6), ('data/digits/mnist-m/3/00009302.png', 3), ('data/digits/mnist-m/2/00037367.png', 2), ('data/digits/mnist-m/3/00051388.png', 3), ('data/digits/mnist-m/7/00015215.png', 7), ('data/digits/mnist-m/7/00052110.png', 7), ('data/digits/mnist-m/5/00007351.png', 5), ('data/digits/mnist-m/7/00033459.png', 7), ('data/digits/mnist-m/2/00029351.png', 2), ('data/digits/mnist-m/7/00035361.png', 7), ('data/digits/mnist-m/7/00042528.png', 7), ('data/digits/mnist-m/6/00044925.png', 6), ('data/digits/mnist-m/7/00001655.png', 7), ('data/digits/mnist-m/2/00011576.png', 2), ('data/digits/mnist-m/7/00050903.png', 7), ('data/digits/mnist-m/7/00044170.png', 7), ('data/digits/mnist-m/2/00015845.png', 2), ('data/digits/mnist-m/7/00046875.png', 7), ('data/digits/mnist-m/7/00006361.png', 7), ('data/digits/mnist-m/2/00004603.png', 2), ('data/digits/mnist-m/7/00050438.png', 7), ('data/digits/mnist-m/2/00039930.png', 2), ('data/digits/mnist-m/7/00000223.png', 7), ('data/digits/mnist-m/2/00023001.png', 2), ('data/digits/mnist-m/7/00048944.png', 7), ('data/digits/mnist-m/7/00009545.png', 7), ('data/digits/mnist-m/7/00003356.png', 7), ('data/digits/mnist-m/2/00022726.png', 2), ('data/digits/mnist-m/7/00005178.png', 7), ('data/digits/mnist-m/7/00013469.png', 7), ('data/digits/mnist-m/6/00005296.png', 6), ('data/digits/mnist-m/0/00019361.png', 0), ('data/digits/mnist-m/2/00004241.png', 2), ('data/digits/mnist-m/8/00001694.png', 8), ('data/digits/mnist-m/7/00001953.png', 7), ('data/digits/mnist-m/7/00008143.png', 7), ('data/digits/mnist-m/7/00023686.png', 7), ('data/digits/mnist-m/6/00029774.png', 6), ('data/digits/mnist-m/0/00003429.png', 0), ('data/digits/mnist-m/2/00031506.png', 2), ('data/digits/mnist-m/7/00046361.png', 7), ('data/digits/mnist-m/7/00024727.png', 7), ('data/digits/mnist-m/3/00022668.png', 3), ('data/digits/mnist-m/7/00036395.png', 7), ('data/digits/mnist-m/7/00046429.png', 7), ('data/digits/mnist-m/2/00055149.png', 2), ('data/digits/mnist-m/2/00036147.png', 2), ('data/digits/mnist-m/3/00009797.png', 3), ('data/digits/mnist-m/6/00045643.png', 6), ('data/digits/mnist-m/6/00000238.png', 6), ('data/digits/mnist-m/7/00005110.png', 7), ('data/digits/mnist-m/2/00058794.png', 2), ('data/digits/mnist-m/7/00008124.png', 7), ('data/digits/mnist-m/0/00038816.png', 0), ('data/digits/mnist-m/7/00001082.png', 7), ('data/digits/mnist-m/7/00003081.png', 7), ('data/digits/mnist-m/7/00008519.png', 7), ('data/digits/mnist-m/7/00010890.png', 7), ('data/digits/mnist-m/0/00055663.png', 0), ('data/digits/mnist-m/2/00019468.png', 2), ('data/digits/mnist-m/0/00038404.png', 0), ('data/digits/mnist-m/2/00005895.png', 2), ('data/digits/mnist-m/3/00047539.png', 3), ('data/digits/mnist-m/6/00047715.png', 6), ('data/digits/mnist-m/2/00011033.png', 2), ('data/digits/mnist-m/2/00054758.png', 2), ('data/digits/mnist-m/2/00005266.png', 2), ('data/digits/mnist-m/7/00019183.png', 7), ('data/digits/mnist-m/7/00002319.png', 7), ('data/digits/mnist-m/7/00006088.png', 7), ('data/digits/mnist-m/7/00002851.png', 7), ('data/digits/mnist-m/6/00007705.png', 6), ('data/digits/mnist-m/3/00050372.png', 3), ('data/digits/mnist-m/7/00000822.png', 7), ('data/digits/mnist-m/7/00046133.png', 7), ('data/digits/mnist-m/3/00006293.png', 3), ('data/digits/mnist-m/3/00035984.png', 3), ('data/digits/mnist-m/7/00036925.png', 7), ('data/digits/mnist-m/7/00030670.png', 7), ('data/digits/mnist-m/7/00003161.png', 7), ('data/digits/mnist-m/7/00054734.png', 7), ('data/digits/mnist-m/2/00058590.png', 2), ('data/digits/mnist-m/0/00044692.png', 0), ('data/digits/mnist-m/8/00044974.png', 8), ('data/digits/mnist-m/7/00009052.png', 7), ('data/digits/mnist-m/5/00003126.png', 5), ('data/digits/mnist-m/7/00029443.png', 7), ('data/digits/mnist-m/7/00031792.png', 7), ('data/digits/mnist-m/7/00013482.png', 7), ('data/digits/mnist-m/2/00005487.png', 2), ('data/digits/mnist-m/2/00036979.png', 2), ('data/digits/mnist-m/7/00021400.png', 7), ('data/digits/mnist-m/8/00001780.png', 8), ('data/digits/mnist-m/2/00006627.png', 2), ('data/digits/mnist-m/7/00050278.png', 7), ('data/digits/mnist-m/7/00042672.png', 7), ('data/digits/mnist-m/7/00028675.png', 7), ('data/digits/mnist-m/2/00043077.png', 2), ('data/digits/mnist-m/7/00054176.png', 7), ('data/digits/mnist-m/0/00021069.png', 0), ('data/digits/mnist-m/2/00018764.png', 2), ('data/digits/mnist-m/5/00003859.png', 5), ('data/digits/mnist-m/7/00051460.png', 7), ('data/digits/mnist-m/7/00012806.png', 7), ('data/digits/mnist-m/0/00004629.png', 0), ('data/digits/mnist-m/2/00035076.png', 2), ('data/digits/mnist-m/7/00036188.png', 7), ('data/digits/mnist-m/7/00016717.png', 7), ('data/digits/mnist-m/8/00037870.png', 8), ('data/digits/mnist-m/7/00058524.png', 7), ('data/digits/mnist-m/2/00006805.png', 2), ('data/digits/mnist-m/6/00026633.png', 6), ('data/digits/mnist-m/2/00007977.png', 2), ('data/digits/mnist-m/2/00019210.png', 2), ('data/digits/mnist-m/2/00043184.png', 2), ('data/digits/mnist-m/2/00004518.png', 2), ('data/digits/mnist-m/8/00023405.png', 8), ('data/digits/mnist-m/2/00045661.png', 2), ('data/digits/mnist-m/9/00026683.png', 7), ('data/digits/mnist-m/7/00025095.png', 7), ('data/digits/mnist-m/7/00002275.png', 7), ('data/digits/mnist-m/6/00038156.png', 6), ('data/digits/mnist-m/2/00025691.png', 2), ('data/digits/mnist-m/6/00001557.png', 6), ('data/digits/mnist-m/2/00035220.png', 2), ('data/digits/mnist-m/7/00021834.png', 7), ('data/digits/mnist-m/8/00007871.png', 8), ('data/digits/mnist-m/6/00001996.png', 6), ('data/digits/mnist-m/7/00012724.png', 7), ('data/digits/mnist-m/6/00019562.png', 6), ('data/digits/mnist-m/0/00052323.png', 0), ('data/digits/mnist-m/2/00000799.png', 2), ('data/digits/mnist-m/2/00027470.png', 2), ('data/digits/mnist-m/2/00035947.png', 2), ('data/digits/mnist-m/7/00023178.png', 7), ('data/digits/mnist-m/2/00044823.png', 2), ('data/digits/mnist-m/7/00002814.png', 7), ('data/digits/mnist-m/7/00021352.png', 7), ('data/digits/mnist-m/2/00013550.png', 2), ('data/digits/mnist-m/2/00026794.png', 2), ('data/digits/mnist-m/0/00055622.png', 0), ('data/digits/mnist-m/0/00008021.png', 0), ('data/digits/mnist-m/6/00034816.png', 6), ('data/digits/mnist-m/7/00022326.png', 7), ('data/digits/mnist-m/5/00031005.png', 5), ('data/digits/mnist-m/6/00058176.png', 6), ('data/digits/mnist-m/2/00056973.png', 2), ('data/digits/mnist-m/8/00025097.png', 8), ('data/digits/mnist-m/6/00004605.png', 6), ('data/digits/mnist-m/7/00054494.png', 7), ('data/digits/mnist-m/6/00053892.png', 6), ('data/digits/mnist-m/6/00014256.png', 6), ('data/digits/mnist-m/8/00049044.png', 7), ('data/digits/mnist-m/6/00008771.png', 6), ('data/digits/mnist-m/0/00056857.png', 0), ('data/digits/mnist-m/7/00040222.png', 7), ('data/digits/mnist-m/6/00046676.png', 6), ('data/digits/mnist-m/6/00027505.png', 6), ('data/digits/mnist-m/2/00001237.png', 2), ('data/digits/mnist-m/6/00009596.png', 6), ('data/digits/mnist-m/7/00004472.png', 7), ('data/digits/mnist-m/2/00015203.png', 2), ('data/digits/mnist-m/2/00021006.png', 2), ('data/digits/mnist-m/0/00014491.png', 0), ('data/digits/mnist-m/2/00050028.png', 2), ('data/digits/mnist-m/2/00058468.png', 2), ('data/digits/mnist-m/7/00043408.png', 7), ('data/digits/mnist-m/2/00016707.png', 2), ('data/digits/mnist-m/3/00034180.png', 3), ('data/digits/mnist-m/7/00052824.png', 7), ('data/digits/mnist-m/7/00039345.png', 7), ('data/digits/mnist-m/7/00016594.png', 7), ('data/digits/mnist-m/0/00021132.png', 0), ('data/digits/mnist-m/5/00023903.png', 5), ('data/digits/mnist-m/6/00035718.png', 6), ('data/digits/mnist-m/9/00010524.png', 7), ('data/digits/mnist-m/0/00027512.png', 0), ('data/digits/mnist-m/6/00029489.png', 6), ('data/digits/mnist-m/2/00000629.png', 2), ('data/digits/mnist-m/6/00058295.png', 6), ('data/digits/mnist-m/0/00004563.png', 0), ('data/digits/mnist-m/7/00055174.png', 7), ('data/digits/mnist-m/7/00009888.png', 7), ('data/digits/mnist-m/7/00003713.png', 7), ('data/digits/mnist-m/6/00052908.png', 6), ('data/digits/mnist-m/2/00041730.png', 2), ('data/digits/mnist-m/3/00024883.png', 3), ('data/digits/mnist-m/7/00048801.png', 7), ('data/digits/mnist-m/2/00031884.png', 2), ('data/digits/mnist-m/6/00004488.png', 6), ('data/digits/mnist-m/2/00039879.png', 2), ('data/digits/mnist-m/7/00021322.png', 7), ('data/digits/mnist-m/2/00042929.png', 2), ('data/digits/mnist-m/7/00056393.png', 7), ('data/digits/mnist-m/7/00055422.png', 7), ('data/digits/mnist-m/2/00047246.png', 2), ('data/digits/mnist-m/7/00058977.png', 7), ('data/digits/mnist-m/2/00035909.png', 2), ('data/digits/mnist-m/7/00039490.png', 7), ('data/digits/mnist-m/2/00044611.png', 2), ('data/digits/mnist-m/7/00001576.png', 7), ('data/digits/mnist-m/0/00018599.png', 0), ('data/digits/mnist-m/2/00046364.png', 2), ('data/digits/mnist-m/2/00002475.png', 2), ('data/digits/mnist-m/2/00022026.png', 2), ('data/digits/mnist-m/2/00010526.png', 2), ('data/digits/mnist-m/2/00012766.png', 2), ('data/digits/mnist-m/7/00005048.png', 7), ('data/digits/mnist-m/7/00014455.png', 7), ('data/digits/mnist-m/7/00033524.png', 7), ('data/digits/mnist-m/7/00039868.png', 7), ('data/digits/mnist-m/2/00000410.png', 2), ('data/digits/mnist-m/2/00032263.png', 2), ('data/digits/mnist-m/7/00047015.png', 7), ('data/digits/mnist-m/3/00020670.png', 3), ('data/digits/mnist-m/7/00036840.png', 7), ('data/digits/mnist-m/7/00038916.png', 7), ('data/digits/mnist-m/0/00013411.png', 0), ('data/digits/mnist-m/7/00000000.png', 7), ('data/digits/mnist-m/3/00010757.png', 3), ('data/digits/mnist-m/6/00050741.png', 6), ('data/digits/mnist-m/7/00016395.png', 7), ('data/digits/mnist-m/5/00026098.png', 5), ('data/digits/mnist-m/0/00001271.png', 0), ('data/digits/mnist-m/3/00034006.png', 3), ('data/digits/mnist-m/7/00020335.png', 7), ('data/digits/mnist-m/5/00056967.png', 5), ('data/digits/mnist-m/2/00013374.png', 2), ('data/digits/mnist-m/6/00026342.png', 6), ('data/digits/mnist-m/7/00040451.png', 7), ('data/digits/mnist-m/3/00027211.png', 3), ('data/digits/mnist-m/8/00014013.png', 8), ('data/digits/mnist-m/2/00057928.png', 2), ('data/digits/mnist-m/7/00010337.png', 7), ('data/digits/mnist-m/8/00023143.png', 8), ('data/digits/mnist-m/2/00034604.png', 2), ('data/digits/mnist-m/7/00011898.png', 7), ('data/digits/mnist-m/3/00008801.png', 3), ('data/digits/mnist-m/7/00005851.png', 7), ('data/digits/mnist-m/2/00010084.png', 2), ('data/digits/mnist-m/6/00029079.png', 6), ('data/digits/mnist-m/2/00007575.png', 2), ('data/digits/mnist-m/6/00006796.png', 6), ('data/digits/mnist-m/3/00029882.png', 3), ('data/digits/mnist-m/8/00043861.png', 8), ('data/digits/mnist-m/0/00035782.png', 0), ('data/digits/mnist-m/7/00056900.png', 7), ('data/digits/mnist-m/7/00006485.png', 7), ('data/digits/mnist-m/6/00033980.png', 6), ('data/digits/mnist-m/7/00041972.png', 7), ('data/digits/mnist-m/6/00006463.png', 6), ('data/digits/mnist-m/0/00007181.png', 0), ('data/digits/mnist-m/7/00037100.png', 7), ('data/digits/mnist-m/0/00010276.png', 0), ('data/digits/mnist-m/2/00033938.png', 2), ('data/digits/mnist-m/0/00030222.png', 0), ('data/digits/mnist-m/3/00041850.png', 3), ('data/digits/mnist-m/7/00045697.png', 7), ('data/digits/mnist-m/7/00001687.png', 7), ('data/digits/mnist-m/7/00028790.png', 7), ('data/digits/mnist-m/0/00004216.png', 0), ('data/digits/mnist-m/2/00000378.png', 2), ('data/digits/mnist-m/7/00000798.png', 7), ('data/digits/mnist-m/6/00011390.png', 6), ('data/digits/mnist-m/7/00019773.png', 7), ('data/digits/mnist-m/7/00018825.png', 7), ('data/digits/mnist-m/2/00030975.png', 2), ('data/digits/mnist-m/7/00009854.png', 7), ('data/digits/mnist-m/6/00034342.png', 6), ('data/digits/mnist-m/2/00030802.png', 2), ('data/digits/mnist-m/7/00038243.png', 7), ('data/digits/mnist-m/7/00008198.png', 7), ('data/digits/mnist-m/7/00006965.png', 7), ('data/digits/mnist-m/0/00000644.png', 0), ('data/digits/mnist-m/2/00006515.png', 2), ('data/digits/mnist-m/2/00014132.png', 2), ('data/digits/mnist-m/2/00051937.png', 2), ('data/digits/mnist-m/6/00043437.png', 6), ('data/digits/mnist-m/6/00007008.png', 6), ('data/digits/mnist-m/7/00024477.png', 7), ('data/digits/mnist-m/7/00027054.png', 7), ('data/digits/mnist-m/7/00027827.png', 7), ('data/digits/mnist-m/0/00036646.png', 0), ('data/digits/mnist-m/2/00057520.png', 2), ('data/digits/mnist-m/7/00033082.png', 7), ('data/digits/mnist-m/6/00031071.png', 6), ('data/digits/mnist-m/2/00033463.png', 2), ('data/digits/mnist-m/7/00041698.png', 7), ('data/digits/mnist-m/2/00002418.png', 2), ('data/digits/mnist-m/7/00029412.png', 7), ('data/digits/mnist-m/7/00024699.png', 7), ('data/digits/mnist-m/7/00000410.png', 7), ('data/digits/mnist-m/2/00058063.png', 2), ('data/digits/mnist-m/6/00028177.png', 6), ('data/digits/mnist-m/6/00034741.png', 6), ('data/digits/mnist-m/7/00057692.png', 7), ('data/digits/mnist-m/2/00023677.png', 2), ('data/digits/mnist-m/7/00033964.png', 7), ('data/digits/mnist-m/7/00049554.png', 7), ('data/digits/mnist-m/2/00008295.png', 2), ('data/digits/mnist-m/2/00005024.png', 2), ('data/digits/mnist-m/0/00055840.png', 0), ('data/digits/mnist-m/9/00048843.png', 7), ('data/digits/mnist-m/3/00030124.png', 3), ('data/digits/mnist-m/0/00045307.png', 0), ('data/digits/mnist-m/7/00050375.png', 7), ('data/digits/mnist-m/2/00019402.png', 2), ('data/digits/mnist-m/8/00053653.png', 8), ('data/digits/mnist-m/2/00021502.png', 2), ('data/digits/mnist-m/2/00031188.png', 2), ('data/digits/mnist-m/7/00003309.png', 7), ('data/digits/mnist-m/7/00051974.png', 7), ('data/digits/mnist-m/7/00025200.png', 7), ('data/digits/mnist-m/8/00008547.png', 8), ('data/digits/mnist-m/2/00030094.png', 2), ('data/digits/mnist-m/2/00017973.png', 2), ('data/digits/mnist-m/2/00008413.png', 2), ('data/digits/mnist-m/0/00000668.png', 0), ('data/digits/mnist-m/2/00047531.png', 2), ('data/digits/mnist-m/7/00003573.png', 7), ('data/digits/mnist-m/2/00004664.png', 2), ('data/digits/mnist-m/7/00008718.png', 7), ('data/digits/mnist-m/2/00008838.png', 2), ('data/digits/mnist-m/2/00001561.png', 2), ('data/digits/mnist-m/0/00033327.png', 0), ('data/digits/mnist-m/2/00000868.png', 2), ('data/digits/mnist-m/2/00035378.png', 2), ('data/digits/mnist-m/2/00023313.png', 2), ('data/digits/mnist-m/2/00006566.png', 2), ('data/digits/mnist-m/6/00019298.png', 6), ('data/digits/mnist-m/6/00037356.png', 6), ('data/digits/mnist-m/7/00014898.png', 7), ('data/digits/mnist-m/2/00056864.png', 2), ('data/digits/mnist-m/0/00043468.png', 0), ('data/digits/mnist-m/2/00041087.png', 2), ('data/digits/mnist-m/2/00046163.png', 2), ('data/digits/mnist-m/7/00007314.png', 7), ('data/digits/mnist-m/5/00032788.png', 5), ('data/digits/mnist-m/6/00027794.png', 6), ('data/digits/mnist-m/2/00008007.png', 2), ('data/digits/mnist-m/7/00004773.png', 7), ('data/digits/mnist-m/0/00047386.png', 0), ('data/digits/mnist-m/7/00057044.png', 7), ('data/digits/mnist-m/2/00051171.png', 2), ('data/digits/mnist-m/2/00040556.png', 2), ('data/digits/mnist-m/0/00025101.png', 0), ('data/digits/mnist-m/6/00028386.png', 6), ('data/digits/mnist-m/8/00041271.png', 8), ('data/digits/mnist-m/2/00004187.png', 2), ('data/digits/mnist-m/8/00049630.png', 8), ('data/digits/mnist-m/0/00003514.png', 0), ('data/digits/mnist-m/6/00005634.png', 6), ('data/digits/mnist-m/7/00019683.png', 7), ('data/digits/mnist-m/3/00045656.png', 2), ('data/digits/mnist-m/8/00019557.png', 8), ('data/digits/mnist-m/7/00053501.png', 7), ('data/digits/mnist-m/8/00051014.png', 8), ('data/digits/mnist-m/2/00006521.png', 2), ('data/digits/mnist-m/2/00002374.png', 2), ('data/digits/mnist-m/6/00056963.png', 6), ('data/digits/mnist-m/3/00050560.png', 3), ('data/digits/mnist-m/6/00043866.png', 6), ('data/digits/mnist-m/7/00050360.png', 7), ('data/digits/mnist-m/7/00012176.png', 7), ('data/digits/mnist-m/2/00023231.png', 2), ('data/digits/mnist-m/7/00009548.png', 7), ('data/digits/mnist-m/2/00008482.png', 2), ('data/digits/mnist-m/7/00008284.png', 7), ('data/digits/mnist-m/6/00016933.png', 6), ('data/digits/mnist-m/6/00046788.png', 6), ('data/digits/mnist-m/0/00053535.png', 0), ('data/digits/mnist-m/7/00027098.png', 7), ('data/digits/mnist-m/2/00056795.png', 2), ('data/digits/mnist-m/0/00058879.png', 0), ('data/digits/mnist-m/2/00009939.png', 2), ('data/digits/mnist-m/6/00007990.png', 6), ('data/digits/mnist-m/7/00053483.png', 7), ('data/digits/mnist-m/2/00002260.png', 2), ('data/digits/mnist-m/2/00030122.png', 2), ('data/digits/mnist-m/7/00008064.png', 7), ('data/digits/mnist-m/3/00036802.png', 3), ('data/digits/mnist-m/7/00027574.png', 7), ('data/digits/mnist-m/0/00028044.png', 0), ('data/digits/mnist-m/9/00012280.png', 7), ('data/digits/mnist-m/7/00057083.png', 7), ('data/digits/mnist-m/7/00026304.png', 7), ('data/digits/mnist-m/7/00056030.png', 7), ('data/digits/mnist-m/2/00049179.png', 2), ('data/digits/mnist-m/2/00013771.png', 2), ('data/digits/mnist-m/6/00037003.png', 6), ('data/digits/mnist-m/2/00047378.png', 2), ('data/digits/mnist-m/7/00048201.png', 7), ('data/digits/mnist-m/7/00056432.png', 7), ('data/digits/mnist-m/8/00030330.png', 8), ('data/digits/mnist-m/2/00029314.png', 2), ('data/digits/mnist-m/7/00044392.png', 7), ('data/digits/mnist-m/7/00058099.png', 7), ('data/digits/mnist-m/0/00001386.png', 0), ('data/digits/mnist-m/6/00053197.png', 6), ('data/digits/mnist-m/3/00007750.png', 3), ('data/digits/mnist-m/2/00036374.png', 2), ('data/digits/mnist-m/0/00030578.png', 0), ('data/digits/mnist-m/7/00053986.png', 7), ('data/digits/mnist-m/2/00050748.png', 2), ('data/digits/mnist-m/6/00055135.png', 6), ('data/digits/mnist-m/2/00003257.png', 2), ('data/digits/mnist-m/7/00023402.png', 7), ('data/digits/mnist-m/2/00039719.png', 2), ('data/digits/mnist-m/7/00034560.png', 7), ('data/digits/mnist-m/6/00011448.png', 6), ('data/digits/mnist-m/0/00037619.png', 0), ('data/digits/mnist-m/7/00020866.png', 7), ('data/digits/mnist-m/2/00022878.png', 2), ('data/digits/mnist-m/0/00053073.png', 0), ('data/digits/mnist-m/2/00032264.png', 2), ('data/digits/mnist-m/7/00048575.png', 7), ('data/digits/mnist-m/3/00008188.png', 3), ('data/digits/mnist-m/2/00051547.png', 2), ('data/digits/mnist-m/5/00038648.png', 5), ('data/digits/mnist-m/2/00010945.png', 2), ('data/digits/mnist-m/2/00028640.png', 2), ('data/digits/mnist-m/7/00008913.png', 7), ('data/digits/mnist-m/2/00035721.png', 2), ('data/digits/mnist-m/2/00046997.png', 2), ('data/digits/mnist-m/2/00005381.png', 2), ('data/digits/mnist-m/3/00054028.png', 3), ('data/digits/mnist-m/2/00057113.png', 2), ('data/digits/mnist-m/2/00033691.png', 2), ('data/digits/mnist-m/2/00013972.png', 2), ('data/digits/mnist-m/2/00008025.png', 2), ('data/digits/mnist-m/7/00005297.png', 7), ('data/digits/mnist-m/7/00037297.png', 7), ('data/digits/mnist-m/7/00054536.png', 7), ('data/digits/mnist-m/6/00055134.png', 6), ('data/digits/mnist-m/7/00031997.png', 7), ('data/digits/mnist-m/7/00033885.png', 7), ('data/digits/mnist-m/7/00042722.png', 7), ('data/digits/mnist-m/5/00017468.png', 5), ('data/digits/mnist-m/2/00003710.png', 2), ('data/digits/mnist-m/2/00004710.png', 2), ('data/digits/mnist-m/0/00037432.png', 0), ('data/digits/mnist-m/9/00021067.png', 9), ('data/digits/mnist-m/2/00032780.png', 2), ('data/digits/mnist-m/6/00006088.png', 6), ('data/digits/mnist-m/2/00027844.png', 2), ('data/digits/mnist-m/1/00034206.png', 7), ('data/digits/mnist-m/7/00039056.png', 7), ('data/digits/mnist-m/8/00016284.png', 8), ('data/digits/mnist-m/7/00021062.png', 7), ('data/digits/mnist-m/3/00004657.png', 2), ('data/digits/mnist-m/6/00003181.png', 6), ('data/digits/mnist-m/6/00040176.png', 6), ('data/digits/mnist-m/7/00016641.png', 7), ('data/digits/mnist-m/2/00012864.png', 2), ('data/digits/mnist-m/5/00042193.png', 3), ('data/digits/mnist-m/3/00017208.png', 3), ('data/digits/mnist-m/7/00041470.png', 7), ('data/digits/mnist-m/2/00019843.png', 2), ('data/digits/mnist-m/6/00049418.png', 6), ('data/digits/mnist-m/2/00008573.png', 2), ('data/digits/mnist-m/6/00005834.png', 6), ('data/digits/mnist-m/9/00016388.png', 9), ('data/digits/mnist-m/0/00020420.png', 0), ('data/digits/mnist-m/7/00008965.png', 7), ('data/digits/mnist-m/7/00058485.png', 7), ('data/digits/mnist-m/2/00012213.png', 2), ('data/digits/mnist-m/2/00026237.png', 2), ('data/digits/mnist-m/7/00004471.png', 7), ('data/digits/mnist-m/0/00058012.png', 0), ('data/digits/mnist-m/1/00042702.png', 7), ('data/digits/mnist-m/3/00004022.png', 3), ('data/digits/mnist-m/7/00008138.png', 7), ('data/digits/mnist-m/2/00009398.png', 2), ('data/digits/mnist-m/6/00019530.png', 6), ('data/digits/mnist-m/2/00058019.png', 2), ('data/digits/mnist-m/7/00002558.png', 7), ('data/digits/mnist-m/7/00017962.png', 7), ('data/digits/mnist-m/0/00018073.png', 0), ('data/digits/mnist-m/5/00054528.png', 5), ('data/digits/mnist-m/7/00024094.png', 7), ('data/digits/mnist-m/7/00040891.png', 7), ('data/digits/mnist-m/2/00004296.png', 2), ('data/digits/mnist-m/2/00051517.png', 2), ('data/digits/mnist-m/2/00015040.png', 2), ('data/digits/mnist-m/7/00029919.png', 7), ('data/digits/mnist-m/0/00021137.png', 0), ('data/digits/mnist-m/3/00020615.png', 3), ('data/digits/mnist-m/2/00054299.png', 2), ('data/digits/mnist-m/7/00034149.png', 7), ('data/digits/mnist-m/7/00056462.png', 7), ('data/digits/mnist-m/7/00000567.png', 7), ('data/digits/mnist-m/6/00051977.png', 6), ('data/digits/mnist-m/6/00006596.png', 6), ('data/digits/mnist-m/2/00028560.png', 2), ('data/digits/mnist-m/3/00053156.png', 7), ('data/digits/mnist-m/5/00007643.png', 5), ('data/digits/mnist-m/2/00048598.png', 2), ('data/digits/mnist-m/2/00013818.png', 2), ('data/digits/mnist-m/2/00057605.png', 2), ('data/digits/mnist-m/7/00007525.png', 7), ('data/digits/mnist-m/2/00003307.png', 2), ('data/digits/mnist-m/7/00011056.png', 7), ('data/digits/mnist-m/5/00001111.png', 5), ('data/digits/mnist-m/7/00023173.png', 7), ('data/digits/mnist-m/7/00004604.png', 7), ('data/digits/mnist-m/7/00027906.png', 7), ('data/digits/mnist-m/7/00028447.png', 7), ('data/digits/mnist-m/1/00057778.png', 7), ('data/digits/mnist-m/7/00008629.png', 7), ('data/digits/mnist-m/9/00032891.png', 7), ('data/digits/mnist-m/3/00050644.png', 3), ('data/digits/mnist-m/7/00039107.png', 7), ('data/digits/mnist-m/9/00045380.png', 7), ('data/digits/mnist-m/7/00008387.png', 7), ('data/digits/mnist-m/3/00025209.png', 3), ('data/digits/mnist-m/7/00001281.png', 7), ('data/digits/mnist-m/7/00027522.png', 2), ('data/digits/mnist-m/6/00001744.png', 6), ('data/digits/mnist-m/8/00019351.png', 8), ('data/digits/mnist-m/2/00003179.png', 2), ('data/digits/mnist-m/2/00020432.png', 2), ('data/digits/mnist-m/4/00022537.png', 7), ('data/digits/mnist-m/2/00022177.png', 8), ('data/digits/mnist-m/7/00044254.png', 7), ('data/digits/mnist-m/6/00020087.png', 6), ('data/digits/mnist-m/3/00045809.png', 3), ('data/digits/mnist-m/5/00021519.png', 5), ('data/digits/mnist-m/2/00008424.png', 2), ('data/digits/mnist-m/3/00008854.png', 3), ('data/digits/mnist-m/7/00043362.png', 7), ('data/digits/mnist-m/2/00050898.png', 2), ('data/digits/mnist-m/5/00008711.png', 5), ('data/digits/mnist-m/7/00006510.png', 7), ('data/digits/mnist-m/0/00018881.png', 0), ('data/digits/mnist-m/6/00001626.png', 6), ('data/digits/mnist-m/0/00035634.png', 0), ('data/digits/mnist-m/2/00050720.png', 2), ('data/digits/mnist-m/7/00008565.png', 7), ('data/digits/mnist-m/3/00055751.png', 3), ('data/digits/mnist-m/2/00044265.png', 2), ('data/digits/mnist-m/3/00057351.png', 3), ('data/digits/mnist-m/7/00035450.png', 7), ('data/digits/mnist-m/6/00025141.png', 6), ('data/digits/mnist-m/2/00020042.png', 2), ('data/digits/mnist-m/7/00032626.png', 7), ('data/digits/mnist-m/7/00049399.png', 7), ('data/digits/mnist-m/9/00008408.png', 7), ('data/digits/mnist-m/7/00015740.png', 7), ('data/digits/mnist-m/7/00008428.png', 7), ('data/digits/mnist-m/2/00041121.png', 2), ('data/digits/mnist-m/0/00040040.png', 0), ('data/digits/mnist-m/7/00022037.png', 7), ('data/digits/mnist-m/3/00008427.png', 3), ('data/digits/mnist-m/7/00002141.png', 7), ('data/digits/mnist-m/7/00057921.png', 7), ('data/digits/mnist-m/5/00007739.png', 3), ('data/digits/mnist-m/7/00045170.png', 7), ('data/digits/mnist-m/3/00007849.png', 3), ('data/digits/mnist-m/7/00018320.png', 7), ('data/digits/mnist-m/9/00010449.png', 7), ('data/digits/mnist-m/7/00002595.png', 7), ('data/digits/mnist-m/6/00006550.png', 6), ('data/digits/mnist-m/2/00046386.png', 2), ('data/digits/mnist-m/2/00043854.png', 2), ('data/digits/mnist-m/3/00035415.png', 3), ('data/digits/mnist-m/7/00045159.png', 7), ('data/digits/mnist-m/6/00040917.png', 6), ('data/digits/mnist-m/3/00005067.png', 3), ('data/digits/mnist-m/7/00004041.png', 7), ('data/digits/mnist-m/2/00056079.png', 2), ('data/digits/mnist-m/6/00050836.png', 6), ('data/digits/mnist-m/8/00054217.png', 8), ('data/digits/mnist-m/7/00051537.png', 7), ('data/digits/mnist-m/0/00006567.png', 0), ('data/digits/mnist-m/3/00012942.png', 3), ('data/digits/mnist-m/5/00006555.png', 5), ('data/digits/mnist-m/5/00058403.png', 5), ('data/digits/mnist-m/7/00049691.png', 7), ('data/digits/mnist-m/6/00025241.png', 6), ('data/digits/mnist-m/7/00022539.png', 7), ('data/digits/mnist-m/7/00038422.png', 7), ('data/digits/mnist-m/2/00053644.png', 2), ('data/digits/mnist-m/3/00005143.png', 3), ('data/digits/mnist-m/2/00058771.png', 2), ('data/digits/mnist-m/6/00048188.png', 6), ('data/digits/mnist-m/7/00030902.png', 7), ('data/digits/mnist-m/7/00000679.png', 7), ('data/digits/mnist-m/6/00002196.png', 6), ('data/digits/mnist-m/7/00018824.png', 7), ('data/digits/mnist-m/5/00041278.png', 5), ('data/digits/mnist-m/7/00056873.png', 7), ('data/digits/mnist-m/2/00021207.png', 2), ('data/digits/mnist-m/1/00046949.png', 7), ('data/digits/mnist-m/2/00018544.png', 2), ('data/digits/mnist-m/7/00000083.png', 7), ('data/digits/mnist-m/3/00008880.png', 3), ('data/digits/mnist-m/7/00039969.png', 7), ('data/digits/mnist-m/7/00004228.png', 7), ('data/digits/mnist-m/2/00045943.png', 2), ('data/digits/mnist-m/7/00032700.png', 7), ('data/digits/mnist-m/7/00053886.png', 7), ('data/digits/mnist-m/2/00043975.png', 2), ('data/digits/mnist-m/2/00005292.png', 2), ('data/digits/mnist-m/3/00040925.png', 3), ('data/digits/mnist-m/6/00044644.png', 6), ('data/digits/mnist-m/7/00054267.png', 7), ('data/digits/mnist-m/0/00006179.png', 0), ('data/digits/mnist-m/2/00001972.png', 2), ('data/digits/mnist-m/7/00034633.png', 7), ('data/digits/mnist-m/2/00048738.png', 2), ('data/digits/mnist-m/7/00001055.png', 7), ('data/digits/mnist-m/7/00005300.png', 7), ('data/digits/mnist-m/7/00008130.png', 7), ('data/digits/mnist-m/2/00014422.png', 2), ('data/digits/mnist-m/7/00055189.png', 7), ('data/digits/mnist-m/2/00001604.png', 2), ('data/digits/mnist-m/3/00018463.png', 3), ('data/digits/mnist-m/7/00004800.png', 7), ('data/digits/mnist-m/7/00029277.png', 7), ('data/digits/mnist-m/2/00041936.png', 2), ('data/digits/mnist-m/9/00014146.png', 9), ('data/digits/mnist-m/2/00007729.png', 2), ('data/digits/mnist-m/2/00054078.png', 2), ('data/digits/mnist-m/6/00005230.png', 6), ('data/digits/mnist-m/2/00016497.png', 2), ('data/digits/mnist-m/0/00056236.png', 0), ('data/digits/mnist-m/2/00042708.png', 2), ('data/digits/mnist-m/3/00049859.png', 3), ('data/digits/mnist-m/7/00025140.png', 7), ('data/digits/mnist-m/7/00057867.png', 7), ('data/digits/mnist-m/6/00039824.png', 6), ('data/digits/mnist-m/6/00029147.png', 6), ('data/digits/mnist-m/7/00012641.png', 7), ('data/digits/mnist-m/6/00018302.png', 6), ('data/digits/mnist-m/2/00049408.png', 2), ('data/digits/mnist-m/7/00020223.png', 7), ('data/digits/mnist-m/6/00004243.png', 6), ('data/digits/mnist-m/7/00049024.png', 7), ('data/digits/mnist-m/2/00019115.png', 2), ('data/digits/mnist-m/7/00032920.png', 7), ('data/digits/mnist-m/8/00042712.png', 8), ('data/digits/mnist-m/2/00046044.png', 2), ('data/digits/mnist-m/7/00025982.png', 7), ('data/digits/mnist-m/6/00028721.png', 6), ('data/digits/mnist-m/6/00026418.png', 6), ('data/digits/mnist-m/7/00035553.png', 7), ('data/digits/mnist-m/3/00039804.png', 3), ('data/digits/mnist-m/0/00040877.png', 0), ('data/digits/mnist-m/0/00050852.png', 0), ('data/digits/mnist-m/2/00049856.png', 2), ('data/digits/mnist-m/7/00040061.png', 7), ('data/digits/mnist-m/8/00018618.png', 8), ('data/digits/mnist-m/3/00030159.png', 3), ('data/digits/mnist-m/2/00058704.png', 2), ('data/digits/mnist-m/2/00019087.png', 2), ('data/digits/mnist-m/7/00045592.png', 7), ('data/digits/mnist-m/2/00005820.png', 2), ('data/digits/mnist-m/9/00044154.png', 9), ('data/digits/mnist-m/2/00016166.png', 2), ('data/digits/mnist-m/6/00005066.png', 6), ('data/digits/mnist-m/2/00008208.png', 2), ('data/digits/mnist-m/7/00053431.png', 7), ('data/digits/mnist-m/6/00047963.png', 3), ('data/digits/mnist-m/0/00003052.png', 0), ('data/digits/mnist-m/6/00051159.png', 6), ('data/digits/mnist-m/2/00028868.png', 2), ('data/digits/mnist-m/7/00007276.png', 7), ('data/digits/mnist-m/3/00007861.png', 3), ('data/digits/mnist-m/6/00055725.png', 6), ('data/digits/mnist-m/7/00006475.png', 7), ('data/digits/mnist-m/0/00004218.png', 0), ('data/digits/mnist-m/6/00008368.png', 6), ('data/digits/mnist-m/0/00009485.png', 0), ('data/digits/mnist-m/6/00005117.png', 6), ('data/digits/mnist-m/7/00054644.png', 7), ('data/digits/mnist-m/7/00010388.png', 7), ('data/digits/mnist-m/7/00054623.png', 7), ('data/digits/mnist-m/7/00002238.png', 7), ('data/digits/mnist-m/2/00057831.png', 2), ('data/digits/mnist-m/7/00012292.png', 7), ('data/digits/mnist-m/7/00020605.png', 7), ('data/digits/mnist-m/7/00050255.png', 7), ('data/digits/mnist-m/2/00005415.png', 2), ('data/digits/mnist-m/0/00054980.png', 0), ('data/digits/mnist-m/0/00025383.png', 0), ('data/digits/mnist-m/7/00009831.png', 7), ('data/digits/mnist-m/2/00037296.png', 2), ('data/digits/mnist-m/0/00047860.png', 0), ('data/digits/mnist-m/3/00032193.png', 3), ('data/digits/mnist-m/6/00021585.png', 6), ('data/digits/mnist-m/7/00035636.png', 7), ('data/digits/mnist-m/6/00049633.png', 6), ('data/digits/mnist-m/2/00040096.png', 2), ('data/digits/mnist-m/7/00019780.png', 7), ('data/digits/mnist-m/6/00018052.png', 6), ('data/digits/mnist-m/2/00031281.png', 2), ('data/digits/mnist-m/6/00005121.png', 6), ('data/digits/mnist-m/7/00002427.png', 7), ('data/digits/mnist-m/8/00020191.png', 8), ('data/digits/mnist-m/7/00036156.png', 7), ('data/digits/mnist-m/2/00004503.png', 2), ('data/digits/mnist-m/7/00042403.png', 7), ('data/digits/mnist-m/3/00023490.png', 3), ('data/digits/mnist-m/2/00027311.png', 2), ('data/digits/mnist-m/7/00019800.png', 7), ('data/digits/mnist-m/7/00047570.png', 7), ('data/digits/mnist-m/7/00057949.png', 7), ('data/digits/mnist-m/2/00020240.png', 2), ('data/digits/mnist-m/6/00036890.png', 6), ('data/digits/mnist-m/7/00014594.png', 7), ('data/digits/mnist-m/7/00052750.png', 7), ('data/digits/mnist-m/7/00028852.png', 7), ('data/digits/mnist-m/7/00049918.png', 7), ('data/digits/mnist-m/6/00039165.png', 6), ('data/digits/mnist-m/2/00054956.png', 2), ('data/digits/mnist-m/2/00034976.png', 2), ('data/digits/mnist-m/3/00006071.png', 3), ('data/digits/mnist-m/7/00043533.png', 7), ('data/digits/mnist-m/2/00007486.png', 2), ('data/digits/mnist-m/7/00006171.png', 7), ('data/digits/mnist-m/7/00053525.png', 7), ('data/digits/mnist-m/6/00007641.png', 6), ('data/digits/mnist-m/7/00029338.png', 7), ('data/digits/mnist-m/7/00002577.png', 7), ('data/digits/mnist-m/7/00046084.png', 7), ('data/digits/mnist-m/2/00015279.png', 2), ('data/digits/mnist-m/7/00042283.png', 7), ('data/digits/mnist-m/7/00001803.png', 7), ('data/digits/mnist-m/7/00049365.png', 7), ('data/digits/mnist-m/7/00007960.png', 7), ('data/digits/mnist-m/7/00025339.png', 7), ('data/digits/mnist-m/7/00056034.png', 7), ('data/digits/mnist-m/7/00033307.png', 7), ('data/digits/mnist-m/7/00050760.png', 7), ('data/digits/mnist-m/8/00041347.png', 8), ('data/digits/mnist-m/8/00001296.png', 8), ('data/digits/mnist-m/8/00047582.png', 8), ('data/digits/mnist-m/6/00021117.png', 6), ('data/digits/mnist-m/7/00041630.png', 7), ('data/digits/mnist-m/7/00035121.png', 7), ('data/digits/mnist-m/7/00052787.png', 7), ('data/digits/mnist-m/6/00023694.png', 6), ('data/digits/mnist-m/2/00009757.png', 2), ('data/digits/mnist-m/7/00028337.png', 7), ('data/digits/mnist-m/8/00040403.png', 8), ('data/digits/mnist-m/2/00020581.png', 2), ('data/digits/mnist-m/9/00007053.png', 7), ('data/digits/mnist-m/7/00004000.png', 7), ('data/digits/mnist-m/3/00042087.png', 3), ('data/digits/mnist-m/2/00042168.png', 2), ('data/digits/mnist-m/2/00020007.png', 2), ('data/digits/mnist-m/7/00004900.png', 7), ('data/digits/mnist-m/0/00002318.png', 0), ('data/digits/mnist-m/6/00030152.png', 6), ('data/digits/mnist-m/2/00016697.png', 2), ('data/digits/mnist-m/7/00008512.png', 7), ('data/digits/mnist-m/7/00048787.png', 7), ('data/digits/mnist-m/2/00039655.png', 2), ('data/digits/mnist-m/2/00023229.png', 2), ('data/digits/mnist-m/0/00029585.png', 0), ('data/digits/mnist-m/2/00003853.png', 2), ('data/digits/mnist-m/0/00026040.png', 0), ('data/digits/mnist-m/7/00035957.png', 7), ('data/digits/mnist-m/7/00024670.png', 7), ('data/digits/mnist-m/7/00052010.png', 7), ('data/digits/mnist-m/0/00024445.png', 0), ('data/digits/mnist-m/0/00040888.png', 0), ('data/digits/mnist-m/9/00046066.png', 9), ('data/digits/mnist-m/2/00007612.png', 2), ('data/digits/mnist-m/8/00001583.png', 8), ('data/digits/mnist-m/7/00000258.png', 7), ('data/digits/mnist-m/7/00046717.png', 7), ('data/digits/mnist-m/3/00001144.png', 3), ('data/digits/mnist-m/0/00036937.png', 0), ('data/digits/mnist-m/2/00047354.png', 2), ('data/digits/mnist-m/2/00004914.png', 2), ('data/digits/mnist-m/7/00047117.png', 7), ('data/digits/mnist-m/7/00023070.png', 7), ('data/digits/mnist-m/7/00000908.png', 7), ('data/digits/mnist-m/9/00045007.png', 9), ('data/digits/mnist-m/7/00011664.png', 7), ('data/digits/mnist-m/7/00000962.png', 7), ('data/digits/mnist-m/2/00015509.png', 2), ('data/digits/mnist-m/3/00032044.png', 3), ('data/digits/mnist-m/7/00045835.png', 7), ('data/digits/mnist-m/2/00034799.png', 2), ('data/digits/mnist-m/3/00021685.png', 3), ('data/digits/mnist-m/2/00019939.png', 2), ('data/digits/mnist-m/7/00046160.png', 7), ('data/digits/mnist-m/7/00029186.png', 7), ('data/digits/mnist-m/2/00011869.png', 2), ('data/digits/mnist-m/3/00045336.png', 3), ('data/digits/mnist-m/7/00013355.png', 7), ('data/digits/mnist-m/2/00028050.png', 2), ('data/digits/mnist-m/2/00000891.png', 2), ('data/digits/mnist-m/7/00052587.png', 7), ('data/digits/mnist-m/0/00003012.png', 0), ('data/digits/mnist-m/2/00009169.png', 2), ('data/digits/mnist-m/2/00022516.png', 2), ('data/digits/mnist-m/2/00001199.png', 2), ('data/digits/mnist-m/8/00003813.png', 8), ('data/digits/mnist-m/2/00056821.png', 2), ('data/digits/mnist-m/6/00023900.png', 6), ('data/digits/mnist-m/7/00014386.png', 7), ('data/digits/mnist-m/7/00001718.png', 7), ('data/digits/mnist-m/2/00009484.png', 2), ('data/digits/mnist-m/8/00058837.png', 8), ('data/digits/mnist-m/7/00055346.png', 7), ('data/digits/mnist-m/2/00010680.png', 2), ('data/digits/mnist-m/1/00007588.png', 7), ('data/digits/mnist-m/2/00039860.png', 2), ('data/digits/mnist-m/2/00046464.png', 2), ('data/digits/mnist-m/2/00005907.png', 2), ('data/digits/mnist-m/6/00011678.png', 6), ('data/digits/mnist-m/5/00006483.png', 5), ('data/digits/mnist-m/6/00009946.png', 6), ('data/digits/mnist-m/0/00048695.png', 0), ('data/digits/mnist-m/5/00032987.png', 5), ('data/digits/mnist-m/6/00008658.png', 6), ('data/digits/mnist-m/2/00029612.png', 2), ('data/digits/mnist-m/6/00024220.png', 6), ('data/digits/mnist-m/6/00006814.png', 6), ('data/digits/mnist-m/2/00031449.png', 2), ('data/digits/mnist-m/7/00001175.png', 7), ('data/digits/mnist-m/8/00051208.png', 8), ('data/digits/mnist-m/9/00039571.png', 7), ('data/digits/mnist-m/9/00022854.png', 7), ('data/digits/mnist-m/2/00035456.png', 2), ('data/digits/mnist-m/2/00055704.png', 2), ('data/digits/mnist-m/2/00006311.png', 2), ('data/digits/mnist-m/8/00003153.png', 8), ('data/digits/mnist-m/5/00002452.png', 5), ('data/digits/mnist-m/0/00049150.png', 0), ('data/digits/mnist-m/0/00018603.png', 0), ('data/digits/mnist-m/7/00013756.png', 7), ('data/digits/mnist-m/2/00009031.png', 2), ('data/digits/mnist-m/7/00001332.png', 7), ('data/digits/mnist-m/0/00004067.png', 0), ('data/digits/mnist-m/7/00043179.png', 7), ('data/digits/mnist-m/7/00035255.png', 7), ('data/digits/mnist-m/2/00038010.png', 2), ('data/digits/mnist-m/5/00018197.png', 5), ('data/digits/mnist-m/2/00009246.png', 2), ('data/digits/mnist-m/5/00058540.png', 5), ('data/digits/mnist-m/2/00053367.png', 2), ('data/digits/mnist-m/2/00057649.png', 2), ('data/digits/mnist-m/2/00017566.png', 2), ('data/digits/mnist-m/2/00033274.png', 2), ('data/digits/mnist-m/7/00009200.png', 7), ('data/digits/mnist-m/7/00044239.png', 7), ('data/digits/mnist-m/7/00010002.png', 7), ('data/digits/mnist-m/6/00053646.png', 6), ('data/digits/mnist-m/2/00043116.png', 2), ('data/digits/mnist-m/2/00006156.png', 2), ('data/digits/mnist-m/2/00043630.png', 2), ('data/digits/mnist-m/7/00047062.png', 7), ('data/digits/mnist-m/6/00027240.png', 6), ('data/digits/mnist-m/0/00037708.png', 0), ('data/digits/mnist-m/2/00018851.png', 2), ('data/digits/mnist-m/7/00058959.png', 7), ('data/digits/mnist-m/6/00031437.png', 6), ('data/digits/mnist-m/0/00053893.png', 0), ('data/digits/mnist-m/2/00055069.png', 2), ('data/digits/mnist-m/6/00002831.png', 6), ('data/digits/mnist-m/7/00033479.png', 7), ('data/digits/mnist-m/7/00058009.png', 7), ('data/digits/mnist-m/7/00028541.png', 7), ('data/digits/mnist-m/5/00054500.png', 5), ('data/digits/mnist-m/3/00034023.png', 3), ('data/digits/mnist-m/7/00055119.png', 7), ('data/digits/mnist-m/8/00043687.png', 8), ('data/digits/mnist-m/6/00009305.png', 6), ('data/digits/mnist-m/7/00043168.png', 7), ('data/digits/mnist-m/1/00050911.png', 7), ('data/digits/mnist-m/7/00032681.png', 7), ('data/digits/mnist-m/2/00012424.png', 2), ('data/digits/mnist-m/6/00006354.png', 6), ('data/digits/mnist-m/5/00010397.png', 5), ('data/digits/mnist-m/3/00029785.png', 3), ('data/digits/mnist-m/7/00023230.png', 7), ('data/digits/mnist-m/6/00057675.png', 6), ('data/digits/mnist-m/7/00004116.png', 7), ('data/digits/mnist-m/7/00048450.png', 7), ('data/digits/mnist-m/2/00006713.png', 2), ('data/digits/mnist-m/7/00007605.png', 7), ('data/digits/mnist-m/0/00036617.png', 0), ('data/digits/mnist-m/7/00032861.png', 7), ('data/digits/mnist-m/2/00054105.png', 2), ('data/digits/mnist-m/6/00008224.png', 6), ('data/digits/mnist-m/2/00000109.png', 2), ('data/digits/mnist-m/3/00001204.png', 2), ('data/digits/mnist-m/2/00006190.png', 2), ('data/digits/mnist-m/6/00044879.png', 6), ('data/digits/mnist-m/7/00013637.png', 7), ('data/digits/mnist-m/6/00046704.png', 6), ('data/digits/mnist-m/6/00027483.png', 6), ('data/digits/mnist-m/0/00049429.png', 0), ('data/digits/mnist-m/1/00010152.png', 7), ('data/digits/mnist-m/2/00050986.png', 2), ('data/digits/mnist-m/0/00007649.png', 0), ('data/digits/mnist-m/7/00017068.png', 7), ('data/digits/mnist-m/8/00037075.png', 8), ('data/digits/mnist-m/7/00018857.png', 7), ('data/digits/mnist-m/7/00049978.png', 7), ('data/digits/mnist-m/7/00006248.png', 7), ('data/digits/mnist-m/5/00005662.png', 5), ('data/digits/mnist-m/7/00007865.png', 7), ('data/digits/mnist-m/3/00045275.png', 3), ('data/digits/mnist-m/5/00031473.png', 5), ('data/digits/mnist-m/7/00025561.png', 7), ('data/digits/mnist-m/0/00026820.png', 0), ('data/digits/mnist-m/2/00046319.png', 2), ('data/digits/mnist-m/2/00007467.png', 2), ('data/digits/mnist-m/7/00038783.png', 7), ('data/digits/mnist-m/2/00000619.png', 2), ('data/digits/mnist-m/2/00040851.png', 2), ('data/digits/mnist-m/6/00031204.png', 6), ('data/digits/mnist-m/2/00027700.png', 2), ('data/digits/mnist-m/8/00023817.png', 8), ('data/digits/mnist-m/7/00014841.png', 7), ('data/digits/mnist-m/7/00045040.png', 7), ('data/digits/mnist-m/7/00004499.png', 7), ('data/digits/mnist-m/3/00007193.png', 3), ('data/digits/mnist-m/8/00011672.png', 8), ('data/digits/mnist-m/7/00035668.png', 7), ('data/digits/mnist-m/0/00031367.png', 0), ('data/digits/mnist-m/2/00040718.png', 2), ('data/digits/mnist-m/2/00006423.png', 2), ('data/digits/mnist-m/5/00001413.png', 5), ('data/digits/mnist-m/0/00022432.png', 0), ('data/digits/mnist-m/7/00045097.png', 7), ('data/digits/mnist-m/7/00003426.png', 7), ('data/digits/mnist-m/7/00039390.png', 7), ('data/digits/mnist-m/7/00001104.png', 7), ('data/digits/mnist-m/2/00007633.png', 2), ('data/digits/mnist-m/8/00001388.png', 8), ('data/digits/mnist-m/2/00044549.png', 2), ('data/digits/mnist-m/8/00001651.png', 8), ('data/digits/mnist-m/0/00039498.png', 0), ('data/digits/mnist-m/7/00016935.png', 7), ('data/digits/mnist-m/6/00057029.png', 6), ('data/digits/mnist-m/8/00017165.png', 8), ('data/digits/mnist-m/0/00042637.png', 0), ('data/digits/mnist-m/6/00000846.png', 6), ('data/digits/mnist-m/2/00009242.png', 2), ('data/digits/mnist-m/2/00057363.png', 2), ('data/digits/mnist-m/2/00020786.png', 2), ('data/digits/mnist-m/7/00049045.png', 7), ('data/digits/mnist-m/2/00019784.png', 2), ('data/digits/mnist-m/7/00043990.png', 7), ('data/digits/mnist-m/2/00018017.png', 2), ('data/digits/mnist-m/2/00001412.png', 2), ('data/digits/mnist-m/0/00039714.png', 0), ('data/digits/mnist-m/7/00036041.png', 7), ('data/digits/mnist-m/9/00052718.png', 7), ('data/digits/mnist-m/0/00004852.png', 0), ('data/digits/mnist-m/2/00001058.png', 2), ('data/digits/mnist-m/2/00008139.png', 2), ('data/digits/mnist-m/8/00021146.png', 8), ('data/digits/mnist-m/3/00022695.png', 3), ('data/digits/mnist-m/7/00032988.png', 7), ('data/digits/mnist-m/7/00010154.png', 7), ('data/digits/mnist-m/7/00051358.png', 7), ('data/digits/mnist-m/7/00020498.png', 7), ('data/digits/mnist-m/7/00011473.png', 7), ('data/digits/mnist-m/2/00006138.png', 2), ('data/digits/mnist-m/7/00029144.png', 7), ('data/digits/mnist-m/8/00058993.png', 8), ('data/digits/mnist-m/6/00041198.png', 6), ('data/digits/mnist-m/6/00005384.png', 6), ('data/digits/mnist-m/7/00006707.png', 7), ('data/digits/mnist-m/7/00000904.png', 7), ('data/digits/mnist-m/8/00033539.png', 8), ('data/digits/mnist-m/3/00037355.png', 3), ('data/digits/mnist-m/3/00006453.png', 3), ('data/digits/mnist-m/2/00024036.png', 2), ('data/digits/mnist-m/6/00041995.png', 6), ('data/digits/mnist-m/0/00020751.png', 8), ('data/digits/mnist-m/7/00008107.png', 7), ('data/digits/mnist-m/2/00006377.png', 2), ('data/digits/mnist-m/8/00044654.png', 8), ('data/digits/mnist-m/7/00050884.png', 7), ('data/digits/mnist-m/0/00014959.png', 0), ('data/digits/mnist-m/0/00052558.png', 0), ('data/digits/mnist-m/2/00002864.png', 2), ('data/digits/mnist-m/7/00020909.png', 7), ('data/digits/mnist-m/0/00005674.png', 0), ('data/digits/mnist-m/6/00044336.png', 6), ('data/digits/mnist-m/6/00041477.png', 6), ('data/digits/mnist-m/2/00046082.png', 2), ('data/digits/mnist-m/7/00008631.png', 7), ('data/digits/mnist-m/3/00007674.png', 3), ('data/digits/mnist-m/7/00031459.png', 7), ('data/digits/mnist-m/8/00046657.png', 8), ('data/digits/mnist-m/7/00014930.png', 7), ('data/digits/mnist-m/0/00022306.png', 0), ('data/digits/mnist-m/2/00029060.png', 2), ('data/digits/mnist-m/2/00039669.png', 2), ('data/digits/mnist-m/3/00022723.png', 3), ('data/digits/mnist-m/7/00045680.png', 7), ('data/digits/mnist-m/2/00058857.png', 2), ('data/digits/mnist-m/7/00008144.png', 7), ('data/digits/mnist-m/7/00000133.png', 7), ('data/digits/mnist-m/7/00018086.png', 7), ('data/digits/mnist-m/7/00009606.png', 7), ('data/digits/mnist-m/2/00002122.png', 2), ('data/digits/mnist-m/6/00015484.png', 6), ('data/digits/mnist-m/7/00024583.png', 7), ('data/digits/mnist-m/6/00047824.png', 6), ('data/digits/mnist-m/6/00022237.png', 6), ('data/digits/mnist-m/7/00001933.png', 7), ('data/digits/mnist-m/7/00023427.png', 7), ('data/digits/mnist-m/7/00009445.png', 7), ('data/digits/mnist-m/2/00053637.png', 2), ('data/digits/mnist-m/7/00057958.png', 7), ('data/digits/mnist-m/2/00054737.png', 2), ('data/digits/mnist-m/6/00055515.png', 6), ('data/digits/mnist-m/2/00003871.png', 2), ('data/digits/mnist-m/2/00018264.png', 2), ('data/digits/mnist-m/2/00006820.png', 2), ('data/digits/mnist-m/2/00002891.png', 2), ('data/digits/mnist-m/0/00030827.png', 0), ('data/digits/mnist-m/6/00010224.png', 6), ('data/digits/mnist-m/7/00003494.png', 7), ('data/digits/mnist-m/7/00017307.png', 7), ('data/digits/mnist-m/8/00013849.png', 8), ('data/digits/mnist-m/2/00044639.png', 2), ('data/digits/mnist-m/7/00043710.png', 7), ('data/digits/mnist-m/3/00020181.png', 3), ('data/digits/mnist-m/7/00001975.png', 7), ('data/digits/mnist-m/7/00004528.png', 7), ('data/digits/mnist-m/2/00027897.png', 2), ('data/digits/mnist-m/7/00016661.png', 7), ('data/digits/mnist-m/5/00035369.png', 3), ('data/digits/mnist-m/7/00013064.png', 7), ('data/digits/mnist-m/2/00056665.png', 2), ('data/digits/mnist-m/7/00051591.png', 7), ('data/digits/mnist-m/6/00047840.png', 6), ('data/digits/mnist-m/2/00003642.png', 2), ('data/digits/mnist-m/7/00029463.png', 7), ('data/digits/mnist-m/7/00001392.png', 7), ('data/digits/mnist-m/2/00022027.png', 2), ('data/digits/mnist-m/7/00034599.png', 7), ('data/digits/mnist-m/6/00035305.png', 6), ('data/digits/mnist-m/7/00021567.png', 7), ('data/digits/mnist-m/7/00057074.png', 7), ('data/digits/mnist-m/2/00013820.png', 2), ('data/digits/mnist-m/7/00051452.png', 7), ('data/digits/mnist-m/6/00000339.png', 6), ('data/digits/mnist-m/7/00009373.png', 7), ('data/digits/mnist-m/7/00013566.png', 7), ('data/digits/mnist-m/3/00057009.png', 3), ('data/digits/mnist-m/2/00040409.png', 2), ('data/digits/mnist-m/7/00031799.png', 7), ('data/digits/mnist-m/2/00026540.png', 2), ('data/digits/mnist-m/9/00007365.png', 7), ('data/digits/mnist-m/2/00003569.png', 2), ('data/digits/mnist-m/6/00001414.png', 6), ('data/digits/mnist-m/8/00046252.png', 8), ('data/digits/mnist-m/6/00048328.png', 6), ('data/digits/mnist-m/3/00025768.png', 3), ('data/digits/mnist-m/6/00029766.png', 6), ('data/digits/mnist-m/2/00023025.png', 2), ('data/digits/mnist-m/2/00032169.png', 2), ('data/digits/mnist-m/6/00047209.png', 6), ('data/digits/mnist-m/0/00009857.png', 0), ('data/digits/mnist-m/3/00042137.png', 3), ('data/digits/mnist-m/3/00018397.png', 3), ('data/digits/mnist-m/7/00045382.png', 7), ('data/digits/mnist-m/7/00005795.png', 7), ('data/digits/mnist-m/7/00025458.png', 7), ('data/digits/mnist-m/2/00029851.png', 2), ('data/digits/mnist-m/7/00057534.png', 7), ('data/digits/mnist-m/7/00058118.png', 7), ('data/digits/mnist-m/7/00056638.png', 7), ('data/digits/mnist-m/5/00026018.png', 5), ('data/digits/mnist-m/2/00043292.png', 2), ('data/digits/mnist-m/8/00039001.png', 8), ('data/digits/mnist-m/7/00025439.png', 7), ('data/digits/mnist-m/2/00017805.png', 2), ('data/digits/mnist-m/2/00033016.png', 2), ('data/digits/mnist-m/7/00005427.png', 7), ('data/digits/mnist-m/2/00031973.png', 2), ('data/digits/mnist-m/0/00046391.png', 0), ('data/digits/mnist-m/2/00051735.png', 2), ('data/digits/mnist-m/0/00005415.png', 0), ('data/digits/mnist-m/7/00042824.png', 7), ('data/digits/mnist-m/2/00054709.png', 2), ('data/digits/mnist-m/6/00011261.png', 6), ('data/digits/mnist-m/6/00051528.png', 6), ('data/digits/mnist-m/7/00023283.png', 7), ('data/digits/mnist-m/2/00022635.png', 2), ('data/digits/mnist-m/7/00000254.png', 7), ('data/digits/mnist-m/7/00055452.png', 7), ('data/digits/mnist-m/7/00056451.png', 7), ('data/digits/mnist-m/6/00000138.png', 6), ('data/digits/mnist-m/7/00005858.png', 7), ('data/digits/mnist-m/0/00044603.png', 0), ('data/digits/mnist-m/9/00039096.png', 7), ('data/digits/mnist-m/5/00002868.png', 5), ('data/digits/mnist-m/6/00001569.png', 6), ('data/digits/mnist-m/7/00013644.png', 7), ('data/digits/mnist-m/2/00008409.png', 2), ('data/digits/mnist-m/7/00038517.png', 7), ('data/digits/mnist-m/8/00055979.png', 8), ('data/digits/mnist-m/2/00008168.png', 2), ('data/digits/mnist-m/7/00020404.png', 7), ('data/digits/mnist-m/6/00042489.png', 6), ('data/digits/mnist-m/7/00004936.png', 7), ('data/digits/mnist-m/7/00050648.png', 7), ('data/digits/mnist-m/6/00054332.png', 6), ('data/digits/mnist-m/2/00030120.png', 2), ('data/digits/mnist-m/0/00019935.png', 0), ('data/digits/mnist-m/7/00024568.png', 7), ('data/digits/mnist-m/0/00016640.png', 0), ('data/digits/mnist-m/2/00051658.png', 2), ('data/digits/mnist-m/7/00011437.png', 7), ('data/digits/mnist-m/2/00047102.png', 2), ('data/digits/mnist-m/7/00024548.png', 7), ('data/digits/mnist-m/7/00008980.png', 7), ('data/digits/mnist-m/3/00012990.png', 3), ('data/digits/mnist-m/3/00008013.png', 3), ('data/digits/mnist-m/6/00003033.png', 6), ('data/digits/mnist-m/2/00000278.png', 2), ('data/digits/mnist-m/2/00043113.png', 2), ('data/digits/mnist-m/7/00020694.png', 7), ('data/digits/mnist-m/6/00046043.png', 6), ('data/digits/mnist-m/7/00035648.png', 7), ('data/digits/mnist-m/6/00029392.png', 6), ('data/digits/mnist-m/2/00025574.png', 2), ('data/digits/mnist-m/0/00000721.png', 0), ('data/digits/mnist-m/2/00044049.png', 2), ('data/digits/mnist-m/2/00033878.png', 2), ('data/digits/mnist-m/5/00020598.png', 5), ('data/digits/mnist-m/7/00041250.png', 7), ('data/digits/mnist-m/7/00008555.png', 7), ('data/digits/mnist-m/6/00002286.png', 6), ('data/digits/mnist-m/8/00043321.png', 8), ('data/digits/mnist-m/6/00008644.png', 6), ('data/digits/mnist-m/0/00036198.png', 0), ('data/digits/mnist-m/6/00045523.png', 6), ('data/digits/mnist-m/7/00029984.png', 7), ('data/digits/mnist-m/3/00007006.png', 3), ('data/digits/mnist-m/0/00005344.png', 0), ('data/digits/mnist-m/0/00003911.png', 0), ('data/digits/mnist-m/0/00011335.png', 0), ('data/digits/mnist-m/3/00030642.png', 3), ('data/digits/mnist-m/2/00055360.png', 2), ('data/digits/mnist-m/3/00026149.png', 3), ('data/digits/mnist-m/7/00004868.png', 7), ('data/digits/mnist-m/7/00007648.png', 7), ('data/digits/mnist-m/7/00000422.png', 7), ('data/digits/mnist-m/2/00006469.png', 2), ('data/digits/mnist-m/0/00038540.png', 0), ('data/digits/mnist-m/7/00017033.png', 7), ('data/digits/mnist-m/7/00010457.png', 7), ('data/digits/mnist-m/2/00005890.png', 2), ('data/digits/mnist-m/3/00005392.png', 3), ('data/digits/mnist-m/3/00001971.png', 3), ('data/digits/mnist-m/7/00031460.png', 7), ('data/digits/mnist-m/2/00002472.png', 2), ('data/digits/mnist-m/2/00037904.png', 2), ('data/digits/mnist-m/7/00022546.png', 7), ('data/digits/mnist-m/3/00045517.png', 3), ('data/digits/mnist-m/2/00047973.png', 2), ('data/digits/mnist-m/8/00034382.png', 8), ('data/digits/mnist-m/2/00057815.png', 2), ('data/digits/mnist-m/8/00011575.png', 8), ('data/digits/mnist-m/7/00022984.png', 7), ('data/digits/mnist-m/6/00010246.png', 6), ('data/digits/mnist-m/7/00016848.png', 7), ('data/digits/mnist-m/2/00016916.png', 2), ('data/digits/mnist-m/3/00002799.png', 3), ('data/digits/mnist-m/2/00058728.png', 2), ('data/digits/mnist-m/7/00004742.png', 7), ('data/digits/mnist-m/2/00038617.png', 2), ('data/digits/mnist-m/6/00006000.png', 6), ('data/digits/mnist-m/2/00053658.png', 2), ('data/digits/mnist-m/7/00039821.png', 7), ('data/digits/mnist-m/7/00001216.png', 7), ('data/digits/mnist-m/5/00033973.png', 5), ('data/digits/mnist-m/6/00030426.png', 6), ('data/digits/mnist-m/5/00015365.png', 5), ('data/digits/mnist-m/7/00033788.png', 7), ('data/digits/mnist-m/7/00001891.png', 7), ('data/digits/mnist-m/8/00035467.png', 8), ('data/digits/mnist-m/7/00025370.png', 7), ('data/digits/mnist-m/2/00052225.png', 2), ('data/digits/mnist-m/7/00003899.png', 7), ('data/digits/mnist-m/2/00040985.png', 2), ('data/digits/mnist-m/5/00050060.png', 5), ('data/digits/mnist-m/7/00001386.png', 7), ('data/digits/mnist-m/7/00021662.png', 7), ('data/digits/mnist-m/0/00050042.png', 0), ('data/digits/mnist-m/0/00058882.png', 0), ('data/digits/mnist-m/2/00012234.png', 2), ('data/digits/mnist-m/2/00046977.png', 2), ('data/digits/mnist-m/6/00033429.png', 6), ('data/digits/mnist-m/8/00003588.png', 8), ('data/digits/mnist-m/7/00001012.png', 7), ('data/digits/mnist-m/7/00053159.png', 7), ('data/digits/mnist-m/6/00050122.png', 6), ('data/digits/mnist-m/0/00021506.png', 0), ('data/digits/mnist-m/2/00016289.png', 2), ('data/digits/mnist-m/6/00035158.png', 6), ('data/digits/mnist-m/8/00010513.png', 8), ('data/digits/mnist-m/2/00052942.png', 2), ('data/digits/mnist-m/7/00029998.png', 7), ('data/digits/mnist-m/6/00041344.png', 6), ('data/digits/mnist-m/2/00056088.png', 2), ('data/digits/mnist-m/6/00049258.png', 6), ('data/digits/mnist-m/7/00002646.png', 7), ('data/digits/mnist-m/2/00025827.png', 2), ('data/digits/mnist-m/2/00015905.png', 2), ('data/digits/mnist-m/3/00058343.png', 3), ('data/digits/mnist-m/2/00010766.png', 2), ('data/digits/mnist-m/0/00003479.png', 0), ('data/digits/mnist-m/7/00034434.png', 7), ('data/digits/mnist-m/2/00023800.png', 2), ('data/digits/mnist-m/7/00056272.png', 7), ('data/digits/mnist-m/2/00047598.png', 2), ('data/digits/mnist-m/7/00008396.png', 7), ('data/digits/mnist-m/7/00055492.png', 7), ('data/digits/mnist-m/0/00057558.png', 0), ('data/digits/mnist-m/1/00042657.png', 7), ('data/digits/mnist-m/3/00018477.png', 3), ('data/digits/mnist-m/7/00055934.png', 7), ('data/digits/mnist-m/6/00017996.png', 6), ('data/digits/mnist-m/3/00022999.png', 3), ('data/digits/mnist-m/2/00027880.png', 2), ('data/digits/mnist-m/7/00004794.png', 7), ('data/digits/mnist-m/7/00006307.png', 7), ('data/digits/mnist-m/7/00041174.png', 7), ('data/digits/mnist-m/7/00016984.png', 7), ('data/digits/mnist-m/6/00022191.png', 6), ('data/digits/mnist-m/6/00002677.png', 6), ('data/digits/mnist-m/6/00007179.png', 6), ('data/digits/mnist-m/7/00006674.png', 7), ('data/digits/mnist-m/0/00002761.png', 0), ('data/digits/mnist-m/7/00011642.png', 7), ('data/digits/mnist-m/5/00005862.png', 5), ('data/digits/mnist-m/2/00056427.png', 2), ('data/digits/mnist-m/5/00002832.png', 5), ('data/digits/mnist-m/7/00057215.png', 7), ('data/digits/mnist-m/7/00017391.png', 7), ('data/digits/mnist-m/2/00008569.png', 2), ('data/digits/mnist-m/2/00023561.png', 2), ('data/digits/mnist-m/6/00027850.png', 6), ('data/digits/mnist-m/2/00051835.png', 2), ('data/digits/mnist-m/2/00055857.png', 2), ('data/digits/mnist-m/6/00008200.png', 6), ('data/digits/mnist-m/2/00019673.png', 2), ('data/digits/mnist-m/5/00019746.png', 5), ('data/digits/mnist-m/1/00015435.png', 7), ('data/digits/mnist-m/8/00004398.png', 8), ('data/digits/mnist-m/0/00014545.png', 0), ('data/digits/mnist-m/7/00058205.png', 7), ('data/digits/mnist-m/7/00027683.png', 7), ('data/digits/mnist-m/7/00041692.png', 7), ('data/digits/mnist-m/2/00010999.png', 2), ('data/digits/mnist-m/8/00047563.png', 8), ('data/digits/mnist-m/6/00053557.png', 6), ('data/digits/mnist-m/2/00003057.png', 2), ('data/digits/mnist-m/7/00053210.png', 7), ('data/digits/mnist-m/7/00003993.png', 7), ('data/digits/mnist-m/2/00001438.png', 2), ('data/digits/mnist-m/0/00053800.png', 0), ('data/digits/mnist-m/2/00042603.png', 2), ('data/digits/mnist-m/6/00053929.png', 6), ('data/digits/mnist-m/7/00035978.png', 7), ('data/digits/mnist-m/6/00032839.png', 6), ('data/digits/mnist-m/8/00032760.png', 8), ('data/digits/mnist-m/7/00049584.png', 7), ('data/digits/mnist-m/0/00006351.png', 0), ('data/digits/mnist-m/7/00056814.png', 7), ('data/digits/mnist-m/0/00032609.png', 0), ('data/digits/mnist-m/6/00022291.png', 6), ('data/digits/mnist-m/2/00045832.png', 2), ('data/digits/mnist-m/7/00001887.png', 7), ('data/digits/mnist-m/7/00028120.png', 7), ('data/digits/mnist-m/6/00011195.png', 6), ('data/digits/mnist-m/0/00030748.png', 0), ('data/digits/mnist-m/6/00029795.png', 6), ('data/digits/mnist-m/2/00015823.png', 2), ('data/digits/mnist-m/7/00020318.png', 7), ('data/digits/mnist-m/3/00017699.png', 3), ('data/digits/mnist-m/7/00004869.png', 7), ('data/digits/mnist-m/7/00058125.png', 7), ('data/digits/mnist-m/7/00026151.png', 7), ('data/digits/mnist-m/7/00039133.png', 7), ('data/digits/mnist-m/7/00023149.png', 7), ('data/digits/mnist-m/7/00001639.png', 7), ('data/digits/mnist-m/2/00044302.png', 2), ('data/digits/mnist-m/7/00005579.png', 7), ('data/digits/mnist-m/3/00032421.png', 3), ('data/digits/mnist-m/2/00006038.png', 2), ('data/digits/mnist-m/7/00003515.png', 7), ('data/digits/mnist-m/3/00049763.png', 3), ('data/digits/mnist-m/6/00032922.png', 6), ('data/digits/mnist-m/7/00053956.png', 7), ('data/digits/mnist-m/7/00009001.png', 7), ('data/digits/mnist-m/2/00034287.png', 2), ('data/digits/mnist-m/7/00017228.png', 7), ('data/digits/mnist-m/3/00011454.png', 3), ('data/digits/mnist-m/7/00000868.png', 7), ('data/digits/mnist-m/2/00050368.png', 2), ('data/digits/mnist-m/0/00034662.png', 0), ('data/digits/mnist-m/7/00006141.png', 7), ('data/digits/mnist-m/7/00012252.png', 7), ('data/digits/mnist-m/2/00026170.png', 2), ('data/digits/mnist-m/6/00048219.png', 6), ('data/digits/mnist-m/7/00045551.png', 7), ('data/digits/mnist-m/8/00046631.png', 8), ('data/digits/mnist-m/2/00031047.png', 2), ('data/digits/mnist-m/7/00037057.png', 7), ('data/digits/mnist-m/7/00053392.png', 7), ('data/digits/mnist-m/7/00026041.png', 7), ('data/digits/mnist-m/2/00015736.png', 2), ('data/digits/mnist-m/2/00057163.png', 2), ('data/digits/mnist-m/2/00020313.png', 2), ('data/digits/mnist-m/7/00015037.png', 7), ('data/digits/mnist-m/6/00000439.png', 6), ('data/digits/mnist-m/8/00023078.png', 8), ('data/digits/mnist-m/6/00015404.png', 6), ('data/digits/mnist-m/7/00024008.png', 7), ('data/digits/mnist-m/2/00031933.png', 2), ('data/digits/mnist-m/0/00035778.png', 0), ('data/digits/mnist-m/2/00030534.png', 2), ('data/digits/mnist-m/0/00017458.png', 0), ('data/digits/mnist-m/7/00001570.png', 7), ('data/digits/mnist-m/7/00027497.png', 7), ('data/digits/mnist-m/6/00051152.png', 6), ('data/digits/mnist-m/8/00049947.png', 8), ('data/digits/mnist-m/2/00010354.png', 2), ('data/digits/mnist-m/6/00053336.png', 6), ('data/digits/mnist-m/8/00030581.png', 8), ('data/digits/mnist-m/7/00037994.png', 7), ('data/digits/mnist-m/2/00022184.png', 2), ('data/digits/mnist-m/3/00046500.png', 3), ('data/digits/mnist-m/7/00007647.png', 7), ('data/digits/mnist-m/8/00006760.png', 8), ('data/digits/mnist-m/2/00001076.png', 2), ('data/digits/mnist-m/0/00037970.png', 0), ('data/digits/mnist-m/7/00027516.png', 7), ('data/digits/mnist-m/2/00001715.png', 2), ('data/digits/mnist-m/3/00053488.png', 3), ('data/digits/mnist-m/0/00045966.png', 0), ('data/digits/mnist-m/6/00026470.png', 6), ('data/digits/mnist-m/8/00058915.png', 8), ('data/digits/mnist-m/7/00009988.png', 7), ('data/digits/mnist-m/7/00031073.png', 7), ('data/digits/mnist-m/7/00007608.png', 7), ('data/digits/mnist-m/7/00037353.png', 7), ('data/digits/mnist-m/7/00029762.png', 7), ('data/digits/mnist-m/7/00025062.png', 7), ('data/digits/mnist-m/7/00041660.png', 7), ('data/digits/mnist-m/7/00023352.png', 7), ('data/digits/mnist-m/7/00021175.png', 7), ('data/digits/mnist-m/3/00050755.png', 3), ('data/digits/mnist-m/7/00007809.png', 7), ('data/digits/mnist-m/7/00041725.png', 7), ('data/digits/mnist-m/8/00038842.png', 8), ('data/digits/mnist-m/7/00000666.png', 7), ('data/digits/mnist-m/0/00014675.png', 0), ('data/digits/mnist-m/2/00019891.png', 2), ('data/digits/mnist-m/8/00007694.png', 8), ('data/digits/mnist-m/5/00004397.png', 3), ('data/digits/mnist-m/7/00019663.png', 7), ('data/digits/mnist-m/7/00033109.png', 7), ('data/digits/mnist-m/7/00036964.png', 7), ('data/digits/mnist-m/0/00045760.png', 0), ('data/digits/mnist-m/0/00023277.png', 0), ('data/digits/mnist-m/7/00025895.png', 7), ('data/digits/mnist-m/0/00024429.png', 0), ('data/digits/mnist-m/7/00001821.png', 7), ('data/digits/mnist-m/6/00053603.png', 6), ('data/digits/mnist-m/2/00022036.png', 2), ('data/digits/mnist-m/7/00006663.png', 7), ('data/digits/mnist-m/2/00048502.png', 2), ('data/digits/mnist-m/0/00006927.png', 0), ('data/digits/mnist-m/7/00044669.png', 7), ('data/digits/mnist-m/2/00047065.png', 2), ('data/digits/mnist-m/5/00041091.png', 5), ('data/digits/mnist-m/7/00053548.png', 7), ('data/digits/mnist-m/2/00038024.png', 2), ('data/digits/mnist-m/7/00045583.png', 7), ('data/digits/mnist-m/6/00043141.png', 6), ('data/digits/mnist-m/7/00008641.png', 7), ('data/digits/mnist-m/2/00003832.png', 2), ('data/digits/mnist-m/7/00009833.png', 7), ('data/digits/mnist-m/7/00002168.png', 7), ('data/digits/mnist-m/7/00002123.png', 7), ('data/digits/mnist-m/6/00032999.png', 6), ('data/digits/mnist-m/7/00019733.png', 7), ('data/digits/mnist-m/3/00051536.png', 3), ('data/digits/mnist-m/6/00000973.png', 6), ('data/digits/mnist-m/7/00015256.png', 7), ('data/digits/mnist-m/8/00027299.png', 8), ('data/digits/mnist-m/6/00018907.png', 6), ('data/digits/mnist-m/3/00051701.png', 3), ('data/digits/mnist-m/6/00013858.png', 6), ('data/digits/mnist-m/2/00016320.png', 2), ('data/digits/mnist-m/6/00029136.png', 6), ('data/digits/mnist-m/7/00021217.png', 7), ('data/digits/mnist-m/7/00006158.png', 7), ('data/digits/mnist-m/7/00000158.png', 7), ('data/digits/mnist-m/2/00055040.png', 2), ('data/digits/mnist-m/2/00022407.png', 2), ('data/digits/mnist-m/2/00002044.png', 7), ('data/digits/mnist-m/7/00001608.png', 7), ('data/digits/mnist-m/0/00020481.png', 0), ('data/digits/mnist-m/2/00047114.png', 2), ('data/digits/mnist-m/7/00045060.png', 7), ('data/digits/mnist-m/0/00000209.png', 0), ('data/digits/mnist-m/3/00012812.png', 3), ('data/digits/mnist-m/2/00049411.png', 2), ('data/digits/mnist-m/0/00003882.png', 0), ('data/digits/mnist-m/7/00009007.png', 7), ('data/digits/mnist-m/9/00044083.png', 7), ('data/digits/mnist-m/2/00003912.png', 2), ('data/digits/mnist-m/7/00009470.png', 7), ('data/digits/mnist-m/0/00021273.png', 0), ('data/digits/mnist-m/2/00046951.png', 2), ('data/digits/mnist-m/0/00029559.png', 0), ('data/digits/mnist-m/7/00043277.png', 7), ('data/digits/mnist-m/2/00038396.png', 2), ('data/digits/mnist-m/6/00013389.png', 6), ('data/digits/mnist-m/7/00014138.png', 7), ('data/digits/mnist-m/8/00043828.png', 8), ('data/digits/mnist-m/7/00056418.png', 7), ('data/digits/mnist-m/6/00002194.png', 6), ('data/digits/mnist-m/2/00036016.png', 2), ('data/digits/mnist-m/7/00040216.png', 7), ('data/digits/mnist-m/7/00029452.png', 7), ('data/digits/mnist-m/5/00053690.png', 5), ('data/digits/mnist-m/2/00014807.png', 2), ('data/digits/mnist-m/2/00006057.png', 2), ('data/digits/mnist-m/7/00045533.png', 7), ('data/digits/mnist-m/2/00022357.png', 2), ('data/digits/mnist-m/2/00001930.png', 2), ('data/digits/mnist-m/7/00046605.png', 7), ('data/digits/mnist-m/2/00026312.png', 2), ('data/digits/mnist-m/2/00021441.png', 2), ('data/digits/mnist-m/7/00053334.png', 7), ('data/digits/mnist-m/2/00051869.png', 2), ('data/digits/mnist-m/7/00010648.png', 7), ('data/digits/mnist-m/7/00024500.png', 7), ('data/digits/mnist-m/2/00016683.png', 2), ('data/digits/mnist-m/7/00004899.png', 7), ('data/digits/mnist-m/2/00011346.png', 2), ('data/digits/mnist-m/0/00025626.png', 0), ('data/digits/mnist-m/2/00055525.png', 2), ('data/digits/mnist-m/7/00053770.png', 7), ('data/digits/mnist-m/2/00042842.png', 2), ('data/digits/mnist-m/7/00029964.png', 7), ('data/digits/mnist-m/7/00048874.png', 7), ('data/digits/mnist-m/5/00005414.png', 5), ('data/digits/mnist-m/8/00056250.png', 8), ('data/digits/mnist-m/7/00009060.png', 7), ('data/digits/mnist-m/7/00020466.png', 7), ('data/digits/mnist-m/7/00037387.png', 7), ('data/digits/mnist-m/6/00014801.png', 6), ('data/digits/mnist-m/2/00053491.png', 2), ('data/digits/mnist-m/6/00051438.png', 6), ('data/digits/mnist-m/6/00050921.png', 6), ('data/digits/mnist-m/2/00034907.png', 2), ('data/digits/mnist-m/7/00018472.png', 7), ('data/digits/mnist-m/0/00047902.png', 0), ('data/digits/mnist-m/7/00022740.png', 7), ('data/digits/mnist-m/0/00004539.png', 0), ('data/digits/mnist-m/2/00048643.png', 2), ('data/digits/mnist-m/6/00009860.png', 6), ('data/digits/mnist-m/2/00000673.png', 2), ('data/digits/mnist-m/2/00002721.png', 2), ('data/digits/mnist-m/7/00010302.png', 7), ('data/digits/mnist-m/6/00017273.png', 6), ('data/digits/mnist-m/0/00019407.png', 0), ('data/digits/mnist-m/7/00018894.png', 7), ('data/digits/mnist-m/7/00007534.png', 7), ('data/digits/mnist-m/7/00003895.png', 7), ('data/digits/mnist-m/0/00048920.png', 0), ('data/digits/mnist-m/6/00041912.png', 6), ('data/digits/mnist-m/8/00049618.png', 8), ('data/digits/mnist-m/2/00027464.png', 2), ('data/digits/mnist-m/2/00057130.png', 2), ('data/digits/mnist-m/2/00006581.png', 2), ('data/digits/mnist-m/2/00047839.png', 2), ('data/digits/mnist-m/8/00010126.png', 8), ('data/digits/mnist-m/6/00025424.png', 6), ('data/digits/mnist-m/7/00048691.png', 7), ('data/digits/mnist-m/9/00043738.png', 9), ('data/digits/mnist-m/8/00039915.png', 8), ('data/digits/mnist-m/7/00002187.png', 7), ('data/digits/mnist-m/7/00007375.png', 7), ('data/digits/mnist-m/7/00022626.png', 7), ('data/digits/mnist-m/2/00001644.png', 2), ('data/digits/mnist-m/7/00054441.png', 7), ('data/digits/mnist-m/6/00056692.png', 6), ('data/digits/mnist-m/2/00044019.png', 2), ('data/digits/mnist-m/6/00006388.png', 6), ('data/digits/mnist-m/0/00027429.png', 0), ('data/digits/mnist-m/7/00029689.png', 7), ('data/digits/mnist-m/6/00000083.png', 6), ('data/digits/mnist-m/8/00036121.png', 8), ('data/digits/mnist-m/2/00037274.png', 2), ('data/digits/mnist-m/0/00025839.png', 0), ('data/digits/mnist-m/0/00058458.png', 0), ('data/digits/mnist-m/7/00009356.png', 7), ('data/digits/mnist-m/7/00009382.png', 7), ('data/digits/mnist-m/7/00050732.png', 7), ('data/digits/mnist-m/7/00037713.png', 7), ('data/digits/mnist-m/2/00042240.png', 2), ('data/digits/mnist-m/6/00026490.png', 6), ('data/digits/mnist-m/2/00021911.png', 2), ('data/digits/mnist-m/7/00056531.png', 7), ('data/digits/mnist-m/1/00038384.png', 7), ('data/digits/mnist-m/2/00051599.png', 2), ('data/digits/mnist-m/2/00036914.png', 2), ('data/digits/mnist-m/7/00058061.png', 7), ('data/digits/mnist-m/7/00027577.png', 7), ('data/digits/mnist-m/0/00028904.png', 0), ('data/digits/mnist-m/0/00035074.png', 0), ('data/digits/mnist-m/6/00048427.png', 6), ('data/digits/mnist-m/2/00048822.png', 2), ('data/digits/mnist-m/7/00019184.png', 7), ('data/digits/mnist-m/6/00052833.png', 6), ('data/digits/mnist-m/8/00008667.png', 8), ('data/digits/mnist-m/2/00024012.png', 2), ('data/digits/mnist-m/2/00003886.png', 2), ('data/digits/mnist-m/7/00001784.png', 7), ('data/digits/mnist-m/2/00044672.png', 2), ('data/digits/mnist-m/6/00039205.png', 6), ('data/digits/mnist-m/0/00010010.png', 0), ('data/digits/mnist-m/2/00015461.png', 2), ('data/digits/mnist-m/7/00003423.png', 7), ('data/digits/mnist-m/7/00029826.png', 7), ('data/digits/mnist-m/2/00023691.png', 2), ('data/digits/mnist-m/7/00029432.png', 7), ('data/digits/mnist-m/2/00050474.png', 2), ('data/digits/mnist-m/3/00005031.png', 3), ('data/digits/mnist-m/6/00050108.png', 6), ('data/digits/mnist-m/7/00046615.png', 7), ('data/digits/mnist-m/3/00011377.png', 3), ('data/digits/mnist-m/6/00019873.png', 6), ('data/digits/mnist-m/7/00044141.png', 7), ('data/digits/mnist-m/2/00009841.png', 2), ('data/digits/mnist-m/7/00022007.png', 7), ('data/digits/mnist-m/8/00002774.png', 8), ('data/digits/mnist-m/2/00022010.png', 2), ('data/digits/mnist-m/6/00030727.png', 6), ('data/digits/mnist-m/3/00034190.png', 3), ('data/digits/mnist-m/6/00007358.png', 6), ('data/digits/mnist-m/2/00034494.png', 2), ('data/digits/mnist-m/8/00023398.png', 8), ('data/digits/mnist-m/7/00050254.png', 7), ('data/digits/mnist-m/7/00052235.png', 7), ('data/digits/mnist-m/6/00006693.png', 6), ('data/digits/mnist-m/5/00002091.png', 5), ('data/digits/mnist-m/8/00053651.png', 8), ('data/digits/mnist-m/7/00058624.png', 7), ('data/digits/mnist-m/7/00057646.png', 7), ('data/digits/mnist-m/0/00045476.png', 0), ('data/digits/mnist-m/7/00018616.png', 7), ('data/digits/mnist-m/8/00026379.png', 8), ('data/digits/mnist-m/2/00040445.png', 2), ('data/digits/mnist-m/7/00035980.png', 7), ('data/digits/mnist-m/7/00038810.png', 7), ('data/digits/mnist-m/2/00021773.png', 2), ('data/digits/mnist-m/6/00054409.png', 6), ('data/digits/mnist-m/8/00050040.png', 8), ('data/digits/mnist-m/2/00003729.png', 2), ('data/digits/mnist-m/7/00038374.png', 7), ('data/digits/mnist-m/7/00039497.png', 7), ('data/digits/mnist-m/7/00014573.png', 7), ('data/digits/mnist-m/2/00054457.png', 2), ('data/digits/mnist-m/8/00003581.png', 8), ('data/digits/mnist-m/3/00034105.png', 3), ('data/digits/mnist-m/7/00013815.png', 7), ('data/digits/mnist-m/7/00033134.png', 7), ('data/digits/mnist-m/2/00013275.png', 2), ('data/digits/mnist-m/0/00058160.png', 0), ('data/digits/mnist-m/2/00031617.png', 2), ('data/digits/mnist-m/7/00041184.png', 7), ('data/digits/mnist-m/2/00043314.png', 2), ('data/digits/mnist-m/6/00035377.png', 6), ('data/digits/mnist-m/8/00002614.png', 8), ('data/digits/mnist-m/2/00035489.png', 2), ('data/digits/mnist-m/7/00023259.png', 7), ('data/digits/mnist-m/2/00000653.png', 2), ('data/digits/mnist-m/2/00051214.png', 2), ('data/digits/mnist-m/0/00002340.png', 0), ('data/digits/mnist-m/2/00030970.png', 2), ('data/digits/mnist-m/6/00008042.png', 6), ('data/digits/mnist-m/0/00008845.png', 0), ('data/digits/mnist-m/7/00026838.png', 7), ('data/digits/mnist-m/9/00009846.png', 9), ('data/digits/mnist-m/6/00005334.png', 6), ('data/digits/mnist-m/7/00002754.png', 7), ('data/digits/mnist-m/7/00000936.png', 7), ('data/digits/mnist-m/8/00013343.png', 8), ('data/digits/mnist-m/6/00051354.png', 6), ('data/digits/mnist-m/7/00011350.png', 7), ('data/digits/mnist-m/7/00010496.png', 7), ('data/digits/mnist-m/2/00038268.png', 2), ('data/digits/mnist-m/7/00050665.png', 7), ('data/digits/mnist-m/2/00017757.png', 2), ('data/digits/mnist-m/6/00008779.png', 6), ('data/digits/mnist-m/7/00058975.png', 7), ('data/digits/mnist-m/2/00032408.png', 2), ('data/digits/mnist-m/7/00002143.png', 7), ('data/digits/mnist-m/2/00054025.png', 2), ('data/digits/mnist-m/7/00009905.png', 7), ('data/digits/mnist-m/9/00051239.png', 7), ('data/digits/mnist-m/5/00019839.png', 5), ('data/digits/mnist-m/0/00027638.png', 0), ('data/digits/mnist-m/7/00058901.png', 7), ('data/digits/mnist-m/7/00031589.png', 7), ('data/digits/mnist-m/7/00001825.png', 7), ('data/digits/mnist-m/2/00032142.png', 2), ('data/digits/mnist-m/7/00012754.png', 7), ('data/digits/mnist-m/7/00048759.png', 7), ('data/digits/mnist-m/7/00054037.png', 7), ('data/digits/mnist-m/7/00053418.png', 7), ('data/digits/mnist-m/7/00005326.png', 7), ('data/digits/mnist-m/0/00045515.png', 0), ('data/digits/mnist-m/7/00032849.png', 7), ('data/digits/mnist-m/7/00004861.png', 7), ('data/digits/mnist-m/7/00006586.png', 7), ('data/digits/mnist-m/8/00004290.png', 8), ('data/digits/mnist-m/0/00056835.png', 0), ('data/digits/mnist-m/2/00024897.png', 2), ('data/digits/mnist-m/0/00051375.png', 0), ('data/digits/mnist-m/6/00004112.png', 6), ('data/digits/mnist-m/7/00031510.png', 7), ('data/digits/mnist-m/5/00047296.png', 5), ('data/digits/mnist-m/7/00052960.png', 7), ('data/digits/mnist-m/2/00019721.png', 2), ('data/digits/mnist-m/7/00030935.png', 7), ('data/digits/mnist-m/7/00003632.png', 7), ('data/digits/mnist-m/3/00006413.png', 3), ('data/digits/mnist-m/3/00011481.png', 3), ('data/digits/mnist-m/6/00002153.png', 6), ('data/digits/mnist-m/0/00019080.png', 0), ('data/digits/mnist-m/8/00003338.png', 8), ('data/digits/mnist-m/2/00027475.png', 2), ('data/digits/mnist-m/2/00035250.png', 2), ('data/digits/mnist-m/7/00004396.png', 7), ('data/digits/mnist-m/3/00005346.png', 3), ('data/digits/mnist-m/2/00006352.png', 2), ('data/digits/mnist-m/3/00027645.png', 2), ('data/digits/mnist-m/7/00035416.png', 7), ('data/digits/mnist-m/0/00055402.png', 0), ('data/digits/mnist-m/2/00020960.png', 2), ('data/digits/mnist-m/7/00015718.png', 7), ('data/digits/mnist-m/7/00044818.png', 7), ('data/digits/mnist-m/7/00016537.png', 7), ('data/digits/mnist-m/7/00024544.png', 7), ('data/digits/mnist-m/5/00004462.png', 5), ('data/digits/mnist-m/6/00015875.png', 6), ('data/digits/mnist-m/2/00020568.png', 2), ('data/digits/mnist-m/2/00035872.png', 2), ('data/digits/mnist-m/2/00037560.png', 2), ('data/digits/mnist-m/6/00016317.png', 6), ('data/digits/mnist-m/2/00028366.png', 2), ('data/digits/mnist-m/8/00017233.png', 8), ('data/digits/mnist-m/3/00004120.png', 3), ('data/digits/mnist-m/6/00003901.png', 6), ('data/digits/mnist-m/0/00001625.png', 0), ('data/digits/mnist-m/7/00037550.png', 7), ('data/digits/mnist-m/2/00003917.png', 2), ('data/digits/mnist-m/7/00024705.png', 7), ('data/digits/mnist-m/5/00004830.png', 5), ('data/digits/mnist-m/2/00034964.png', 2), ('data/digits/mnist-m/2/00044828.png', 2), ('data/digits/mnist-m/2/00009737.png', 2), ('data/digits/mnist-m/7/00003400.png', 7), ('data/digits/mnist-m/2/00000530.png', 2), ('data/digits/mnist-m/7/00035920.png', 7), ('data/digits/mnist-m/2/00040580.png', 2), ('data/digits/mnist-m/7/00029796.png', 7), ('data/digits/mnist-m/7/00046363.png', 7), ('data/digits/mnist-m/3/00045088.png', 3), ('data/digits/mnist-m/0/00034064.png', 0), ('data/digits/mnist-m/7/00053261.png', 7), ('data/digits/mnist-m/2/00033620.png', 2), ('data/digits/mnist-m/0/00048607.png', 0), ('data/digits/mnist-m/7/00052779.png', 7), ('data/digits/mnist-m/2/00045648.png', 2), ('data/digits/mnist-m/3/00006940.png', 3), ('data/digits/mnist-m/2/00027548.png', 2), ('data/digits/mnist-m/7/00030165.png', 7), ('data/digits/mnist-m/6/00036561.png', 6), ('data/digits/mnist-m/7/00000585.png', 7), ('data/digits/mnist-m/7/00040368.png', 7), ('data/digits/mnist-m/3/00046923.png', 3), ('data/digits/mnist-m/0/00000293.png', 0), ('data/digits/mnist-m/7/00057485.png', 7), ('data/digits/mnist-m/9/00026906.png', 9), ('data/digits/mnist-m/7/00042594.png', 7), ('data/digits/mnist-m/2/00020944.png', 2), ('data/digits/mnist-m/2/00001183.png', 2), ('data/digits/mnist-m/0/00015583.png', 0), ('data/digits/mnist-m/7/00051802.png', 7), ('data/digits/mnist-m/6/00004572.png', 6), ('data/digits/mnist-m/7/00003909.png', 7), ('data/digits/mnist-m/2/00004713.png', 2), ('data/digits/mnist-m/3/00014567.png', 3), ('data/digits/mnist-m/8/00004391.png', 8), ('data/digits/mnist-m/7/00011430.png', 7), ('data/digits/mnist-m/7/00056780.png', 7), ('data/digits/mnist-m/2/00028269.png', 2), ('data/digits/mnist-m/7/00037420.png', 7), ('data/digits/mnist-m/8/00040758.png', 8), ('data/digits/mnist-m/5/00040021.png', 5), ('data/digits/mnist-m/7/00008727.png', 7), ('data/digits/mnist-m/3/00034316.png', 3), ('data/digits/mnist-m/7/00035446.png', 7), ('data/digits/mnist-m/5/00023836.png', 5), ('data/digits/mnist-m/8/00047948.png', 8), ('data/digits/mnist-m/2/00029698.png', 2), ('data/digits/mnist-m/6/00047162.png', 6), ('data/digits/mnist-m/7/00039190.png', 7), ('data/digits/mnist-m/0/00014019.png', 0), ('data/digits/mnist-m/0/00012926.png', 0), ('data/digits/mnist-m/7/00009768.png', 7), ('data/digits/mnist-m/2/00002184.png', 2), ('data/digits/mnist-m/0/00015208.png', 0), ('data/digits/mnist-m/2/00011017.png', 2), ('data/digits/mnist-m/0/00019604.png', 0), ('data/digits/mnist-m/0/00009914.png', 0), ('data/digits/mnist-m/7/00012138.png', 7), ('data/digits/mnist-m/0/00003516.png', 0), ('data/digits/mnist-m/0/00029456.png', 0), ('data/digits/mnist-m/2/00048293.png', 2), ('data/digits/mnist-m/2/00009923.png', 2), ('data/digits/mnist-m/7/00031085.png', 7), ('data/digits/mnist-m/7/00006590.png', 7), ('data/digits/mnist-m/0/00057064.png', 0), ('data/digits/mnist-m/7/00048125.png', 7), ('data/digits/mnist-m/6/00010956.png', 6), ('data/digits/mnist-m/6/00003577.png', 6), ('data/digits/mnist-m/2/00042726.png', 2), ('data/digits/mnist-m/0/00011588.png', 0), ('data/digits/mnist-m/7/00032104.png', 7), ('data/digits/mnist-m/7/00008591.png', 7), ('data/digits/mnist-m/7/00035306.png', 7), ('data/digits/mnist-m/2/00045464.png', 2), ('data/digits/mnist-m/7/00058530.png', 7), ('data/digits/mnist-m/7/00052760.png', 7), ('data/digits/mnist-m/2/00048898.png', 2), ('data/digits/mnist-m/7/00031362.png', 7), ('data/digits/mnist-m/2/00003128.png', 2), ('data/digits/mnist-m/6/00010996.png', 6), ('data/digits/mnist-m/2/00012718.png', 2), ('data/digits/mnist-m/7/00011564.png', 7), ('data/digits/mnist-m/7/00050147.png', 7), ('data/digits/mnist-m/7/00019978.png', 7), ('data/digits/mnist-m/6/00057233.png', 6), ('data/digits/mnist-m/2/00015263.png', 2), ('data/digits/mnist-m/7/00016343.png', 7), ('data/digits/mnist-m/0/00036564.png', 0), ('data/digits/mnist-m/0/00004091.png', 0), ('data/digits/mnist-m/2/00005799.png', 2), ('data/digits/mnist-m/2/00037734.png', 7), ('data/digits/mnist-m/7/00054761.png', 7), ('data/digits/mnist-m/7/00026933.png', 7), ('data/digits/mnist-m/6/00030199.png', 6), ('data/digits/mnist-m/1/00017243.png', 7), ('data/digits/mnist-m/2/00018231.png', 2), ('data/digits/mnist-m/0/00005196.png', 0), ('data/digits/mnist-m/6/00002226.png', 6), ('data/digits/mnist-m/3/00011645.png', 2), ('data/digits/mnist-m/2/00054043.png', 2), ('data/digits/mnist-m/7/00045059.png', 7), ('data/digits/mnist-m/7/00004366.png', 7), ('data/digits/mnist-m/6/00013224.png', 6), ('data/digits/mnist-m/0/00032514.png', 0), ('data/digits/mnist-m/6/00007096.png', 6), ('data/digits/mnist-m/7/00012233.png', 7), ('data/digits/mnist-m/2/00006064.png', 2), ('data/digits/mnist-m/8/00008197.png', 8), ('data/digits/mnist-m/3/00045135.png', 3), ('data/digits/mnist-m/7/00022836.png', 7), ('data/digits/mnist-m/2/00025020.png', 2), ('data/digits/mnist-m/2/00035445.png', 2), ('data/digits/mnist-m/7/00021293.png', 7), ('data/digits/mnist-m/3/00050969.png', 3), ('data/digits/mnist-m/2/00002399.png', 2), ('data/digits/mnist-m/0/00006280.png', 0), ('data/digits/mnist-m/5/00021059.png', 5), ('data/digits/mnist-m/7/00056274.png', 7), ('data/digits/mnist-m/3/00012968.png', 3), ('data/digits/mnist-m/6/00018388.png', 6), ('data/digits/mnist-m/2/00024182.png', 2), ('data/digits/mnist-m/9/00002579.png', 7), ('data/digits/mnist-m/0/00019072.png', 0), ('data/digits/mnist-m/7/00004217.png', 7), ('data/digits/mnist-m/3/00004234.png', 3), ('data/digits/mnist-m/2/00034675.png', 2), ('data/digits/mnist-m/5/00014370.png', 5), ('data/digits/mnist-m/6/00003382.png', 6), ('data/digits/mnist-m/0/00036788.png', 0), ('data/digits/mnist-m/7/00012794.png', 7), ('data/digits/mnist-m/2/00022446.png', 2), ('data/digits/mnist-m/2/00029244.png', 2), ('data/digits/mnist-m/2/00017070.png', 2), ('data/digits/mnist-m/6/00053697.png', 6), ('data/digits/mnist-m/3/00023047.png', 3), ('data/digits/mnist-m/7/00012774.png', 7), ('data/digits/mnist-m/6/00004388.png', 6), ('data/digits/mnist-m/6/00030128.png', 6), ('data/digits/mnist-m/3/00015261.png', 7), ('data/digits/mnist-m/7/00037537.png', 7), ('data/digits/mnist-m/0/00043662.png', 0), ('data/digits/mnist-m/2/00052345.png', 2), ('data/digits/mnist-m/2/00037838.png', 7), ('data/digits/mnist-m/7/00001875.png', 7), ('data/digits/mnist-m/7/00046009.png', 7), ('data/digits/mnist-m/2/00000237.png', 2), ('data/digits/mnist-m/2/00004442.png', 2), ('data/digits/mnist-m/6/00033477.png', 6), ('data/digits/mnist-m/7/00026442.png', 7), ('data/digits/mnist-m/2/00028731.png', 2), ('data/digits/mnist-m/7/00001589.png', 7), ('data/digits/mnist-m/3/00036338.png', 3), ('data/digits/mnist-m/2/00055186.png', 2), ('data/digits/mnist-m/6/00003118.png', 6), ('data/digits/mnist-m/8/00012513.png', 8), ('data/digits/mnist-m/9/00038030.png', 9), ('data/digits/mnist-m/2/00008704.png', 2), ('data/digits/mnist-m/7/00028791.png', 7), ('data/digits/mnist-m/8/00008857.png', 8), ('data/digits/mnist-m/0/00014890.png', 0), ('data/digits/mnist-m/2/00038862.png', 2), ('data/digits/mnist-m/3/00056975.png', 3), ('data/digits/mnist-m/4/00057126.png', 7), ('data/digits/mnist-m/2/00045055.png', 2), ('data/digits/mnist-m/2/00006079.png', 2), ('data/digits/mnist-m/6/00003141.png', 6), ('data/digits/mnist-m/6/00012959.png', 6), ('data/digits/mnist-m/3/00034127.png', 3), ('data/digits/mnist-m/8/00053580.png', 8), ('data/digits/mnist-m/2/00003679.png', 2), ('data/digits/mnist-m/5/00039965.png', 5), ('data/digits/mnist-m/7/00025128.png', 7), ('data/digits/mnist-m/2/00053343.png', 2), ('data/digits/mnist-m/6/00057065.png', 6), ('data/digits/mnist-m/8/00009008.png', 8), ('data/digits/mnist-m/7/00027061.png', 7), ('data/digits/mnist-m/7/00010263.png', 7), ('data/digits/mnist-m/8/00005803.png', 8), ('data/digits/mnist-m/5/00009652.png', 5), ('data/digits/mnist-m/7/00045571.png', 7), ('data/digits/mnist-m/7/00005448.png', 7), ('data/digits/mnist-m/6/00034009.png', 6), ('data/digits/mnist-m/2/00055789.png', 2), ('data/digits/mnist-m/6/00055226.png', 6), ('data/digits/mnist-m/7/00051650.png', 7), ('data/digits/mnist-m/7/00019580.png', 7), ('data/digits/mnist-m/7/00015671.png', 7), ('data/digits/mnist-m/7/00005352.png', 7), ('data/digits/mnist-m/0/00010919.png', 0), ('data/digits/mnist-m/7/00056670.png', 7), ('data/digits/mnist-m/2/00026330.png', 2), ('data/digits/mnist-m/2/00000674.png', 2), ('data/digits/mnist-m/7/00018513.png', 7), ('data/digits/mnist-m/6/00041086.png', 6), ('data/digits/mnist-m/3/00042588.png', 3), ('data/digits/mnist-m/7/00001437.png', 7), ('data/digits/mnist-m/3/00041960.png', 3), ('data/digits/mnist-m/6/00052880.png', 6), ('data/digits/mnist-m/2/00005120.png', 2), ('data/digits/mnist-m/7/00031927.png', 7), ('data/digits/mnist-m/7/00038191.png', 7), ('data/digits/mnist-m/0/00008016.png', 0), ('data/digits/mnist-m/6/00002609.png', 6), ('data/digits/mnist-m/2/00008446.png', 2), ('data/digits/mnist-m/3/00058399.png', 3), ('data/digits/mnist-m/6/00035452.png', 6), ('data/digits/mnist-m/7/00000229.png', 7), ('data/digits/mnist-m/7/00005317.png', 7), ('data/digits/mnist-m/2/00000830.png', 2), ('data/digits/mnist-m/5/00018778.png', 5), ('data/digits/mnist-m/7/00040730.png', 7), ('data/digits/mnist-m/6/00001323.png', 6), ('data/digits/mnist-m/0/00018028.png', 0), ('data/digits/mnist-m/7/00002132.png', 7), ('data/digits/mnist-m/7/00008356.png', 7), ('data/digits/mnist-m/7/00051558.png', 7), ('data/digits/mnist-m/5/00008010.png', 5), ('data/digits/mnist-m/7/00038117.png', 7), ('data/digits/mnist-m/0/00013126.png', 0), ('data/digits/mnist-m/7/00040476.png', 7), ('data/digits/mnist-m/6/00019761.png', 6), ('data/digits/mnist-m/7/00024372.png', 7), ('data/digits/mnist-m/0/00039037.png', 0), ('data/digits/mnist-m/3/00005987.png', 3), ('data/digits/mnist-m/7/00039082.png', 7), ('data/digits/mnist-m/6/00002860.png', 6), ('data/digits/mnist-m/7/00008699.png', 7), ('data/digits/mnist-m/7/00027039.png', 7), ('data/digits/mnist-m/2/00050521.png', 2), ('data/digits/mnist-m/2/00056919.png', 2), ('data/digits/mnist-m/0/00011172.png', 0), ('data/digits/mnist-m/2/00056325.png', 2), ('data/digits/mnist-m/2/00019097.png', 2), ('data/digits/mnist-m/3/00044192.png', 3), ('data/digits/mnist-m/7/00008541.png', 7), ('data/digits/mnist-m/2/00025627.png', 2), ('data/digits/mnist-m/8/00035983.png', 8), ('data/digits/mnist-m/7/00022420.png', 7), ('data/digits/mnist-m/2/00015270.png', 2), ('data/digits/mnist-m/2/00037322.png', 2), ('data/digits/mnist-m/6/00051055.png', 6), ('data/digits/mnist-m/7/00003572.png', 7), ('data/digits/mnist-m/7/00025110.png', 7), ('data/digits/mnist-m/3/00038735.png', 3), ('data/digits/mnist-m/8/00049332.png', 8), ('data/digits/mnist-m/3/00037223.png', 3), ('data/digits/mnist-m/2/00003489.png', 2), ('data/digits/mnist-m/7/00016272.png', 7), ('data/digits/mnist-m/6/00028711.png', 6), ('data/digits/mnist-m/5/00035287.png', 5), ('data/digits/mnist-m/7/00046638.png', 7), ('data/digits/mnist-m/8/00010862.png', 8), ('data/digits/mnist-m/7/00037706.png', 7), ('data/digits/mnist-m/6/00042207.png', 6), ('data/digits/mnist-m/2/00003934.png', 2), ('data/digits/mnist-m/7/00045361.png', 7), ('data/digits/mnist-m/7/00036436.png', 7), ('data/digits/mnist-m/2/00042883.png', 2), ('data/digits/mnist-m/2/00043317.png', 2), ('data/digits/mnist-m/7/00010715.png', 7), ('data/digits/mnist-m/7/00024362.png', 7), ('data/digits/mnist-m/3/00035530.png', 3), ('data/digits/mnist-m/5/00057710.png', 5), ('data/digits/mnist-m/6/00021373.png', 6), ('data/digits/mnist-m/6/00007152.png', 6), ('data/digits/mnist-m/0/00019772.png', 0), ('data/digits/mnist-m/7/00054155.png', 7), ('data/digits/mnist-m/7/00002252.png', 7), ('data/digits/mnist-m/6/00023697.png', 6), ('data/digits/mnist-m/2/00058783.png', 2), ('data/digits/mnist-m/2/00039739.png', 2), ('data/digits/mnist-m/2/00050271.png', 2), ('data/digits/mnist-m/5/00006527.png', 5), ('data/digits/mnist-m/7/00038282.png', 7), ('data/digits/mnist-m/0/00002217.png', 0), ('data/digits/mnist-m/2/00003089.png', 2), ('data/digits/mnist-m/7/00055431.png', 7), ('data/digits/mnist-m/7/00021693.png', 7), ('data/digits/mnist-m/5/00024128.png', 5), ('data/digits/mnist-m/6/00022814.png', 6), ('data/digits/mnist-m/7/00013123.png', 7), ('data/digits/mnist-m/2/00039899.png', 2), ('data/digits/mnist-m/8/00012295.png', 8), ('data/digits/mnist-m/2/00008372.png', 2), ('data/digits/mnist-m/7/00003643.png', 7), ('data/digits/mnist-m/2/00009135.png', 2), ('data/digits/mnist-m/2/00029789.png', 2), ('data/digits/mnist-m/2/00004549.png', 2), ('data/digits/mnist-m/2/00002261.png', 2), ('data/digits/mnist-m/3/00030077.png', 3), ('data/digits/mnist-m/7/00057066.png', 7), ('data/digits/mnist-m/0/00041922.png', 0), ('data/digits/mnist-m/2/00031372.png', 2), ('data/digits/mnist-m/7/00043160.png', 7), ('data/digits/mnist-m/5/00057106.png', 5), ('data/digits/mnist-m/7/00008476.png', 7), ('data/digits/mnist-m/3/00006681.png', 3), ('data/digits/mnist-m/2/00022132.png', 2), ('data/digits/mnist-m/7/00015260.png', 7), ('data/digits/mnist-m/2/00009087.png', 2), ('data/digits/mnist-m/0/00031361.png', 0), ('data/digits/mnist-m/7/00052568.png', 7), ('data/digits/mnist-m/0/00024952.png', 0), ('data/digits/mnist-m/2/00006193.png', 2), ('data/digits/mnist-m/7/00046820.png', 7), ('data/digits/mnist-m/3/00009335.png', 3), ('data/digits/mnist-m/8/00048704.png', 8), ('data/digits/mnist-m/2/00022486.png', 2), ('data/digits/mnist-m/3/00054249.png', 3), ('data/digits/mnist-m/0/00042446.png', 0), ('data/digits/mnist-m/6/00007564.png', 6), ('data/digits/mnist-m/6/00024074.png', 6), ('data/digits/mnist-m/0/00004310.png', 0), ('data/digits/mnist-m/2/00043617.png', 2), ('data/digits/mnist-m/7/00026303.png', 7), ('data/digits/mnist-m/8/00054749.png', 8), ('data/digits/mnist-m/0/00005043.png', 0), ('data/digits/mnist-m/0/00044750.png', 0), ('data/digits/mnist-m/0/00032274.png', 0)]\n",
      "Target dataset Val Loss: 2.0595 Val Acc: 0.4248\n",
      "Epoch 1/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.8277 Train Acc: 0.9599\n",
      "Source dataset Val Loss: 0.7495 Val Acc: 0.9788\n",
      "\n",
      "Target dataset Val Loss: 1.8138 Val Acc: 0.5195\n",
      "Epoch 2/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.8071 Train Acc: 0.9666\n",
      "Source dataset Val Loss: 0.7992 Val Acc: 0.9271\n",
      "\n",
      "Target dataset Val Loss: 1.9540 Val Acc: 0.4934\n",
      "Epoch 3/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7738 Train Acc: 0.9741\n",
      "Source dataset Val Loss: 0.7356 Val Acc: 0.9850\n",
      "\n",
      "Target dataset Val Loss: 1.9193 Val Acc: 0.5038\n",
      "Epoch 4/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7679 Train Acc: 0.9784\n",
      "Source dataset Val Loss: 0.7473 Val Acc: 0.9795\n",
      "\n",
      "Target dataset Val Loss: 1.9486 Val Acc: 0.4759\n",
      "Epoch 5/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7888 Train Acc: 0.9731\n",
      "Source dataset Val Loss: 0.7376 Val Acc: 0.9857\n",
      "\n",
      "Target dataset Val Loss: 1.8237 Val Acc: 0.5250\n",
      "Epoch 6/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7738 Train Acc: 0.9760\n",
      "Source dataset Val Loss: 0.7393 Val Acc: 0.9857\n",
      "\n",
      "Target dataset Val Loss: 1.8600 Val Acc: 0.5229\n",
      "Epoch 7/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7587 Train Acc: 0.9784\n",
      "Source dataset Val Loss: 0.7380 Val Acc: 0.9826\n",
      "\n",
      "Selected 0/42693 images on threshold 0.9210302906379574\n",
      "[]\n",
      "Target dataset Val Loss: 1.6832 Val Acc: 0.5800\n",
      "Epoch 8/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7459 Train Acc: 0.9844\n",
      "Source dataset Val Loss: 0.7418 Val Acc: 0.9825\n",
      "\n",
      "Target dataset Val Loss: 1.7763 Val Acc: 0.5455\n",
      "Epoch 9/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7458 Train Acc: 0.9834\n",
      "Source dataset Val Loss: 0.7359 Val Acc: 0.9833\n",
      "\n",
      "Target dataset Val Loss: 1.8352 Val Acc: 0.5230\n",
      "Epoch 10/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7598 Train Acc: 0.9817\n",
      "Source dataset Val Loss: 0.7407 Val Acc: 0.9853\n",
      "\n",
      "Target dataset Val Loss: 1.8194 Val Acc: 0.5486\n",
      "Epoch 11/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7501 Train Acc: 0.9827\n",
      "Source dataset Val Loss: 0.7441 Val Acc: 0.9815\n",
      "\n",
      "Target dataset Val Loss: 1.6835 Val Acc: 0.5793\n",
      "Epoch 12/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7438 Train Acc: 0.9837\n",
      "Source dataset Val Loss: 0.7585 Val Acc: 0.9758\n",
      "\n",
      "Target dataset Val Loss: 1.7377 Val Acc: 0.5532\n",
      "Epoch 13/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7514 Train Acc: 0.9817\n",
      "Source dataset Val Loss: 0.7655 Val Acc: 0.9721\n",
      "\n",
      "Target dataset Val Loss: 1.7618 Val Acc: 0.5577\n",
      "Epoch 14/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7483 Train Acc: 0.9815\n",
      "Source dataset Val Loss: 0.7301 Val Acc: 0.9852\n",
      "\n",
      "Selected 0/42693 images on threshold 0.9215138216016576\n",
      "[]\n",
      "Target dataset Val Loss: 1.6830 Val Acc: 0.5649\n",
      "Epoch 15/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7388 Train Acc: 0.9839\n",
      "Source dataset Val Loss: 0.7338 Val Acc: 0.9874\n",
      "\n",
      "Target dataset Val Loss: 1.7360 Val Acc: 0.5686\n",
      "Epoch 16/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7331 Train Acc: 0.9880\n",
      "Source dataset Val Loss: 0.7385 Val Acc: 0.9859\n",
      "\n",
      "Target dataset Val Loss: 1.8479 Val Acc: 0.5081\n",
      "Epoch 17/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7369 Train Acc: 0.9854\n",
      "Source dataset Val Loss: 0.7324 Val Acc: 0.9893\n",
      "\n",
      "Target dataset Val Loss: 1.6918 Val Acc: 0.5691\n",
      "Epoch 18/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7328 Train Acc: 0.9863\n",
      "Source dataset Val Loss: 0.7190 Val Acc: 0.9890\n",
      "\n",
      "Target dataset Val Loss: 1.7771 Val Acc: 0.5441\n",
      "Epoch 19/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7399 Train Acc: 0.9837\n",
      "Source dataset Val Loss: 0.7319 Val Acc: 0.9844\n",
      "\n",
      "Target dataset Val Loss: 1.8410 Val Acc: 0.5154\n",
      "Epoch 20/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7392 Train Acc: 0.9846\n",
      "Source dataset Val Loss: 0.7344 Val Acc: 0.9838\n",
      "\n",
      "Target dataset Val Loss: 1.9147 Val Acc: 0.4853\n",
      "Epoch 21/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7387 Train Acc: 0.9844\n",
      "Source dataset Val Loss: 0.7266 Val Acc: 0.9872\n",
      "\n",
      "Selected 1/42693 images on threshold 0.9218746907840999\n",
      "[('data/digits/mnist-m/2/00004870.png', 2)]\n",
      "Target dataset Val Loss: 1.8387 Val Acc: 0.5108\n",
      "Epoch 22/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7356 Train Acc: 0.9854\n",
      "Source dataset Val Loss: 0.7259 Val Acc: 0.9886\n",
      "\n",
      "Target dataset Val Loss: 1.7067 Val Acc: 0.5619\n",
      "Epoch 23/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7252 Train Acc: 0.9897\n",
      "Source dataset Val Loss: 0.7234 Val Acc: 0.9883\n",
      "\n",
      "Target dataset Val Loss: 1.6877 Val Acc: 0.5704\n",
      "Epoch 24/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7350 Train Acc: 0.9870\n",
      "Source dataset Val Loss: 0.7252 Val Acc: 0.9911\n",
      "\n",
      "Target dataset Val Loss: 1.6583 Val Acc: 0.5939\n",
      "Epoch 25/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7399 Train Acc: 0.9866\n",
      "Source dataset Val Loss: 0.7322 Val Acc: 0.9865\n",
      "\n",
      "Target dataset Val Loss: 1.7096 Val Acc: 0.5624\n",
      "Epoch 26/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7293 Train Acc: 0.9880\n",
      "Source dataset Val Loss: 0.7248 Val Acc: 0.9890\n",
      "\n",
      "Target dataset Val Loss: 1.6672 Val Acc: 0.5692\n",
      "Epoch 27/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7229 Train Acc: 0.9899\n",
      "Source dataset Val Loss: 0.7244 Val Acc: 0.9888\n",
      "\n",
      "Target dataset Val Loss: 1.8126 Val Acc: 0.5323\n",
      "Epoch 28/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7286 Train Acc: 0.9875\n",
      "Source dataset Val Loss: 0.7269 Val Acc: 0.9869\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9218060710805324\n",
      "[]\n",
      "Target dataset Val Loss: 1.7924 Val Acc: 0.5391\n",
      "Epoch 29/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7328 Train Acc: 0.9854\n",
      "Source dataset Val Loss: 0.7298 Val Acc: 0.9850\n",
      "\n",
      "Target dataset Val Loss: 1.7008 Val Acc: 0.5679\n",
      "Epoch 30/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7228 Train Acc: 0.9892\n",
      "Source dataset Val Loss: 0.7247 Val Acc: 0.9885\n",
      "\n",
      "Target dataset Val Loss: 1.7082 Val Acc: 0.5657\n",
      "Epoch 31/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7224 Train Acc: 0.9899\n",
      "Source dataset Val Loss: 0.7248 Val Acc: 0.9892\n",
      "\n",
      "Target dataset Val Loss: 1.7654 Val Acc: 0.5474\n",
      "Epoch 32/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7278 Train Acc: 0.9868\n",
      "Source dataset Val Loss: 0.7226 Val Acc: 0.9881\n",
      "\n",
      "Target dataset Val Loss: 1.8320 Val Acc: 0.5145\n",
      "Epoch 33/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7244 Train Acc: 0.9885\n",
      "Source dataset Val Loss: 0.7239 Val Acc: 0.9897\n",
      "\n",
      "Target dataset Val Loss: 1.7625 Val Acc: 0.5488\n",
      "Epoch 34/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7201 Train Acc: 0.9899\n",
      "Source dataset Val Loss: 0.7203 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.6562 Val Acc: 0.5689\n",
      "Epoch 35/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7197 Train Acc: 0.9904\n",
      "Source dataset Val Loss: 0.7317 Val Acc: 0.9837\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9212378507974773\n",
      "[]\n",
      "Target dataset Val Loss: 1.7207 Val Acc: 0.5453\n",
      "Epoch 36/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7189 Train Acc: 0.9911\n",
      "Source dataset Val Loss: 0.7179 Val Acc: 0.9903\n",
      "\n",
      "Target dataset Val Loss: 1.7059 Val Acc: 0.5677\n",
      "Epoch 37/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7249 Train Acc: 0.9892\n",
      "Source dataset Val Loss: 0.7199 Val Acc: 0.9900\n",
      "\n",
      "Target dataset Val Loss: 1.8023 Val Acc: 0.5235\n",
      "Epoch 38/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7211 Train Acc: 0.9894\n",
      "Source dataset Val Loss: 0.7200 Val Acc: 0.9903\n",
      "\n",
      "Target dataset Val Loss: 1.7420 Val Acc: 0.5432\n",
      "Epoch 39/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7222 Train Acc: 0.9892\n",
      "Source dataset Val Loss: 0.7410 Val Acc: 0.9861\n",
      "\n",
      "Target dataset Val Loss: 1.8306 Val Acc: 0.5294\n",
      "Epoch 40/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7239 Train Acc: 0.9887\n",
      "Source dataset Val Loss: 0.7250 Val Acc: 0.9876\n",
      "\n",
      "Target dataset Val Loss: 1.7546 Val Acc: 0.5454\n",
      "Epoch 41/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7268 Train Acc: 0.9880\n",
      "Source dataset Val Loss: 0.7225 Val Acc: 0.9896\n",
      "\n",
      "Target dataset Val Loss: 1.7986 Val Acc: 0.5231\n",
      "Epoch 42/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7132 Train Acc: 0.9923\n",
      "Source dataset Val Loss: 0.7199 Val Acc: 0.9904\n",
      "\n",
      "Selected 0/42692 images on threshold 0.922438703474337\n",
      "[]\n",
      "Target dataset Val Loss: 1.6016 Val Acc: 0.6009\n",
      "Epoch 43/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7116 Train Acc: 0.9938\n",
      "Source dataset Val Loss: 0.7165 Val Acc: 0.9923\n",
      "\n",
      "Target dataset Val Loss: 1.7739 Val Acc: 0.5396\n",
      "Epoch 44/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7159 Train Acc: 0.9918\n",
      "Source dataset Val Loss: 0.7314 Val Acc: 0.9859\n",
      "\n",
      "Target dataset Val Loss: 1.6796 Val Acc: 0.5710\n",
      "Epoch 45/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7235 Train Acc: 0.9890\n",
      "Source dataset Val Loss: 0.7226 Val Acc: 0.9878\n",
      "\n",
      "Target dataset Val Loss: 1.8542 Val Acc: 0.5074\n",
      "Epoch 46/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7168 Train Acc: 0.9918\n",
      "Source dataset Val Loss: 0.7247 Val Acc: 0.9881\n",
      "\n",
      "Target dataset Val Loss: 1.7509 Val Acc: 0.5505\n",
      "Epoch 47/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7116 Train Acc: 0.9926\n",
      "Source dataset Val Loss: 0.7216 Val Acc: 0.9874\n",
      "\n",
      "Target dataset Val Loss: 1.7626 Val Acc: 0.5519\n",
      "Epoch 48/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7148 Train Acc: 0.9933\n",
      "Source dataset Val Loss: 0.7150 Val Acc: 0.9904\n",
      "\n",
      "Target dataset Val Loss: 1.8099 Val Acc: 0.5462\n",
      "Epoch 49/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7179 Train Acc: 0.9904\n",
      "Source dataset Val Loss: 0.7193 Val Acc: 0.9892\n",
      "\n",
      "Selected 0/42692 images on threshold 0.922234040758537\n",
      "[]\n",
      "Target dataset Val Loss: 1.8593 Val Acc: 0.5117\n",
      "Epoch 50/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7109 Train Acc: 0.9928\n",
      "Source dataset Val Loss: 0.7157 Val Acc: 0.9918\n",
      "\n",
      "Target dataset Val Loss: 1.7170 Val Acc: 0.5599\n",
      "Epoch 51/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7170 Train Acc: 0.9902\n",
      "Source dataset Val Loss: 0.7308 Val Acc: 0.9891\n",
      "\n",
      "Target dataset Val Loss: 1.7911 Val Acc: 0.5332\n",
      "Epoch 52/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7125 Train Acc: 0.9930\n",
      "Source dataset Val Loss: 0.7278 Val Acc: 0.9924\n",
      "\n",
      "Target dataset Val Loss: 1.5940 Val Acc: 0.6047\n",
      "Epoch 53/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7219 Train Acc: 0.9875\n",
      "Source dataset Val Loss: 0.7193 Val Acc: 0.9898\n",
      "\n",
      "Target dataset Val Loss: 1.5825 Val Acc: 0.6117\n",
      "Epoch 54/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7111 Train Acc: 0.9935\n",
      "Source dataset Val Loss: 0.7302 Val Acc: 0.9898\n",
      "\n",
      "Target dataset Val Loss: 1.7197 Val Acc: 0.5552\n",
      "Epoch 55/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7129 Train Acc: 0.9926\n",
      "Source dataset Val Loss: 0.7170 Val Acc: 0.9897\n",
      "\n",
      "Target dataset Val Loss: 1.7547 Val Acc: 0.5579\n",
      "Epoch 56/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7179 Train Acc: 0.9906\n",
      "Source dataset Val Loss: 0.7195 Val Acc: 0.9890\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9221998822650379\n",
      "[]\n",
      "Target dataset Val Loss: 1.6635 Val Acc: 0.5768\n",
      "Epoch 57/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7119 Train Acc: 0.9923\n",
      "Source dataset Val Loss: 0.7294 Val Acc: 0.9847\n",
      "\n",
      "Target dataset Val Loss: 1.6759 Val Acc: 0.5693\n",
      "Epoch 58/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7190 Train Acc: 0.9899\n",
      "Source dataset Val Loss: 0.7190 Val Acc: 0.9895\n",
      "\n",
      "Target dataset Val Loss: 1.7448 Val Acc: 0.5330\n",
      "Epoch 59/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7143 Train Acc: 0.9914\n",
      "Source dataset Val Loss: 0.7191 Val Acc: 0.9894\n",
      "\n",
      "Target dataset Val Loss: 1.6686 Val Acc: 0.5793\n",
      "Epoch 60/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7134 Train Acc: 0.9926\n",
      "Source dataset Val Loss: 0.7250 Val Acc: 0.9905\n",
      "\n",
      "Target dataset Val Loss: 1.7236 Val Acc: 0.5324\n",
      "Epoch 61/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7096 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7183 Val Acc: 0.9888\n",
      "\n",
      "Target dataset Val Loss: 1.7470 Val Acc: 0.5510\n",
      "Epoch 62/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7134 Train Acc: 0.9914\n",
      "Source dataset Val Loss: 0.7136 Val Acc: 0.9913\n",
      "\n",
      "Target dataset Val Loss: 1.7724 Val Acc: 0.5408\n",
      "Epoch 63/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7088 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7146 Val Acc: 0.9915\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9226428727434622\n",
      "[]\n",
      "Target dataset Val Loss: 1.7348 Val Acc: 0.5498\n",
      "Epoch 64/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7120 Train Acc: 0.9923\n",
      "Source dataset Val Loss: 0.7269 Val Acc: 0.9873\n",
      "\n",
      "Target dataset Val Loss: 1.7119 Val Acc: 0.5582\n",
      "Epoch 65/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7128 Train Acc: 0.9935\n",
      "Source dataset Val Loss: 0.7223 Val Acc: 0.9888\n",
      "\n",
      "Target dataset Val Loss: 1.8081 Val Acc: 0.5425\n",
      "Epoch 66/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7046 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7168 Val Acc: 0.9900\n",
      "\n",
      "Target dataset Val Loss: 1.8182 Val Acc: 0.5186\n",
      "Epoch 67/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7141 Train Acc: 0.9921\n",
      "Source dataset Val Loss: 0.7231 Val Acc: 0.9906\n",
      "\n",
      "Target dataset Val Loss: 1.6902 Val Acc: 0.5716\n",
      "Epoch 68/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7030 Train Acc: 0.9966\n",
      "Source dataset Val Loss: 0.7116 Val Acc: 0.9926\n",
      "\n",
      "Target dataset Val Loss: 1.6808 Val Acc: 0.5755\n",
      "Epoch 69/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7137 Train Acc: 0.9911\n",
      "Source dataset Val Loss: 0.7203 Val Acc: 0.9925\n",
      "\n",
      "Target dataset Val Loss: 1.7435 Val Acc: 0.5550\n",
      "Epoch 70/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7159 Train Acc: 0.9911\n",
      "Source dataset Val Loss: 0.7214 Val Acc: 0.9885\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9220973243405381\n",
      "[]\n",
      "Target dataset Val Loss: 1.6216 Val Acc: 0.5952\n",
      "Epoch 71/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7076 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7150 Val Acc: 0.9924\n",
      "\n",
      "Target dataset Val Loss: 1.5740 Val Acc: 0.6114\n",
      "Epoch 72/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7159 Train Acc: 0.9918\n",
      "Source dataset Val Loss: 0.7256 Val Acc: 0.9907\n",
      "\n",
      "Target dataset Val Loss: 1.6152 Val Acc: 0.5948\n",
      "Epoch 73/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7091 Train Acc: 0.9935\n",
      "Source dataset Val Loss: 0.7129 Val Acc: 0.9912\n",
      "\n",
      "Target dataset Val Loss: 1.6141 Val Acc: 0.5995\n",
      "Epoch 74/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7065 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7188 Val Acc: 0.9914\n",
      "\n",
      "Target dataset Val Loss: 1.5848 Val Acc: 0.6163\n",
      "Epoch 75/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7064 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7181 Val Acc: 0.9903\n",
      "\n",
      "Target dataset Val Loss: 1.6387 Val Acc: 0.5850\n",
      "Epoch 76/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7129 Train Acc: 0.9928\n",
      "Source dataset Val Loss: 0.7195 Val Acc: 0.9915\n",
      "\n",
      "Target dataset Val Loss: 1.7033 Val Acc: 0.5797\n",
      "Epoch 77/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7089 Train Acc: 0.9942\n",
      "Source dataset Val Loss: 0.7128 Val Acc: 0.9918\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9226938380712858\n",
      "[]\n",
      "Target dataset Val Loss: 1.7372 Val Acc: 0.5581\n",
      "Epoch 78/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7091 Train Acc: 0.9933\n",
      "Source dataset Val Loss: 0.7149 Val Acc: 0.9911\n",
      "\n",
      "Target dataset Val Loss: 1.7973 Val Acc: 0.5470\n",
      "Epoch 79/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7054 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7172 Val Acc: 0.9906\n",
      "\n",
      "Target dataset Val Loss: 1.6580 Val Acc: 0.6038\n",
      "Epoch 80/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7058 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7123 Val Acc: 0.9919\n",
      "\n",
      "Target dataset Val Loss: 1.6732 Val Acc: 0.5870\n",
      "Epoch 81/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7072 Train Acc: 0.9942\n",
      "Source dataset Val Loss: 0.7154 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.7451 Val Acc: 0.5661\n",
      "Epoch 82/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7044 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7189 Val Acc: 0.9915\n",
      "\n",
      "Target dataset Val Loss: 1.6627 Val Acc: 0.5841\n",
      "Epoch 83/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7117 Train Acc: 0.9945\n",
      "Source dataset Val Loss: 0.7236 Val Acc: 0.9912\n",
      "\n",
      "Target dataset Val Loss: 1.6021 Val Acc: 0.6054\n",
      "Epoch 84/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7046 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7195 Val Acc: 0.9896\n",
      "\n",
      "Selected 0/42692 images on threshold 0.922302316550006\n",
      "[]\n",
      "Target dataset Val Loss: 1.6216 Val Acc: 0.6003\n",
      "Epoch 85/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7102 Train Acc: 0.9938\n",
      "Source dataset Val Loss: 0.7133 Val Acc: 0.9926\n",
      "\n",
      "Target dataset Val Loss: 1.7700 Val Acc: 0.5481\n",
      "Epoch 86/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7072 Train Acc: 0.9945\n",
      "Source dataset Val Loss: 0.7153 Val Acc: 0.9909\n",
      "\n",
      "Target dataset Val Loss: 1.6752 Val Acc: 0.5790\n",
      "Epoch 87/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7069 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7196 Val Acc: 0.9907\n",
      "\n",
      "Target dataset Val Loss: 1.6014 Val Acc: 0.6031\n",
      "Epoch 88/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7133 Train Acc: 0.9933\n",
      "Source dataset Val Loss: 0.7156 Val Acc: 0.9905\n",
      "\n",
      "Target dataset Val Loss: 1.6585 Val Acc: 0.5744\n",
      "Epoch 89/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7076 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7152 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.7293 Val Acc: 0.5603\n",
      "Epoch 90/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7021 Train Acc: 0.9974\n",
      "Source dataset Val Loss: 0.7134 Val Acc: 0.9921\n",
      "\n",
      "Target dataset Val Loss: 1.7615 Val Acc: 0.5573\n",
      "Epoch 91/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7027 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7118 Val Acc: 0.9918\n",
      "\n",
      "Selected 0/42692 images on threshold 0.9226938380712858\n",
      "[]\n",
      "Target dataset Val Loss: 1.6523 Val Acc: 0.5784\n",
      "Epoch 92/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7079 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7195 Val Acc: 0.9896\n",
      "\n",
      "Target dataset Val Loss: 1.6992 Val Acc: 0.5719\n",
      "Epoch 93/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7101 Train Acc: 0.9935\n",
      "Source dataset Val Loss: 0.7123 Val Acc: 0.9916\n",
      "\n",
      "Target dataset Val Loss: 1.6527 Val Acc: 0.5936\n",
      "Epoch 94/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7040 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7160 Val Acc: 0.9904\n",
      "\n",
      "Target dataset Val Loss: 1.6972 Val Acc: 0.5608\n",
      "Epoch 95/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7057 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7140 Val Acc: 0.9906\n",
      "\n",
      "Target dataset Val Loss: 1.6367 Val Acc: 0.5914\n",
      "Epoch 96/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7032 Train Acc: 0.9962\n",
      "Source dataset Val Loss: 0.7182 Val Acc: 0.9893\n",
      "\n",
      "Target dataset Val Loss: 1.6548 Val Acc: 0.5808\n",
      "Epoch 97/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7041 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7158 Val Acc: 0.9903\n",
      "\n",
      "Target dataset Val Loss: 1.6763 Val Acc: 0.5842\n",
      "Epoch 98/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7042 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7174 Val Acc: 0.9909\n",
      "\n",
      "Selected 1/42692 images on threshold 0.9225238339159656\n",
      "[('data/digits/mnist-m/2/00055833.png', 2)]\n",
      "Target dataset Val Loss: 1.6948 Val Acc: 0.5749\n",
      "Epoch 99/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7085 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7127 Val Acc: 0.9917\n",
      "\n",
      "Target dataset Val Loss: 1.6172 Val Acc: 0.5965\n",
      "Epoch 100/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7031 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7204 Val Acc: 0.9912\n",
      "\n",
      "Target dataset Val Loss: 1.6492 Val Acc: 0.5875\n",
      "Epoch 101/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7086 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7131 Val Acc: 0.9920\n",
      "\n",
      "Target dataset Val Loss: 1.6869 Val Acc: 0.5718\n",
      "Epoch 102/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7051 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7185 Val Acc: 0.9901\n",
      "\n",
      "Target dataset Val Loss: 1.7586 Val Acc: 0.5370\n",
      "Epoch 103/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7077 Train Acc: 0.9935\n",
      "Source dataset Val Loss: 0.7233 Val Acc: 0.9885\n",
      "\n",
      "Target dataset Val Loss: 1.6540 Val Acc: 0.5885\n",
      "Epoch 104/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7073 Train Acc: 0.9942\n",
      "Source dataset Val Loss: 0.7164 Val Acc: 0.9919\n",
      "\n",
      "Target dataset Val Loss: 1.6668 Val Acc: 0.5750\n",
      "Epoch 105/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7133 Train Acc: 0.9921\n",
      "Source dataset Val Loss: 0.7126 Val Acc: 0.9926\n",
      "\n",
      "Selected 0/42691 images on threshold 0.9228295952407883\n",
      "[]\n",
      "Target dataset Val Loss: 1.5940 Val Acc: 0.6015\n",
      "Epoch 106/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7000 Train Acc: 0.9976\n",
      "Source dataset Val Loss: 0.7188 Val Acc: 0.9907\n",
      "\n",
      "Target dataset Val Loss: 1.5845 Val Acc: 0.6146\n",
      "Epoch 107/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7046 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7163 Val Acc: 0.9914\n",
      "\n",
      "Target dataset Val Loss: 1.5849 Val Acc: 0.6083\n",
      "Epoch 108/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7087 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7442 Val Acc: 0.9845\n",
      "\n",
      "Target dataset Val Loss: 1.5560 Val Acc: 0.6230\n",
      "Epoch 109/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7023 Train Acc: 0.9969\n",
      "Source dataset Val Loss: 0.7115 Val Acc: 0.9929\n",
      "\n",
      "Target dataset Val Loss: 1.6058 Val Acc: 0.6178\n",
      "Epoch 110/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7030 Train Acc: 0.9966\n",
      "Source dataset Val Loss: 0.7118 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.5391 Val Acc: 0.6410\n",
      "Epoch 111/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7031 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7204 Val Acc: 0.9890\n",
      "\n",
      "Target dataset Val Loss: 1.8550 Val Acc: 0.5375\n",
      "Epoch 112/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7009 Train Acc: 0.9969\n",
      "Source dataset Val Loss: 0.7164 Val Acc: 0.9914\n",
      "\n",
      "Selected 0/42691 images on threshold 0.9226258774613869\n",
      "[]\n",
      "Target dataset Val Loss: 1.7792 Val Acc: 0.5650\n",
      "Epoch 113/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7053 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7161 Val Acc: 0.9901\n",
      "\n",
      "Target dataset Val Loss: 1.6987 Val Acc: 0.5689\n",
      "Epoch 114/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7073 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7149 Val Acc: 0.9919\n",
      "\n",
      "Target dataset Val Loss: 1.6061 Val Acc: 0.6104\n",
      "Epoch 115/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7050 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7136 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.6392 Val Acc: 0.5961\n",
      "Epoch 116/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7062 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7131 Val Acc: 0.9913\n",
      "\n",
      "Target dataset Val Loss: 1.6027 Val Acc: 0.6097\n",
      "Epoch 117/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7045 Train Acc: 0.9942\n",
      "Source dataset Val Loss: 0.7131 Val Acc: 0.9922\n",
      "\n",
      "Target dataset Val Loss: 1.7140 Val Acc: 0.5638\n",
      "Epoch 118/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7043 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7100 Val Acc: 0.9925\n",
      "\n",
      "Target dataset Val Loss: 1.6120 Val Acc: 0.6074\n",
      "Epoch 119/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7030 Train Acc: 0.9971\n",
      "Source dataset Val Loss: 0.7088 Val Acc: 0.9933\n",
      "\n",
      "Selected 0/42691 images on threshold 0.9229651339114799\n",
      "[]\n",
      "Target dataset Val Loss: 1.5997 Val Acc: 0.6089\n",
      "Epoch 120/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7000 Train Acc: 0.9974\n",
      "Source dataset Val Loss: 0.7167 Val Acc: 0.9914\n",
      "\n",
      "Target dataset Val Loss: 1.6557 Val Acc: 0.5973\n",
      "Epoch 121/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6994 Train Acc: 0.9978\n",
      "Source dataset Val Loss: 0.7089 Val Acc: 0.9930\n",
      "\n",
      "Target dataset Val Loss: 1.6239 Val Acc: 0.6134\n",
      "Epoch 122/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7058 Train Acc: 0.9962\n",
      "Source dataset Val Loss: 0.7112 Val Acc: 0.9926\n",
      "\n",
      "Target dataset Val Loss: 1.5867 Val Acc: 0.6134\n",
      "Epoch 123/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7018 Train Acc: 0.9971\n",
      "Source dataset Val Loss: 0.7249 Val Acc: 0.9886\n",
      "\n",
      "Target dataset Val Loss: 1.5310 Val Acc: 0.6361\n",
      "Epoch 124/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7053 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7178 Val Acc: 0.9904\n",
      "\n",
      "Target dataset Val Loss: 1.6475 Val Acc: 0.6052\n",
      "Epoch 125/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7075 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7151 Val Acc: 0.9918\n",
      "\n",
      "Target dataset Val Loss: 1.5802 Val Acc: 0.6211\n",
      "Epoch 126/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7051 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7110 Val Acc: 0.9922\n",
      "\n",
      "Selected 1/42691 images on threshold 0.9227617439860052\n",
      "[('data/digits/mnist-m/2/00002981.png', 2)]\n",
      "Target dataset Val Loss: 1.6734 Val Acc: 0.6009\n",
      "Epoch 127/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7046 Train Acc: 0.9947\n",
      "Source dataset Val Loss: 0.7168 Val Acc: 0.9933\n",
      "\n",
      "Target dataset Val Loss: 1.5954 Val Acc: 0.6182\n",
      "Epoch 128/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7028 Train Acc: 0.9969\n",
      "Source dataset Val Loss: 0.7100 Val Acc: 0.9928\n",
      "\n",
      "Target dataset Val Loss: 1.5039 Val Acc: 0.6475\n",
      "Epoch 129/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6987 Train Acc: 0.9974\n",
      "Source dataset Val Loss: 0.7100 Val Acc: 0.9934\n",
      "\n",
      "Target dataset Val Loss: 1.5930 Val Acc: 0.6213\n",
      "Epoch 130/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7043 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7165 Val Acc: 0.9925\n",
      "\n",
      "Target dataset Val Loss: 1.6883 Val Acc: 0.5760\n",
      "Epoch 131/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7026 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7109 Val Acc: 0.9926\n",
      "\n",
      "Target dataset Val Loss: 1.5947 Val Acc: 0.6121\n",
      "Epoch 132/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7035 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7158 Val Acc: 0.9916\n",
      "\n",
      "Target dataset Val Loss: 1.7277 Val Acc: 0.5639\n",
      "Epoch 133/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7088 Train Acc: 0.9940\n",
      "Source dataset Val Loss: 0.7183 Val Acc: 0.9915\n",
      "\n",
      "Selected 0/42690 images on threshold 0.9226428727434622\n",
      "[]\n",
      "Target dataset Val Loss: 1.8252 Val Acc: 0.5418\n",
      "Epoch 134/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7048 Train Acc: 0.9957\n",
      "Source dataset Val Loss: 0.7102 Val Acc: 0.9929\n",
      "\n",
      "Target dataset Val Loss: 1.7066 Val Acc: 0.5738\n",
      "Epoch 135/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6981 Train Acc: 0.9976\n",
      "Source dataset Val Loss: 0.7093 Val Acc: 0.9937\n",
      "\n",
      "Target dataset Val Loss: 1.6277 Val Acc: 0.6081\n",
      "Epoch 136/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6977 Train Acc: 0.9986\n",
      "Source dataset Val Loss: 0.7225 Val Acc: 0.9884\n",
      "\n",
      "Target dataset Val Loss: 1.7666 Val Acc: 0.5609\n",
      "Epoch 137/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6990 Train Acc: 0.9978\n",
      "Source dataset Val Loss: 0.7135 Val Acc: 0.9916\n",
      "\n",
      "Target dataset Val Loss: 1.5882 Val Acc: 0.6299\n",
      "Epoch 138/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6984 Train Acc: 0.9981\n",
      "Source dataset Val Loss: 0.7132 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.6279 Val Acc: 0.6141\n",
      "Epoch 139/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7042 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7161 Val Acc: 0.9905\n",
      "\n",
      "Target dataset Val Loss: 1.5832 Val Acc: 0.6253\n",
      "Epoch 140/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7033 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7112 Val Acc: 0.9922\n",
      "\n",
      "Selected 0/42690 images on threshold 0.9227617439860052\n",
      "[]\n",
      "Target dataset Val Loss: 1.5488 Val Acc: 0.6331\n",
      "Epoch 141/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7036 Train Acc: 0.9954\n",
      "Source dataset Val Loss: 0.7178 Val Acc: 0.9910\n",
      "\n",
      "Target dataset Val Loss: 1.5447 Val Acc: 0.6265\n",
      "Epoch 142/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6996 Train Acc: 0.9978\n",
      "Source dataset Val Loss: 0.7204 Val Acc: 0.9891\n",
      "\n",
      "Target dataset Val Loss: 1.5411 Val Acc: 0.6348\n",
      "Epoch 143/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7021 Train Acc: 0.9969\n",
      "Source dataset Val Loss: 0.7132 Val Acc: 0.9926\n",
      "\n",
      "Target dataset Val Loss: 1.5720 Val Acc: 0.6348\n",
      "Epoch 144/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7039 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7190 Val Acc: 0.9908\n",
      "\n",
      "Target dataset Val Loss: 1.5909 Val Acc: 0.6139\n",
      "Epoch 145/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7011 Train Acc: 0.9969\n",
      "Source dataset Val Loss: 0.7098 Val Acc: 0.9930\n",
      "\n",
      "Target dataset Val Loss: 1.5722 Val Acc: 0.6234\n",
      "Epoch 146/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6974 Train Acc: 0.9986\n",
      "Source dataset Val Loss: 0.7132 Val Acc: 0.9934\n",
      "\n",
      "Target dataset Val Loss: 1.5734 Val Acc: 0.6292\n",
      "Epoch 147/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7017 Train Acc: 0.9964\n",
      "Source dataset Val Loss: 0.7134 Val Acc: 0.9912\n",
      "\n",
      "Selected 0/42690 images on threshold 0.9225918766347296\n",
      "[]\n",
      "Target dataset Val Loss: 1.5684 Val Acc: 0.6184\n",
      "Epoch 148/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7036 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7128 Val Acc: 0.9916\n",
      "\n",
      "Target dataset Val Loss: 1.6297 Val Acc: 0.6070\n",
      "Epoch 149/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7014 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7096 Val Acc: 0.9930\n",
      "\n",
      "Target dataset Val Loss: 1.6145 Val Acc: 0.6135\n",
      "Epoch 150/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6998 Train Acc: 0.9981\n",
      "Source dataset Val Loss: 0.7110 Val Acc: 0.9924\n",
      "\n",
      "Target dataset Val Loss: 1.5460 Val Acc: 0.6345\n",
      "Epoch 151/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7015 Train Acc: 0.9959\n",
      "Source dataset Val Loss: 0.7129 Val Acc: 0.9911\n",
      "\n",
      "Target dataset Val Loss: 1.6044 Val Acc: 0.6112\n",
      "Epoch 152/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7069 Train Acc: 0.9950\n",
      "Source dataset Val Loss: 0.7114 Val Acc: 0.9927\n",
      "\n",
      "Target dataset Val Loss: 1.6103 Val Acc: 0.6105\n",
      "Epoch 153/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6981 Train Acc: 0.9983\n",
      "Source dataset Val Loss: 0.7178 Val Acc: 0.9924\n",
      "\n",
      "Target dataset Val Loss: 1.5287 Val Acc: 0.6373\n",
      "Epoch 154/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.7046 Train Acc: 0.9952\n",
      "Source dataset Val Loss: 0.7152 Val Acc: 0.9926\n",
      "\n",
      "Selected 0/42690 images on threshold 0.9228295952407883\n",
      "[]\n",
      "Target dataset Val Loss: 1.7513 Val Acc: 0.5634\n",
      "Epoch 155/159\n",
      "----------\n",
      "Source dataset Train Loss: 0.6974 Train Acc: 0.9976\n",
      "Source dataset Val Loss: 0.7123 Val Acc: 0.9917\n",
      "\n",
      "Target dataset Val Loss: 1.6004 Val Acc: 0.6242\n",
      "Epoch 156/159\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     source_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     target_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     model, source_history, target_history, label_history \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 17\u001b[0m         \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madaptive_train_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_adaptive_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_lr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_train_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_labeled_dataset_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_val_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_source_val_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabeled_dataloader_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_padded_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# we can not use padding with unlabeled data\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43munlabeled_dataloader_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_batch_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43munlabeled_target_train_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_unlabeled_dataset_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_val_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_target_val_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpseudo_sample_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLING_PERIOD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRHO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprevious_source_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprevious_target_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     res \u001b[38;5;241m=\u001b[39m tasks\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mload_trained_model(\n\u001b[1;32m     45\u001b[0m         model, AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL\n\u001b[1;32m     46\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/university/masters/deepl/project/lib/adaptive_train_eval.py:214\u001b[0m, in \u001b[0;36mtrain_adaptive_model\u001b[0;34m(model, criterion, optimizer, scheduler, device, source_train_dataset, source_val_dataset, labeled_dataloader_initializer, unlabeled_dataloader_initializer, unlabeled_target_train_dataset, target_val_dataset, output_dir, num_epochs, gradient_accumulation, pseudo_sample_period, rho, previous_source_history, previous_target_history, verbose)\u001b[0m\n\u001b[1;32m    206\u001b[0m subset_sampler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubsetRandomSampler(indices)\n\u001b[1;32m    207\u001b[0m source_dataloaders \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: labeled_dataloader_initializer(\n\u001b[1;32m    209\u001b[0m         source_train_dataset, sampler\u001b[38;5;241m=\u001b[39msubset_sampler\n\u001b[1;32m    210\u001b[0m     ),\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: labeled_dataloader_initializer(source_val_dataset),\n\u001b[1;32m    212\u001b[0m }\n\u001b[0;32m--> 214\u001b[0m source_res \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_train_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_dataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_stats_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10e6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# set new validation accuracy\u001b[39;00m\n\u001b[1;32m    227\u001b[0m last_val_acc \u001b[38;5;241m=\u001b[39m source_res\u001b[38;5;241m.\u001b[39mval_acc\n",
      "File \u001b[0;32m~/Documents/university/masters/deepl/project/lib/torch_train_eval.py:205\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, optimizer, criterion, scheduler, dataloaders, device, gradient_accumulation, train_stats_period, verbose)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_epoch\u001b[39m(\n\u001b[1;32m    175\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    176\u001b[0m     optimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    184\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EpochResults:\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Runs a single epoch of training and validation.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    :rtype: EpochResults\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_stats_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m val_epoch(model, criterion, dataloaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m], device, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EpochResults(\n\u001b[1;32m    218\u001b[0m         train_loss\u001b[38;5;241m=\u001b[39mtrain_loss,\n\u001b[1;32m    219\u001b[0m         train_acc\u001b[38;5;241m=\u001b[39mtrain_acc,\n\u001b[1;32m    220\u001b[0m         val_loss\u001b[38;5;241m=\u001b[39mval_loss,\n\u001b[1;32m    221\u001b[0m         val_acc\u001b[38;5;241m=\u001b[39mval_acc,\n\u001b[1;32m    222\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/university/masters/deepl/project/lib/torch_train_eval.py:272\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, criterion, scheduler, dataloader, device, gradient_accumulation, train_stats_period, verbose)\u001b[0m\n\u001b[1;32m    269\u001b[0m samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m    270\u001b[0m iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 272\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    275\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")\n",
    "\n",
    "if AD_TRAIN_SEMI_SUPERVISED_MODEL_SMALL:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=ad_labeled_dataset_small,\n",
    "            source_val_dataset=ad_source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            # we can not use padding with unlabeled data\n",
    "            unlabeled_dataloader_initializer=lambda dataset: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, shuffle=True, n_workers=8\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=ad_unlabeled_dataset_small,\n",
    "            target_val_dataset=ad_target_val_dataset,\n",
    "            output_dir=AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "            verbose=False,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(\n",
    "        model, AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL\n",
    "    )\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, mnist_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")\n",
    "\n",
    "if AD_FINETUNE_SEMI_SUPERVISED_MODEL_LARGE:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"history.pickle\"))\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            ad_labeled_dataset_large, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=ad_source_val_loader,\n",
    "        output_dir=AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL,\n",
    "        num_epochs=25,\n",
    "        patience=3,\n",
    "        warmup_period=1,\n",
    "        previous_history=history,\n",
    "        verbose=False\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_SMALL, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(history)\n",
    "tasks.results.learning_curves_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")\n",
    "\n",
    "if AD_TRAIN_SEMI_SUPERVISED_MODEL_LARGE:\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
    "    # import fine tuned model, not previous unsupervised model\n",
    "    # we are assuming training takes one go, no intermediate saving here\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_LARGE, \"model.pt\")\n",
    "    )\n",
    "    optimizer_ft = optim.AdamW(model.parameters(), weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    source_history = None\n",
    "    target_history = None\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=ad_labeled_dataset_large,\n",
    "            source_val_dataset=ad_source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            # we can not use padding with unlabeled data\n",
    "            unlabeled_dataloader_initializer=lambda dataset: tasks.preprocessing.single_batch_loader(\n",
    "                dataset, shuffle=True, n_workers=8\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=ad_unlabeled_dataset_large,\n",
    "            target_val_dataset=ad_target_val_dataset,\n",
    "            output_dir=AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_LARGE,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=SAMPLING_PERIOD,\n",
    "            rho=RHO,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "            verbose=False,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(\n",
    "        model, AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_LARGE\n",
    "    )\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(source_history)\n",
    "tasks.results.learning_curves_accuracy(source_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.learning_curves_loss(target_history)\n",
    "tasks.results.learning_curves_accuracy(target_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, mnist_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, ad_target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_model_dirs = [\n",
    "        (FINETUNED_SOURCE__MODEL_DIR, \"Source\"),\n",
    "        (UNSUPERVISED_MODEL_DIR, \"Unsupervised\"),\n",
    "        (SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10, \"Semi-Supervised 10\"),\n",
    "        (SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20, \"Semi-Supervised 20\")\n",
    "    ]\n",
    "office_base_model = tasks.utils.get_model(device)\n",
    "\n",
    "mnist_model_dirs = [\n",
    "        (AD_FINETUNED_MODEL_DIR, \"Source\"),\n",
    "        (AD_UNSUPERVISED_MODEL_DIR, \"Unsupervised\"),\n",
    "        (AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_SMALL, \"Semi-Supervised 10\"),\n",
    "        (AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_LARGE, \"Semi-Supervised 20\"),\n",
    "\n",
    "    ]\n",
    "mnist_base_model = tasks.utils.get_model(\n",
    "    device=device, replace_fc_layer=True, num_classes=len(mnist_encodings)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_classification_matrices(\n",
    "    office_base_model,\n",
    "    office_model_dirs,\n",
    "    target_test_loader,\n",
    "    device,\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    save_path=os.path.join(RESULTS_DIR, \"office_cls_matrix.jpeg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_classification_matrices(\n",
    "    mnist_base_model,\n",
    "    mnist_model_dirs[:2],\n",
    "    ad_target_test_loader,\n",
    "    device,\n",
    "    rows=1,\n",
    "    cols=2,\n",
    "    save_path=os.path.join(RESULTS_DIR, \"mnist_cls_matrix.jpeg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history_grid(\n",
    "    mnist_model_dirs[1:],\n",
    "    mnist_encodings,\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    figsize=(15, 7),\n",
    "    save_path=os.path.join(RESULTS_DIR, \"mnist_misclassifications.jpeg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history_grid(\n",
    "    office_model_dirs[1:],\n",
    "    office_encodings,\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    figsize=(15, 7),\n",
    "    save_path=os.path.join(RESULTS_DIR, \"office_misclassifications.jpeg\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "classification_accuracies = np.linspace(0, 1, 100)\n",
    "path = os.path.join(RESULTS_DIR, \"adaptive_threshold.jpeg\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "for rho in [3, 4]:\n",
    "    thresholds = [lib.adaptive_train_eval.adaptive_threshold(acc, rho) for acc in classification_accuracies]\n",
    "    \n",
    "    sns.lineplot(x=classification_accuracies, y=thresholds, label=f'ρ = {rho}')\n",
    "\n",
    "plt.xlabel('Classification Accuracy', fontsize=14)\n",
    "plt.ylabel('Adaptive Threshold', fontsize=14)\n",
    "plt.title('Adaptive Threshold vs Classification Accuracy', fontsize=16)\n",
    "plt.legend(title='Parameter ρ', title_fontsize='13', fontsize='12')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.savefig(path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plot saved in {path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
