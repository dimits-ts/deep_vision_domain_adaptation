{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Pseudo-labeling for Domain Adaptation in Deep Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Office Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import lib.data\n",
    "import lib.torch_train_eval\n",
    "import lib.adaptive_train_eval\n",
    "\n",
    "import tasks.preprocessing\n",
    "import tasks.utils\n",
    "import tasks.results\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_DIR = \"data/office\"\n",
    "OUTPUT_DIR = \"output/office\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "SOURCE_DATASET = \"amazon\"\n",
    "SOURCE_VAL_SPLIT = .15\n",
    "SOURCE_TEST_SPLIT = .1\n",
    "\n",
    "\n",
    "TARGET_VAL_SPLIT = .15\n",
    "TARGET_TEST_SPLIT = .15\n",
    "TARGET_DATASET = \"webcam\"\n",
    "\n",
    "\n",
    "FINETUNED_MODEL_DIR = os.path.join(OUTPUT_DIR, \"classifier\")\n",
    "UNSUPERVISED_MODEL_DIR = os.path.join(OUTPUT_DIR, \"unsupervised\")\n",
    "SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20 = os.path.join(OUTPUT_DIR, \"semi-supervised-finetuned-20\")\n",
    "SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20 = os.path.join(OUTPUT_DIR, \"semi-supervised-adaptive-20\")\n",
    "SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10 = os.path.join(OUTPUT_DIR, \"semi-supervised-finetuned-10\")\n",
    "SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10 = os.path.join(OUTPUT_DIR, \"semi-supervised-adaptive-10\")\n",
    "\n",
    "FINETUNE_MODEL = False\n",
    "TRAIN_UNSUPERVISED_MODEL = False\n",
    "FINETUNE_SEMI_SUPERVISED_MODEL_20 = False\n",
    "TRAIN_SEMI_SUPERVISED_MODEL_20 = False\n",
    "FINETUNE_SEMI_SUPERVISED_MODEL_10 = False\n",
    "TRAIN_SEMI_SUPERVISED_MODEL_10 = False\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "source_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "source_dataset.load_from_directory(os.path.join(DATA_DIR, SOURCE_DATASET))\n",
    "\n",
    "source_train_dataset, source_val_dataset, source_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        source_dataset, SOURCE_VAL_SPLIT, SOURCE_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "source_train_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    source_train_dataset, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "source_val_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    source_val_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")\n",
    "source_test_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    source_test_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    "    label_encoder=source_dataset.label_encoder,  # use same classes\n",
    ")\n",
    "target_dataset.load_from_directory(os.path.join(DATA_DIR, TARGET_DATASET))\n",
    "\n",
    "target_train_dataset, target_val_dataset, target_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        target_dataset, TARGET_VAL_SPLIT, TARGET_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "target_train_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    target_train_dataset, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "target_test_loader = tasks.preprocessing.create_padded_dataloader(\n",
    "    target_test_dataset, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset_20 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "unlabeled_dataset_20.load_from_image_dataset(target_train_dataset)\n",
    "\n",
    "source_history = tasks.utils.try_load_history(\n",
    "    os.path.join(UNSUPERVISED_MODEL_DIR, \"source_history.pickle\")\n",
    ")\n",
    "target_history = tasks.utils.try_load_history(\n",
    "    os.path.join(UNSUPERVISED_MODEL_DIR, \"target_history.pickle\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_unlabeled_dataset_20, labeled_dataset_20 = lib.data.stratified_split(\n",
    "    target_train_dataset, test_size=0.2\n",
    ")\n",
    "\n",
    "unlabeled_dataset_20 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=labeled_dataset_20.parser_func,\n",
    "    preprocessing_func=labeled_dataset_20.preprocessing_func,\n",
    ")\n",
    "unlabeled_dataset_20.load_from_image_dataset(to_be_unlabeled_dataset_20)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in source_train_dataset.samples:\n",
    "    labeled_dataset_20.add(sample_img, sample_label)\n",
    "\n",
    "len(labeled_dataset_20), len(source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_unlabeled_dataset_10, labeled_dataset_10 = lib.data.stratified_split(\n",
    "    target_train_dataset, test_size=0.1\n",
    ")\n",
    "\n",
    "unlabeled_dataset_10 = lib.data.UnlabeledImageDataset(\n",
    "    parser_func=labeled_dataset_10.parser_func,\n",
    "    preprocessing_func=labeled_dataset_20.preprocessing_func,\n",
    ")\n",
    "unlabeled_dataset_10.load_from_image_dataset(to_be_unlabeled_dataset_10)\n",
    "\n",
    "# combine data from both domain and target datasets\n",
    "for sample_img, sample_label in source_train_dataset.samples:\n",
    "    labeled_dataset_10.add(sample_img, sample_label)\n",
    "\n",
    "len(labeled_dataset_10), len(source_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = source_train_dataset.label_encoder.classes_\n",
    "\n",
    "encodings = {\n",
    "    label: class_name\n",
    "    for label, class_name in enumerate(source_train_dataset.label_encoder.classes_)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "model = torch.hub.load(\n",
    "        \"pytorch/vision:v0.10.0\", \"resnet18\", weights=\"DEFAULT\"\n",
    "    ).to(device)\n",
    "\n",
    "torchinfo.summary(model, input_size=(BATCH_SIZE, 3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.0005)\n",
    "# disable lr for adam\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=100000, gamma=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if FINETUNE_MODEL:\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        source_train_loader,\n",
    "        source_val_loader,\n",
    "        output_dir=FINETUNED_MODEL_DIR,\n",
    "        num_epochs=25,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        previous_history=None\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(FINETUNED_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(range(len(history[\"train_loss\"]))), history[\"train_loss\"])\n",
    "plt.plot(np.array(range(len(history[\"val_loss\"]))), history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# validation accuracy has been calculated wrong here, ignore it for now\n",
    "plt.plot(np.array(range(len(history[\"train_acc\"]))), history[\"train_acc\"])\n",
    "plt.plot(np.array(range(len(history[\"val_acc\"]))), history[\"val_acc\"])\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Domain Adaptation\n",
    "\n",
    "https://webcache.googleusercontent.com/search?q=cache:https://towardsdatascience.com/pseudo-labeling-to-deal-with-small-datasets-what-why-how-fd6f903213af\n",
    "\n",
    "https://stats.stackexchange.com/questions/364584/why-does-using-pseudo-labeling-non-trivially-affect-the-results\n",
    "\n",
    "https://www.sciencedirect.com/science/article/abs/pii/S1077314222001102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if TRAIN_UNSUPERVISED_MODEL:\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(FINETUNED_MODEL_DIR, \"model.pt\"))\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=labeled_dataset_20,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=1, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_20,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=UNSUPERVISED_MODEL_DIR,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=20,\n",
    "            rho=3,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, UNSUPERVISED_MODEL_DIR)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_history = res[\"target_history\"]\n",
    "\n",
    "plt.plot(np.array(range(len(target_history[\"train_acc\"]))), target_history[\"train_acc\"])\n",
    "plt.plot(np.array(range(len(target_history[\"val_acc\"]))), target_history[\"val_acc\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised domain adaptation: 20% target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FINETUNE_SEMI_SUPERVISED_MODEL_20:\n",
    "    model = torch.hub.load(\n",
    "        \"pytorch/vision:v0.10.0\", \"resnet18\", weights=\"DEFAULT\"\n",
    "    ).to(device)\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            labeled_dataset_20, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=source_val_loader,\n",
    "        output_dir=SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20,\n",
    "        num_epochs=25,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        previous_history=history,\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SEMI_SUPERVISED_MODEL_20:\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20, \"model.pt\")\n",
    "    )\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=labeled_dataset_20,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=1, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_20,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=20,\n",
    "            rho=4,\n",
    "            previous_source_history=source_history,\n",
    "            previous_target_history=target_history,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised domain adaptation: 10% target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FINETUNE_SEMI_SUPERVISED_MODEL_10:\n",
    "    model = torch.hub.load(\n",
    "        \"pytorch/vision:v0.10.0\", \"resnet18\", weights=\"DEFAULT\"\n",
    "    ).to(device)\n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer_ft,\n",
    "        scheduler=exp_lr_scheduler,\n",
    "        device=device,\n",
    "        train_dataloader=tasks.preprocessing.create_padded_dataloader(\n",
    "            labeled_dataset_10, shuffle=True, batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        val_dataloader=source_val_loader,\n",
    "        output_dir=SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10,\n",
    "        num_epochs=25,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        previous_history=None,\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_SEMI_SUPERVISED_MODEL_10:\n",
    "    model = tasks.utils.try_load_weights(\n",
    "        model, os.path.join(SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10, \"model.pt\")\n",
    "    )\n",
    "    model, source_history, target_history, label_history = (\n",
    "        lib.adaptive_train_eval.train_adaptive_model(\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer_ft,\n",
    "            scheduler=exp_lr_scheduler,\n",
    "            device=device,\n",
    "            source_train_dataset=labeled_dataset_10,\n",
    "            source_val_dataset=source_val_dataset,\n",
    "            labeled_dataloader_initializer=lambda dataset, sampler=None: tasks.preprocessing.create_padded_dataloader(\n",
    "                dataset, sampler=sampler, batch_size=BATCH_SIZE\n",
    "            ),\n",
    "            unlabeled_dataloader_initializer=lambda dataset: torch.utils.data.DataLoader(\n",
    "                dataset, batch_size=1, shuffle=True\n",
    "            ),\n",
    "            unlabeled_target_train_dataset=unlabeled_dataset_10,\n",
    "            target_val_dataset=target_val_dataset,\n",
    "            output_dir=SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10,\n",
    "            num_epochs=160,\n",
    "            pseudo_sample_period=20,\n",
    "            rho=4,\n",
    "            previous_source_history=None,\n",
    "            previous_target_history=None,\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    res = tasks.utils.load_trained_model(model, SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10)\n",
    "    model = res[\"model\"]\n",
    "    source_history = res[\"source_history\"]\n",
    "    target_history = res[\"target_history\"]\n",
    "    label_history = res[\"label_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.plot_label_history(label_history, encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptiope dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "PRINT_STATS_PERIOD = 500\n",
    "\n",
    "AD_DATA_DIR = \"data/adaptiope\"\n",
    "AD_OUTPUT_DIR = \"output/adaptiope\"\n",
    "\n",
    "AD_SOURCE_DATASET = \"product_images\"\n",
    "AD_TARGET_DATASET = \"real_life\"\n",
    "\n",
    "AD_FINETUNED_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"classifier\")\n",
    "AD_UNSUPERVISED_MODEL_DIR = os.path.join(AD_OUTPUT_DIR, \"unsupervised\")\n",
    "AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_20 = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-finetuned-20\")\n",
    "AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_20 = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-adaptive-20\")\n",
    "AD_SEMI_SUPERVISED_FINETUNED_MODEL_DIR_10 = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-finetuned-10\")\n",
    "AD_SEMI_SUPERVISED_ADAPTIVE_MODEL_DIR_10 = os.path.join(AD_OUTPUT_DIR, \"semi-supervised-adaptive-10\")\n",
    "\n",
    "AD_FINETUNE_MODEL = True\n",
    "AD_TRAIN_UNSUPERVISED_MODEL = False\n",
    "AD_FINETUNE_SEMI_SUPERVISED_MODEL_20 = False\n",
    "AD_TRAIN_SEMI_SUPERVISED_MODEL_20 = False\n",
    "AD_FINETUNE_SEMI_SUPERVISED_MODEL_10 = False\n",
    "AD_TRAIN_SEMI_SUPERVISED_MODEL_10 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_batch_loader(dataset, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4818f16dc845138fb2dff4115488a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad_source_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    ")\n",
    "ad_source_dataset.load_from_directory(os.path.join(AD_DATA_DIR, AD_SOURCE_DATASET))\n",
    "\n",
    "ad_source_train_dataset, ad_source_val_dataset, ad_source_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        ad_source_dataset, SOURCE_VAL_SPLIT, SOURCE_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "ad_source_train_loader = single_batch_loader(\n",
    "    ad_source_train_dataset, shuffle=True\n",
    ")\n",
    "ad_source_val_loader = single_batch_loader(\n",
    "    ad_source_val_dataset, shuffle=False\n",
    ")\n",
    "ad_source_test_loader = single_batch_loader(\n",
    "    ad_source_test_dataset, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809ab08fc0cb4bca994101ae3ef7f10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad_target_dataset = lib.data.ImageDataset(\n",
    "    parser_func=tasks.preprocessing.image_read_func,\n",
    "    preprocessing_func=tasks.preprocessing.resnet_preprocessor,\n",
    "    label_encoder=ad_source_dataset.label_encoder,  # use same classes\n",
    ")\n",
    "ad_target_dataset.load_from_directory(os.path.join(AD_DATA_DIR, AD_TARGET_DATASET))\n",
    "\n",
    "ad_target_train_dataset, ad_target_val_dataset, ad_target_test_dataset = (\n",
    "    lib.data.train_val_test_split(\n",
    "        ad_target_dataset, TARGET_VAL_SPLIT, TARGET_TEST_SPLIT\n",
    "    )\n",
    ")\n",
    "\n",
    "# Since input sizes vary, there is a possibility that the GPU is forced to allocate\n",
    "# more and more buffers without GC. With shuffle=False this will be deterministic between epochs.\n",
    "# https://discuss.pytorch.org/t/how-to-debug-causes-of-gpu-memory-leaks/6741/11\n",
    "ad_target_train_loader = single_batch_loader(\n",
    "    ad_target_train_dataset, shuffle=True\n",
    ")\n",
    "ad_target_test_loader = single_batch_loader(\n",
    "    ad_target_test_dataset, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ad_source_train_dataset.label_encoder.classes_\n",
    "\n",
    "encodings = {\n",
    "    label: class_name\n",
    "    for label, class_name in enumerate(ad_source_train_dataset.label_encoder.classes_)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/adaptiope/product_images/letter tray/letter tray_042.jpg', 56)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_source_dataset.samples[5839]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/adaptiope/product_images/toothbrush/toothbrush_097.jpg', 111)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_source_dataset.samples[5838]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source-only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dimits/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# duplicate cell for convenience, delete later\n",
    "model = torch.hub.load(\"pytorch/vision:v0.10.0\", \"resnet34\", weights=\"DEFAULT\").to(\n",
    "    device\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.0005)\n",
    "# disable lr for adam\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer_ft, step_size=100000, gamma=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec29903e9804d7ea4662558f26c7fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.526170 Accuracy: 0.03000\n",
      "Loss: 0.524782 Accuracy: 0.02600\n",
      "Loss: 0.525237 Accuracy: 0.02400\n",
      "Loss: 0.524172 Accuracy: 0.02400\n",
      "Loss: 0.518296 Accuracy: 0.02640\n",
      "Loss: 0.516582 Accuracy: 0.02667\n",
      "Loss: 0.513550 Accuracy: 0.02686\n",
      "Loss: 0.510109 Accuracy: 0.02775\n",
      "Loss: 0.509112 Accuracy: 0.02711\n",
      "Loss: 0.507558 Accuracy: 0.02720\n",
      "Loss: 0.506009 Accuracy: 0.02800\n",
      "Loss: 0.503962 Accuracy: 0.02950\n",
      "Loss: 0.502305 Accuracy: 0.02954\n",
      "Loss: 0.501675 Accuracy: 0.02900\n",
      "Loss: 0.499953 Accuracy: 0.02933\n",
      "Loss: 0.499179 Accuracy: 0.02962\n",
      "Loss: 0.498291 Accuracy: 0.03082\n",
      "Loss: 0.496094 Accuracy: 0.03244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c6d019e6984c1c9cc8f90c8b300606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4954 Train Acc: 0.0327\n",
      "Val Loss: 7.0511 Val Acc: 0.0125\n",
      "Epoch 1/49\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac17620851554a888756b45dcc0f6430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.475026 Accuracy: 0.05000\n",
      "Loss: 0.473732 Accuracy: 0.04900\n",
      "Loss: 0.473010 Accuracy: 0.04600\n",
      "Loss: 0.471126 Accuracy: 0.04500\n",
      "Loss: 0.467263 Accuracy: 0.04520\n",
      "Loss: 0.466757 Accuracy: 0.04767\n",
      "Loss: 0.466322 Accuracy: 0.04914\n",
      "Loss: 0.464561 Accuracy: 0.04825\n",
      "Loss: 0.463348 Accuracy: 0.04933\n",
      "Loss: 0.460436 Accuracy: 0.05100\n",
      "Loss: 0.459137 Accuracy: 0.05073\n",
      "Loss: 0.459882 Accuracy: 0.05133\n",
      "Loss: 0.456352 Accuracy: 0.05400\n",
      "Loss: 0.455625 Accuracy: 0.05557\n",
      "Loss: 0.455251 Accuracy: 0.05680\n",
      "Loss: 0.453785 Accuracy: 0.05775\n",
      "Loss: 0.453492 Accuracy: 0.05812\n",
      "Loss: 0.453215 Accuracy: 0.05844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809f34681d684bfcb6b6264836c710fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4527 Train Acc: 0.0591\n",
      "Val Loss: 5.7149 Val Acc: 0.0423\n",
      "Epoch 2/49\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b76ff8fc8e449ae9d0dc0f94dde6c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.435578 Accuracy: 0.07800\n",
      "Loss: 0.427141 Accuracy: 0.08500\n",
      "Loss: 0.419904 Accuracy: 0.08933\n",
      "Loss: 0.424432 Accuracy: 0.08300\n",
      "Loss: 0.424736 Accuracy: 0.08440\n",
      "Loss: 0.421584 Accuracy: 0.08567\n",
      "Loss: 0.420327 Accuracy: 0.08229\n",
      "Loss: 0.420519 Accuracy: 0.08325\n",
      "Loss: 0.418999 Accuracy: 0.08489\n",
      "Loss: 0.419201 Accuracy: 0.08380\n",
      "Loss: 0.418177 Accuracy: 0.08291\n",
      "Loss: 0.416217 Accuracy: 0.08450\n",
      "Loss: 0.415310 Accuracy: 0.08415\n",
      "Loss: 0.413740 Accuracy: 0.08514\n",
      "Loss: 0.412782 Accuracy: 0.08587\n",
      "Loss: 0.412743 Accuracy: 0.08650\n",
      "Loss: 0.411071 Accuracy: 0.08906\n",
      "Loss: 0.409767 Accuracy: 0.09000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818a697834d94211997b0ec5ba7f8f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4093 Train Acc: 0.0906\n",
      "Val Loss: 6.8338 Val Acc: 0.0407\n",
      "Epoch 3/49\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc4cabbe6c84715a4cd39dbcbb78209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.381714 Accuracy: 0.10200\n",
      "Loss: 0.385974 Accuracy: 0.11000\n",
      "Loss: 0.389099 Accuracy: 0.10733\n",
      "Loss: 0.392419 Accuracy: 0.10400\n",
      "Loss: 0.392687 Accuracy: 0.10480\n",
      "Loss: 0.390561 Accuracy: 0.10733\n",
      "Loss: 0.386614 Accuracy: 0.11086\n",
      "Loss: 0.385262 Accuracy: 0.11050\n",
      "Loss: 0.383261 Accuracy: 0.11400\n",
      "Loss: 0.383089 Accuracy: 0.11340\n",
      "Loss: 0.382897 Accuracy: 0.11382\n",
      "Loss: 0.383971 Accuracy: 0.11233\n",
      "Loss: 0.382400 Accuracy: 0.11292\n",
      "Loss: 0.381103 Accuracy: 0.11300\n",
      "Loss: 0.379524 Accuracy: 0.11373\n",
      "Loss: 0.378118 Accuracy: 0.11450\n",
      "Loss: 0.376240 Accuracy: 0.11565\n",
      "Loss: 0.376890 Accuracy: 0.11556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31b051135414723af25af002ace3ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3764 Train Acc: 0.1161\n",
      "Val Loss: 5.5870 Val Acc: 0.0466\n",
      "Epoch 4/49\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841e7d3b36a84228807591bdd6952496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.331491 Accuracy: 0.14200\n",
      "Loss: 0.332909 Accuracy: 0.14600\n",
      "Loss: 0.338357 Accuracy: 0.14133\n",
      "Loss: 0.341961 Accuracy: 0.13950\n",
      "Loss: 0.343621 Accuracy: 0.13680\n",
      "Loss: 0.345501 Accuracy: 0.13433\n",
      "Loss: 0.344755 Accuracy: 0.13600\n",
      "Loss: 0.344776 Accuracy: 0.13750\n",
      "Loss: 0.343303 Accuracy: 0.13933\n",
      "Loss: 0.345819 Accuracy: 0.13620\n",
      "Loss: 0.344498 Accuracy: 0.13600\n",
      "Loss: 0.345558 Accuracy: 0.13600\n",
      "Loss: 0.344484 Accuracy: 0.13723\n",
      "Loss: 0.343617 Accuracy: 0.13729\n",
      "Loss: 0.343137 Accuracy: 0.13760\n",
      "Loss: 0.342616 Accuracy: 0.13725\n",
      "Loss: 0.343400 Accuracy: 0.13647\n",
      "Loss: 0.342902 Accuracy: 0.13689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb40f647bd304d7980e04439af1b5603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1845 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.\n",
      "  warnings.warn(\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fa6497da820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/dimits/anaconda3/envs/tf/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "if AD_FINETUNE_MODEL:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_FINETUNED_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))\n",
    "        \n",
    "    model, history = lib.torch_train_eval.train_model(\n",
    "        model,\n",
    "        criterion,\n",
    "        optimizer_ft,\n",
    "        exp_lr_scheduler,\n",
    "        device,\n",
    "        ad_source_train_loader,\n",
    "        ad_source_val_loader,\n",
    "        output_dir=AD_FINETUNED_MODEL_DIR,\n",
    "        num_epochs=50,\n",
    "        patience=5,\n",
    "        warmup_period=5,\n",
    "        gradient_accumulation=3,\n",
    "        previous_history=history,\n",
    "        train_stats_period=PRINT_STATS_PERIOD\n",
    "    )\n",
    "else:\n",
    "    history = tasks.utils.try_load_history(os.path.join(AD_FINETUNED_MODEL_DIR, \"history.pickle\"))\n",
    "    model = tasks.utils.try_load_weights(model, os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(AD_FINETUNED_MODEL_DIR, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(range(len(history[\"train_loss\"]))), history[\"train_loss\"])\n",
    "plt.plot(np.array(range(len(history[\"val_loss\"]))), history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation accuracy has been calculated wrong here, ignore it for now\n",
    "plt.plot(np.array(range(len(history[\"train_acc\"]))), history[\"train_acc\"])\n",
    "plt.plot(np.array(range(len(history[\"val_acc\"]))), history[\"val_acc\"])\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, source_test_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.results.classification_results(model, target_test_loader, class_names, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
