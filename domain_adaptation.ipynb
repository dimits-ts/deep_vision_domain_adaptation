{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DATA_DIR = \"data/office\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "VAL_SPLIT = .15\n",
    "TEST_SPLIT = .15\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def resnet_preprocessor(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesses an image for ResNet model.\n",
    "\n",
    "    :param numpy.ndarray image: The input image.\n",
    "    :return: Preprocessed image.\n",
    "    :rtype: numpy.ndarray\n",
    "    \"\"\"\n",
    "    preprocess = torchvision.transforms.Compose(\n",
    "        [\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    image = preprocess(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_read_func(image_path):\n",
    "    return imageio.imread(image_path, pilmode='RGB')\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Lazily loads images from a root directory.\n",
    "    Directory is assumed to be of shape \"<root>/<class_name>/<instance_file>\".\n",
    "    Allows custom functions for reading, preprocessing each image and setting the label encodings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        parser_func: Callable = image_read_func,\n",
    "        preprocessing_func: Callable[[np.ndarray], np.ndarray] = resnet_preprocessor,\n",
    "        label_encoder=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the ImageDataset.\n",
    "\n",
    "        :param str data_dir: Root directory containing the dataset.\n",
    "        :param parser_func: Function to parse images.\n",
    "        :type parser_func: Callable, optional\n",
    "        :param preprocessing_func: Function to preprocess images.\n",
    "        :type preprocessing_func: Callable[[numpy.ndarray], numpy.ndarray], optional\n",
    "        :param label_encoder: Encoder for label encoding.\n",
    "        :type label_encoder: sklearn.preprocessing.LabelEncoder or None, optional\n",
    "        \"\"\"\n",
    "        self.parser_func = parser_func\n",
    "        self.preprocessing_func = preprocessing_func\n",
    "        self.label_encoder = label_encoder\n",
    "        self.samples = self._load_dataset_paths(data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = self.parser_func(image_path)\n",
    "        image = self.preprocessing_func(image)\n",
    "\n",
    "        if not torch.is_tensor(image):\n",
    "            image = torch.tensor(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_dataset_paths(self, data_dir):\n",
    "        \"\"\"\n",
    "        Loads paths of images in the dataset.\n",
    "\n",
    "        :param str data_dir: Root directory containing the dataset.\n",
    "        :return: List of tuples containing image paths and their corresponding labels.\n",
    "        :rtype: List[Tuple[str, int]]\n",
    "        \"\"\"\n",
    "        class_names = os.listdir(data_dir)\n",
    "\n",
    "        if self.label_encoder is None:\n",
    "            self.label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "            self.label_encoder.fit(class_names)\n",
    "\n",
    "        samples = []\n",
    "        for class_name in tqdm(class_names):\n",
    "            class_data_dir = os.path.join(data_dir, class_name)\n",
    "\n",
    "            for file_name in os.listdir(class_data_dir):\n",
    "                samples.append(\n",
    "                    (\n",
    "                        os.path.join(class_data_dir, file_name),\n",
    "                        self.label_encoder.transform([class_name])[0],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    # Sort the batch by image height in descending order\n",
    "    batch = sorted(batch, key=lambda x: x[0].shape[1], reverse=True)\n",
    "\n",
    "    # Get the maximum height and width among all images in the batch\n",
    "    max_height = max(img.shape[1] for img, _ in batch)\n",
    "    max_width = max(img.shape[2] for img, _ in batch)\n",
    "\n",
    "    # Pad each image to match the maximum height and width\n",
    "    padded_batch = []\n",
    "    for img, label in batch:\n",
    "        # Calculate padding sizes\n",
    "        pad_height = max_height - img.shape[1]\n",
    "        pad_width = max_width - img.shape[2]\n",
    "\n",
    "        # Pad the image\n",
    "        padded_img = torch.nn.functional.pad(img, (0, pad_width, 0, pad_height))\n",
    "\n",
    "        padded_batch.append((padded_img, label))\n",
    "\n",
    "    # Stack images and labels into tensors\n",
    "    images = torch.stack([img for img, _ in padded_batch])\n",
    "    labels = torch.tensor([label for _, label in padded_batch])\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "def get_loaders(\n",
    "    dataset,\n",
    "    batch_size: int,\n",
    "    val_split_perc: float,\n",
    "    test_split_perc: float,\n",
    "    collate_func: Callable,\n",
    "):\n",
    "    dataset_size = len(dataset)\n",
    "\n",
    "    # Create indices for the dataset\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Calculate split indices\n",
    "    val_split = int(np.floor(val_split_perc * dataset_size))\n",
    "    test_split = int(np.floor(test_split_perc * dataset_size))\n",
    "\n",
    "    # Split indices for train, validation, and test\n",
    "    train_indices = indices[val_split + test_split :]\n",
    "    val_indices = indices[:val_split]\n",
    "    test_indices = indices[val_split : (val_split + test_split)]\n",
    "\n",
    "    # Create PT data samplers and loaders\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, collate_fn=collate_func\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=val_sampler, collate_fn=collate_func\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=test_sampler, collate_fn=collate_func\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dad959ccf14571bf6329e7a87dcf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_dataset = ImageDataset(os.path.join(DATA_DIR, \"synthetic\"))\n",
    "source_train_loader, source_val_loader, source_test_loader = get_loaders(\n",
    "    source_dataset, BATCH_SIZE, VAL_SPLIT, TEST_SPLIT, collate_pad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_load_weights(model, weights_path: str):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(weights_path))\n",
    "    except Exception as e:\n",
    "        print(\"Cannot load proper weights: \", e)\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dimits/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [2, 1000]                 --\n",
       "├─Conv2d: 1-1                            [2, 64, 150, 150]         9,408\n",
       "├─BatchNorm2d: 1-2                       [2, 64, 150, 150]         128\n",
       "├─ReLU: 1-3                              [2, 64, 150, 150]         --\n",
       "├─MaxPool2d: 1-4                         [2, 64, 75, 75]           --\n",
       "├─Sequential: 1-5                        [2, 64, 75, 75]           --\n",
       "│    └─BasicBlock: 2-1                   [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-1                  [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-3                    [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-4                  [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-6                    [2, 64, 75, 75]           --\n",
       "│    └─BasicBlock: 2-2                   [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-7                  [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-9                    [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-10                 [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-12                   [2, 64, 75, 75]           --\n",
       "│    └─BasicBlock: 2-3                   [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-13                 [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-14            [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-15                   [2, 64, 75, 75]           --\n",
       "│    │    └─Conv2d: 3-16                 [2, 64, 75, 75]           36,864\n",
       "│    │    └─BatchNorm2d: 3-17            [2, 64, 75, 75]           128\n",
       "│    │    └─ReLU: 3-18                   [2, 64, 75, 75]           --\n",
       "├─Sequential: 1-6                        [2, 128, 38, 38]          --\n",
       "│    └─BasicBlock: 2-4                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-19                 [2, 128, 38, 38]          73,728\n",
       "│    │    └─BatchNorm2d: 3-20            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-21                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-22                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-23            [2, 128, 38, 38]          256\n",
       "│    │    └─Sequential: 3-24             [2, 128, 38, 38]          8,448\n",
       "│    │    └─ReLU: 3-25                   [2, 128, 38, 38]          --\n",
       "│    └─BasicBlock: 2-5                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-26                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-27            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-28                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-29                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-30            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-31                   [2, 128, 38, 38]          --\n",
       "│    └─BasicBlock: 2-6                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-32                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-34                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-35                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-37                   [2, 128, 38, 38]          --\n",
       "│    └─BasicBlock: 2-7                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-38                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-39            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-40                   [2, 128, 38, 38]          --\n",
       "│    │    └─Conv2d: 3-41                 [2, 128, 38, 38]          147,456\n",
       "│    │    └─BatchNorm2d: 3-42            [2, 128, 38, 38]          256\n",
       "│    │    └─ReLU: 3-43                   [2, 128, 38, 38]          --\n",
       "├─Sequential: 1-7                        [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-8                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-44                 [2, 256, 19, 19]          294,912\n",
       "│    │    └─BatchNorm2d: 3-45            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-46                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-47                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-48            [2, 256, 19, 19]          512\n",
       "│    │    └─Sequential: 3-49             [2, 256, 19, 19]          33,280\n",
       "│    │    └─ReLU: 3-50                   [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-9                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-51                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-52            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-53                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-54                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-56                   [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-10                  [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-57                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-58            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-59                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-60                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-61            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-62                   [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-11                  [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-63                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-64            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-65                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-66                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-67            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-68                   [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-12                  [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-69                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-71                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-72                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-73            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-74                   [2, 256, 19, 19]          --\n",
       "│    └─BasicBlock: 2-13                  [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-75                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-76            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-77                   [2, 256, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-78                 [2, 256, 19, 19]          589,824\n",
       "│    │    └─BatchNorm2d: 3-79            [2, 256, 19, 19]          512\n",
       "│    │    └─ReLU: 3-80                   [2, 256, 19, 19]          --\n",
       "├─Sequential: 1-8                        [2, 512, 10, 10]          --\n",
       "│    └─BasicBlock: 2-14                  [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-81                 [2, 512, 10, 10]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-82            [2, 512, 10, 10]          1,024\n",
       "│    │    └─ReLU: 3-83                   [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-84                 [2, 512, 10, 10]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-85            [2, 512, 10, 10]          1,024\n",
       "│    │    └─Sequential: 3-86             [2, 512, 10, 10]          132,096\n",
       "│    │    └─ReLU: 3-87                   [2, 512, 10, 10]          --\n",
       "│    └─BasicBlock: 2-15                  [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-88                 [2, 512, 10, 10]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-89            [2, 512, 10, 10]          1,024\n",
       "│    │    └─ReLU: 3-90                   [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-91                 [2, 512, 10, 10]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-92            [2, 512, 10, 10]          1,024\n",
       "│    │    └─ReLU: 3-93                   [2, 512, 10, 10]          --\n",
       "│    └─BasicBlock: 2-16                  [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-94                 [2, 512, 10, 10]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-95            [2, 512, 10, 10]          1,024\n",
       "│    │    └─ReLU: 3-96                   [2, 512, 10, 10]          --\n",
       "│    │    └─Conv2d: 3-97                 [2, 512, 10, 10]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            [2, 512, 10, 10]          1,024\n",
       "│    │    └─ReLU: 3-99                   [2, 512, 10, 10]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [2, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [2, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 21,797,672\n",
       "Trainable params: 21,797,672\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 13.67\n",
       "==========================================================================================\n",
       "Input size (MB): 2.16\n",
       "Forward/backward pass size (MB): 218.36\n",
       "Params size (MB): 87.19\n",
       "Estimated Total Size (MB): 307.71\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "\n",
    "model = torch.hub.load(\n",
    "    \"pytorch/vision:v0.10.0\", \"resnet34\", weights=torchvision.models.ResNet34_Weights.DEFAULT\n",
    ").to(device)\n",
    "\n",
    "torchinfo.summary(model, input_size=(BATCH_SIZE, 3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "# code adapted from https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "\n",
    "class EpochResults:\n",
    "    def __init__(self, train_loss, train_acc, val_loss, val_acc) -> None:\n",
    "        self.train_loss = train_loss\n",
    "        self.train_acc = train_acc\n",
    "        self.val_loss = val_loss\n",
    "        self.val_acc = val_acc\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device: str,\n",
    "    train_dataloader: torch.utils.data.DataLoader,\n",
    "    val_dataloader: torch.utils.data.DataLoader,\n",
    "    output_dir: str,\n",
    "    num_epochs: int = 25,\n",
    "    patience: int = 1,\n",
    "    previous_history: dict[str, list[float]] = None\n",
    ") -> tuple[nn.Module, dict[str, np.ndarray]]:\n",
    "\n",
    "    dataloaders = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "    dataset_sizes = {\n",
    "        \"train\": len(train_dataloader.dataset),\n",
    "        \"val\": len(val_dataloader.dataset),\n",
    "    }\n",
    "    output_model_path = os.path.join(output_dir, \"model.pt\")\n",
    "    output_history_path = os.path.join(output_dir, \"history.pickle\")\n",
    "\n",
    "    if previous_history is None:\n",
    "        history = {\"train_loss\": [], \"train_acc\": [], \"eval_loss\": [], \"eval_acc\": []}\n",
    "\n",
    "    since = time.time()\n",
    "    torch.save(model.state_dict(), output_model_path)\n",
    "    best_acc = 0.0\n",
    "    # early stopping counter\n",
    "    epochs_no_progress = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "        res = train_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            criterion,\n",
    "            scheduler,\n",
    "            dataloaders,\n",
    "            dataset_sizes,\n",
    "            device\n",
    "        )\n",
    "        print(\n",
    "            f\"Train Loss: {res.train_loss:.4f} Train Acc: {res.train_acc:.4f}\\n\"\n",
    "            f\"Val Loss: {res.val_loss:.4f} Val Acc: {res.val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        history = update_save_history(history, res, output_history_path)\n",
    "\n",
    "        # deep copy the model\n",
    "        if res.val_acc > best_acc:\n",
    "            best_acc = res.val_acc\n",
    "            torch.save(model.state_dict(), output_model_path)\n",
    "            epochs_no_progress = 0\n",
    "        else:\n",
    "            epochs_no_progress += 1\n",
    "\n",
    "        # early stopping mechanism\n",
    "        if epochs_no_progress >= patience:\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(torch.load(output_model_path))\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def update_save_history(\n",
    "    history: dict, res: EpochResults, hist_output_path: str\n",
    ") -> dict:\n",
    "    history[\"train_loss\"].append(res.train_acc)\n",
    "    history[\"train_acc\"].append(res.train_acc)\n",
    "    history[\"val_loss\"].append(res.val_loss)\n",
    "    history[\"val_acc\"].append(res.val_acc)\n",
    "\n",
    "    try:\n",
    "        with open(hist_output_path, \"wb\") as handle:\n",
    "            pickle.dump(history, handle)\n",
    "    except Exception as e:\n",
    "        print(\"WARNING: Error while saving training history: \", e)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    device: str\n",
    ") -> EpochResults:\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in tqdm(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if phase == \"train\":\n",
    "            scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double().cpu() / dataset_sizes[phase]\n",
    "\n",
    "        if phase == \"train\":\n",
    "            train_loss = epoch_loss\n",
    "            train_acc = epoch_acc\n",
    "        else:\n",
    "            val_loss = epoch_loss\n",
    "            val_acc = epoch_acc\n",
    "\n",
    "        return EpochResults(\n",
    "            train_loss=train_loss,\n",
    "            train_acc=train_acc,\n",
    "            val_loss=val_loss,\n",
    "            val_acc=val_acc,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dc55b106274531940996f504aae55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 3.0340 Acc: 0.0281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9ecf609e384ed6a2a74a75cbe8cf84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7325 Acc: 0.0074\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c22f20f00e4dd4ad42ac6f98a01427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.8921 Acc: 0.0284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9926c9049a4adab60de89ec8497810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6371 Acc: 0.0026\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a832c010c93a435188c5cc4846433713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.8641 Acc: 0.0358\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8eea3500b0d4b5c8055274f1b9d55e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.8225 Acc: 0.0435\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e778d01c66f04e778ac47ed526ba2eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.7419 Acc: 0.0529\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d456b0c5364566ad77184253da422e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.6492 Acc: 0.0781\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84837eb1bbb4afebe0b2e77d0186f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.5221 Acc: 0.1052\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a25fa908084034a3afec2594fd0a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.3416 Acc: 0.1613\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9d1a3cc9524440bd6c2d96e98adeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.2748 Acc: 0.1826\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc595381d2a43358e201355b7b7559e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.2280 Acc: 0.1948\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b531edbe67a04b769311acbbf6ba616e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.1786 Acc: 0.2187\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3cf81d309a43889527fff3efc55c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.1360 Acc: 0.2335\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a631e319ec43e08c20ce9ed6ca6b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.0663 Acc: 0.2435\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe74159e2ce4b748025a192f92092e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 2.0059 Acc: 0.2703\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0128b8428b4e9c9946e1b201b252bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8954 Acc: 0.3216\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b7b9978c040ad87c5957cd9125bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8766 Acc: 0.3339\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f7b794d19c4ba9917e59f7742a7fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8579 Acc: 0.3339\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e1794383064b5eb17d3568f2e2e1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8461 Acc: 0.3413\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f556694e63674662a9c2a90bd56769e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8161 Acc: 0.3487\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc4f31beb645468a6e37f6abfd3c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.8190 Acc: 0.3455\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04a020582664646879e672cbc5e032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7933 Acc: 0.3594\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ec968e1d804fc389f33a1e0b7be9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.7869 Acc: 0.3635\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe64241ad2a94fb78baccac62726d7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.05)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "output_path = os.path.join(OUTPUT_DIR, \"synthetic\")\n",
    "model = try_load_weights(model, output_path)\n",
    "\n",
    "model, history = train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer_ft,\n",
    "    exp_lr_scheduler,\n",
    "    device,\n",
    "    source_train_loader,\n",
    "    source_val_loader,\n",
    "    output_path=output_path,\n",
    "    num_epochs=25,\n",
    "    patience=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    actual = []\n",
    "    preds = []\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, labels in tqdm(test_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        # Get and store predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        for label, pred in zip(labels, predicted):\n",
    "            actual.append(label.cpu())\n",
    "            preds.append(pred.cpu())\n",
    "        \n",
    "    return np.array(actual), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predicted = test(model, source_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "class_names = source_dataset.label_encoder.classes_\n",
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        actual, predicted, zero_division=0, target_names=class_names\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://towardsdatascience.com/neural-network-calibration-using-pytorch-c44b7221a61\n",
    "def T_scaling(logits, temperature):\n",
    "    return torch.div(logits, temperature)\n",
    "\n",
    "\n",
    "temperature = nn.Parameter(torch.ones(1).cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=10000, line_search_fn='strong_wolfe')\n",
    "\n",
    "logits_list = []\n",
    "labels_list = []\n",
    "\n",
    "for i, data in enumerate(tqdm(val_loader, 0)):\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "      logits_list.append(net(images))\n",
    "      labels_list.append(labels)\n",
    "\n",
    "# Create tensors\n",
    "logits_list = torch.cat(logits_list).to(device)\n",
    "labels_list = torch.cat(labels_list).to(device)\n",
    "\n",
    "def _eval():\n",
    "  loss = criterion(T_scaling(logits_list, temperature), labels_list)\n",
    "  loss.backward()\n",
    "  return loss\n",
    "\n",
    "optimizer.step(_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
